[
  {
    "id": "zai-org/GLM-4.7-Flash",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 363320,
    "likes": 1180,
    "tags": [
      "transformers",
      "safetensors",
      "glm4_moe_lite",
      "text-generation",
      "conversational",
      "en",
      "zh",
      "arxiv:2508.06471",
      "license:mit",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "nvidia/personaplex-7b-v1",
    "task": "audio-to-audio",
    "library": "moshi",
    "downloads": 29354,
    "likes": 979,
    "tags": [
      "moshi",
      "safetensors",
      "personaplex",
      "speech-to-speech",
      "audio-to-audio",
      "en",
      "arxiv:2503.04721",
      "arxiv:2110.13900",
      "arxiv:2410.00037",
      "base_model:kyutai/moshiko-pytorch-bf16",
      "base_model:finetune:kyutai/moshiko-pytorch-bf16",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "microsoft/VibeVoice-ASR",
    "task": "automatic-speech-recognition",
    "library": "transformers",
    "downloads": 21722,
    "likes": 520,
    "tags": [
      "transformers",
      "safetensors",
      "vibevoice",
      "ASR",
      "Transcriptoin",
      "Diarization",
      "Speech-to-Text",
      "automatic-speech-recognition",
      "en",
      "zh",
      "license:mit",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-TTS-12Hz-1.7B-CustomVoice",
    "task": null,
    "library": null,
    "downloads": 42703,
    "likes": 466,
    "tags": [
      "safetensors",
      "qwen3_tts",
      "arxiv:2601.15621",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "unsloth/GLM-4.7-Flash-GGUF",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 195744,
    "likes": 326,
    "tags": [
      "transformers",
      "gguf",
      "unsloth",
      "text-generation",
      "en",
      "zh",
      "arxiv:2508.06471",
      "base_model:zai-org/GLM-4.7-Flash",
      "base_model:quantized:zai-org/GLM-4.7-Flash",
      "license:mit",
      "endpoints_compatible",
      "region:us",
      "imatrix",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "lightonai/LightOnOCR-2-1B",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 12479,
    "likes": 287,
    "tags": [
      "transformers",
      "safetensors",
      "mistral3",
      "text-generation",
      "ocr",
      "document-understanding",
      "vision-language",
      "pdf",
      "tables",
      "forms",
      "image-text-to-text",
      "conversational",
      "en",
      "fr",
      "de",
      "es",
      "it",
      "nl",
      "pt",
      "sv",
      "da",
      "zh",
      "ja",
      "arxiv:2601.14251",
      "arxiv:2412.13663",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:eu"
    ],
    "description": ""
  },
  {
    "id": "openbmb/AgentCPM-Report",
    "task": null,
    "library": null,
    "downloads": 634,
    "likes": 252,
    "tags": [
      "safetensors",
      "minicpm",
      "custom_code",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "google/translategemma-4b-it",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 68552,
    "likes": 534,
    "tags": [
      "transformers",
      "safetensors",
      "gemma3",
      "image-to-text",
      "image-text-to-text",
      "conversational",
      "arxiv:2601.09012",
      "arxiv:2503.19786",
      "license:gemma",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "sweepai/sweep-next-edit-1.5B",
    "task": null,
    "library": null,
    "downloads": 2743,
    "likes": 223,
    "tags": [
      "gguf",
      "code",
      "autocomplete",
      "next-edit",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "FlashLabs/Chroma-4B",
    "task": "any-to-any",
    "library": "transformers",
    "downloads": 4684,
    "likes": 222,
    "tags": [
      "transformers",
      "safetensors",
      "chroma",
      "feature-extraction",
      "Speech-to-Speech",
      "Multimodal",
      "any-to-any",
      "custom_code",
      "en",
      "arxiv:2601.11141",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "stepfun-ai/Step3-VL-10B",
    "task": "image-text-to-text",
    "library": null,
    "downloads": 45492,
    "likes": 319,
    "tags": [
      "safetensors",
      "step_robotics",
      "image-text-to-text",
      "conversational",
      "custom_code",
      "arxiv:2601.09668",
      "base_model:stepfun-ai/Step3-VL-10B-Base",
      "base_model:finetune:stepfun-ai/Step3-VL-10B-Base",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-TTS-12Hz-1.7B-Base",
    "task": null,
    "library": null,
    "downloads": 58887,
    "likes": 183,
    "tags": [
      "safetensors",
      "qwen3_tts",
      "arxiv:2601.15621",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "kyutai/pocket-tts",
    "task": null,
    "library": "pocket-tts",
    "downloads": 43087,
    "likes": 470,
    "tags": [
      "pocket-tts",
      "en",
      "arxiv:2509.06926",
      "license:cc-by-4.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "HeartMuLa/HeartMuLa-oss-3B",
    "task": "text-to-audio",
    "library": null,
    "downloads": 7549,
    "likes": 209,
    "tags": [
      "safetensors",
      "heartmula",
      "music",
      "art",
      "text-to-audio",
      "zh",
      "en",
      "ja",
      "ko",
      "es",
      "arxiv:2601.10547",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Lightricks/LTX-2",
    "task": "image-to-video",
    "library": "diffusers",
    "downloads": 2228664,
    "likes": 1312,
    "tags": [
      "diffusers",
      "safetensors",
      "image-to-video",
      "text-to-video",
      "video-to-video",
      "image-text-to-video",
      "audio-to-video",
      "text-to-audio",
      "video-to-audio",
      "audio-to-audio",
      "text-to-audio-video",
      "image-to-audio-video",
      "image-text-to-audio-video",
      "ltx-2",
      "ltx-video",
      "ltxv",
      "lightricks",
      "en",
      "de",
      "es",
      "fr",
      "ja",
      "ko",
      "zh",
      "it",
      "pt",
      "arxiv:2601.03233",
      "license:other",
      "diffusers:LTX2Pipeline",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "LiquidAI/LFM2.5-1.2B-Thinking",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 6563,
    "likes": 160,
    "tags": [
      "transformers",
      "safetensors",
      "lfm2",
      "text-generation",
      "liquid",
      "lfm2.5",
      "edge",
      "conversational",
      "en",
      "ar",
      "zh",
      "fr",
      "de",
      "ja",
      "ko",
      "es",
      "arxiv:2511.23404",
      "base_model:LiquidAI/LFM2.5-1.2B-Base",
      "base_model:finetune:LiquidAI/LFM2.5-1.2B-Base",
      "license:other",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "black-forest-labs/FLUX.2-klein-4B",
    "task": "image-to-image",
    "library": "diffusers",
    "downloads": 59843,
    "likes": 345,
    "tags": [
      "diffusers",
      "safetensors",
      "text-to-image",
      "image-editing",
      "flux",
      "diffusion-single-file",
      "image-to-image",
      "en",
      "license:apache-2.0",
      "diffusers:Flux2KleinPipeline",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-TTS-12Hz-1.7B-VoiceDesign",
    "task": null,
    "library": null,
    "downloads": 26129,
    "likes": 145,
    "tags": [
      "safetensors",
      "qwen3_tts",
      "arxiv:2601.15621",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "zai-org/GLM-Image",
    "task": "text-to-image",
    "library": "diffusers",
    "downloads": 13114,
    "likes": 980,
    "tags": [
      "diffusers",
      "safetensors",
      "text-to-image",
      "zh",
      "en",
      "license:mit",
      "diffusers:GlmImagePipeline",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "black-forest-labs/FLUX.2-klein-9B",
    "task": "image-to-image",
    "library": "diffusers",
    "downloads": 41538,
    "likes": 321,
    "tags": [
      "diffusers",
      "safetensors",
      "image-generation",
      "image-editing",
      "flux",
      "diffusion-single-file",
      "image-to-image",
      "en",
      "license:other",
      "diffusers:Flux2KleinPipeline",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "zai-org/GLM-4.7",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 74315,
    "likes": 1802,
    "tags": [
      "transformers",
      "safetensors",
      "glm4_moe",
      "text-generation",
      "conversational",
      "en",
      "zh",
      "arxiv:2508.06471",
      "license:mit",
      "eval-results",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Phr00t/Qwen-Image-Edit-Rapid-AIO",
    "task": "text-to-image",
    "library": "comfyUI",
    "downloads": 0,
    "likes": 1502,
    "tags": [
      "comfyUI",
      "qwen",
      "qwen-edit",
      "t2i",
      "i2i",
      "text-to-image",
      "base_model:Qwen/Qwen-Image-Edit-2511",
      "base_model:finetune:Qwen/Qwen-Image-Edit-2511",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Tongyi-MAI/Z-Image-Turbo",
    "task": "text-to-image",
    "library": "diffusers",
    "downloads": 507348,
    "likes": 3921,
    "tags": [
      "diffusers",
      "safetensors",
      "text-to-image",
      "en",
      "arxiv:2511.22699",
      "arxiv:2511.22677",
      "arxiv:2511.13649",
      "license:apache-2.0",
      "diffusers:ZImagePipeline",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-TTS-12Hz-0.6B-Base",
    "task": null,
    "library": null,
    "downloads": 30704,
    "likes": 99,
    "tags": [
      "safetensors",
      "qwen3_tts",
      "arxiv:2601.15621",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Alibaba-Apsara/DASD-4B-Thinking",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 1479,
    "likes": 152,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "conversational",
      "dataset:Alibaba-Apsara/Superior-Reasoning-SFT-gpt-oss-120b",
      "dataset:Alibaba-Apsara/Superior-Reasoning-SFT-gpt-oss-120b-Logprob",
      "arxiv:2601.09088",
      "arxiv:2512.20908",
      "license:apache-2.0",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "fal/Qwen-Image-Edit-2511-Multiple-Angles-LoRA",
    "task": "image-to-image",
    "library": "diffusers",
    "downloads": 72781,
    "likes": 845,
    "tags": [
      "diffusers",
      "qwen",
      "qwen-image-edit",
      "qwen-image-edit-2511",
      "lora",
      "multi-angle",
      "camera-angles",
      "camera-control",
      "image-editing",
      "image-to-image",
      "gaussian-splatting",
      "fal",
      "en",
      "base_model:Qwen/Qwen-Image-Edit-2511",
      "base_model:adapter:Qwen/Qwen-Image-Edit-2511",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "google/medgemma-1.5-4b-it",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 93206,
    "likes": 361,
    "tags": [
      "transformers",
      "safetensors",
      "gemma3",
      "image-to-text",
      "medical",
      "radiology",
      "clinical-reasoning",
      "dermatology",
      "pathology",
      "ophthalmology",
      "chest-x-ray",
      "image-text-to-text",
      "conversational",
      "arxiv:2303.15343",
      "arxiv:2507.05201",
      "arxiv:2406.19578",
      "arxiv:2405.03162",
      "arxiv:2106.14463",
      "arxiv:2009.13081",
      "arxiv:2203.14371",
      "arxiv:1909.06146",
      "arxiv:2102.09542",
      "arxiv:2411.15640",
      "arxiv:2404.05590",
      "arxiv:2501.18362",
      "arxiv:1605.01397",
      "arxiv:1901.07031",
      "arxiv:2403.17834",
      "arxiv:2402.16040",
      "license:other",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "numind/NuMarkdown-8B-Thinking",
    "task": "image-to-text",
    "library": "transformers",
    "downloads": 936077,
    "likes": 302,
    "tags": [
      "transformers",
      "safetensors",
      "qwen2_5_vl",
      "image-to-text",
      "OCR",
      "vision-language",
      "VLM",
      "Reasoning",
      "document-to-markdown",
      "qwen2.5",
      "markdown",
      "extraction",
      "RAG",
      "license:mit",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "ekwek/Soprano-1.1-80M",
    "task": "text-to-speech",
    "library": "transformers",
    "downloads": 22068,
    "likes": 155,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "text-to-speech",
      "license:apache-2.0",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "google/translategemma-27b-it",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 26368,
    "likes": 270,
    "tags": [
      "transformers",
      "safetensors",
      "gemma3",
      "image-to-text",
      "image-text-to-text",
      "conversational",
      "arxiv:2601.09012",
      "arxiv:2503.19786",
      "license:gemma",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "google/translategemma-12b-it",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 46306,
    "likes": 215,
    "tags": [
      "transformers",
      "safetensors",
      "gemma3",
      "image-to-text",
      "image-text-to-text",
      "conversational",
      "arxiv:2601.09012",
      "arxiv:2503.19786",
      "license:gemma",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Overworld/Waypoint-1-Small",
    "task": null,
    "library": "diffusers",
    "downloads": 799,
    "likes": 70,
    "tags": [
      "diffusers",
      "safetensors",
      "WM",
      "Diffusion",
      "Egocentric",
      "en",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-TTS-12Hz-0.6B-CustomVoice",
    "task": null,
    "library": null,
    "downloads": 16181,
    "likes": 62,
    "tags": [
      "safetensors",
      "qwen3_tts",
      "arxiv:2601.15621",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "YatharthS/LuxTTS",
    "task": "text-to-speech",
    "library": null,
    "downloads": 186,
    "likes": 61,
    "tags": [
      "onnx",
      "text-to-speech",
      "en",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "unsloth/GLM-4.7-Flash-REAP-23B-A3B-GGUF",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 13246,
    "likes": 57,
    "tags": [
      "transformers",
      "gguf",
      "glm",
      "unsloth",
      "MOE",
      "pruning",
      "compression",
      "text-generation",
      "en",
      "arxiv:2510.13999",
      "base_model:cerebras/GLM-4.7-Flash-REAP-23B-A3B",
      "base_model:quantized:cerebras/GLM-4.7-Flash-REAP-23B-A3B",
      "license:mit",
      "endpoints_compatible",
      "region:us",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "stepfun-ai/Step-Audio-R1.1",
    "task": "audio-text-to-text",
    "library": "transformers",
    "downloads": 463,
    "likes": 135,
    "tags": [
      "transformers",
      "safetensors",
      "step_audio_2",
      "text-generation",
      "audio-reasoning",
      "chain-of-thought",
      "multi-modal",
      "step-audio-r1",
      "audio-text-to-text",
      "custom_code",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "facebook/sam3",
    "task": "mask-generation",
    "library": "transformers",
    "downloads": 1628528,
    "likes": 1446,
    "tags": [
      "transformers",
      "safetensors",
      "sam3_video",
      "feature-extraction",
      "sam3",
      "mask-generation",
      "en",
      "license:other",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "microsoft/OptiMind-SFT",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 980,
    "likes": 73,
    "tags": [
      "transformers",
      "safetensors",
      "gpt_oss",
      "text-generation",
      "optimization",
      "operations-research",
      "milp",
      "gurobi",
      "sft",
      "conversational",
      "en",
      "arxiv:2509.22979",
      "base_model:unsloth/gpt-oss-20b-BF16",
      "base_model:finetune:unsloth/gpt-oss-20b-BF16",
      "license:mit",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "openbmb/AgentCPM-Explore",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 3087,
    "likes": 398,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "conversational",
      "en",
      "base_model:Qwen/Qwen3-4B-Thinking-2507",
      "base_model:finetune:Qwen/Qwen3-4B-Thinking-2507",
      "license:apache-2.0",
      "eval-results",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "LiquidAI/LFM2.5-1.2B-Instruct",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 65536,
    "likes": 419,
    "tags": [
      "transformers",
      "safetensors",
      "lfm2",
      "text-generation",
      "liquid",
      "lfm2.5",
      "edge",
      "conversational",
      "en",
      "ar",
      "zh",
      "fr",
      "de",
      "ja",
      "ko",
      "es",
      "arxiv:2511.23404",
      "base_model:LiquidAI/LFM2.5-1.2B-Base",
      "base_model:finetune:LiquidAI/LFM2.5-1.2B-Base",
      "license:other",
      "eval-results",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "RuneXX/LTX-2-Workflows",
    "task": null,
    "library": null,
    "downloads": 0,
    "likes": 58,
    "tags": [
      "ltx",
      "ltx-2",
      "comfyui",
      "comfy",
      "GGUF",
      "ltx-video",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "ByteDance-Seed/Stable-DiffCoder-8B-Instruct",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 145,
    "likes": 50,
    "tags": [
      "transformers",
      "safetensors",
      "llama",
      "text-generation",
      "conversational",
      "custom_code",
      "arxiv:2601.15892",
      "base_model:ByteDance-Seed/Stable-DiffCoder-8B-Base",
      "base_model:finetune:ByteDance-Seed/Stable-DiffCoder-8B-Base",
      "license:mit",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "MiniMaxAI/MiniMax-M2.1",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 245170,
    "likes": 1142,
    "tags": [
      "transformers",
      "safetensors",
      "minimax_m2",
      "text-generation",
      "conversational",
      "custom_code",
      "arxiv:2509.06501",
      "license:other",
      "eval-results",
      "endpoints_compatible",
      "fp8",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "briaai/Fibo-Edit",
    "task": "image-to-image",
    "library": "diffusers",
    "downloads": 1943,
    "likes": 47,
    "tags": [
      "diffusers",
      "safetensors",
      "art",
      "image-to-image",
      "image-editing",
      "inpainting",
      "en",
      "arxiv:2511.06876",
      "base_model:briaai/Fibo-Edit",
      "base_model:finetune:briaai/Fibo-Edit",
      "license:other",
      "diffusers:BriaFiboEditPipeline",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Linum-AI/linum-v2-720p",
    "task": "text-to-video",
    "library": "linum-v2",
    "downloads": 0,
    "likes": 46,
    "tags": [
      "linum-v2",
      "safetensors",
      "text-to-video",
      "video-generation",
      "diffusion",
      "dit",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "QuantFunc/Nunchaku-Qwen-Image-EDIT-2511",
    "task": "image-to-image",
    "library": "diffusers",
    "downloads": 4427,
    "likes": 46,
    "tags": [
      "diffusers",
      "custom_qwen_image",
      "image-generation",
      "multimodal",
      "qwen",
      "quantized",
      "nunchaku",
      "comfyui",
      "image-to-image",
      "en",
      "zh",
      "base_model:Qwen/Qwen-Image-Edit-2511",
      "base_model:quantized:Qwen/Qwen-Image-Edit-2511",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "openbmb/VoxCPM1.5",
    "task": "text-to-speech",
    "library": "voxcpm",
    "downloads": 4607,
    "likes": 338,
    "tags": [
      "voxcpm",
      "safetensors",
      "text-to-speech",
      "speech",
      "speech generation",
      "voice cloning",
      "en",
      "zh",
      "arxiv:2509.24650",
      "base_model:openbmb/MiniCPM4-0.5B",
      "base_model:finetune:openbmb/MiniCPM4-0.5B",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "deepseek-ai/DeepSeek-V3.2",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 229813,
    "likes": 1171,
    "tags": [
      "transformers",
      "safetensors",
      "deepseek_v32",
      "text-generation",
      "conversational",
      "base_model:deepseek-ai/DeepSeek-V3.2-Exp-Base",
      "base_model:finetune:deepseek-ai/DeepSeek-V3.2-Exp-Base",
      "license:mit",
      "endpoints_compatible",
      "fp8",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen-Image-Edit-2511",
    "task": "image-to-image",
    "library": "diffusers",
    "downloads": 118691,
    "likes": 761,
    "tags": [
      "diffusers",
      "safetensors",
      "image-to-image",
      "en",
      "zh",
      "arxiv:2508.02324",
      "license:apache-2.0",
      "diffusers:QwenImageEditPlusPipeline",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Kijai/LTXV2_comfy",
    "task": null,
    "library": null,
    "downloads": 101305,
    "likes": 352,
    "tags": [
      "gguf",
      "comfyui",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "huihui-ai/Huihui-GLM-4.7-Flash-abliterated",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 1545,
    "likes": 43,
    "tags": [
      "transformers",
      "safetensors",
      "glm4_moe_lite",
      "text-generation",
      "abliterated",
      "uncensored",
      "conversational",
      "en",
      "zh",
      "base_model:zai-org/GLM-4.7-Flash",
      "base_model:finetune:zai-org/GLM-4.7-Flash",
      "license:mit",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "mlx-community/GLM-4.7-Flash-4bit",
    "task": "text-generation",
    "library": "mlx",
    "downloads": 4999,
    "likes": 42,
    "tags": [
      "mlx",
      "safetensors",
      "glm4_moe_lite",
      "text-generation",
      "conversational",
      "en",
      "zh",
      "base_model:zai-org/GLM-4.7-Flash",
      "base_model:quantized:zai-org/GLM-4.7-Flash",
      "license:mit",
      "4-bit",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Supertone/supertonic-2",
    "task": "text-to-speech",
    "library": "supertonic",
    "downloads": 19618,
    "likes": 332,
    "tags": [
      "supertonic",
      "onnx",
      "text-to-speech",
      "speech-synthesis",
      "tts",
      "en",
      "ko",
      "es",
      "pt",
      "fr",
      "license:openrail",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "QuantFunc/Nunchaku-Qwen-Image-2512",
    "task": "text-to-image",
    "library": "diffusers",
    "downloads": 4079,
    "likes": 40,
    "tags": [
      "diffusers",
      "custom_qwen_image",
      "image-generation",
      "multimodal",
      "qwen",
      "quantized",
      "nunchaku",
      "comfyui",
      "text-to-image",
      "en",
      "zh",
      "base_model:Qwen/Qwen-Image-2512",
      "base_model:quantized:Qwen/Qwen-Image-2512",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "GadflyII/GLM-4.7-Flash-NVFP4",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 152768,
    "likes": 38,
    "tags": [
      "transformers",
      "safetensors",
      "glm4_moe_lite",
      "text-generation",
      "moe",
      "nvfp4",
      "quantized",
      "vllm",
      "glm",
      "30b",
      "conversational",
      "en",
      "zh",
      "base_model:zai-org/GLM-4.7-Flash",
      "base_model:quantized:zai-org/GLM-4.7-Flash",
      "license:apache-2.0",
      "endpoints_compatible",
      "8-bit",
      "compressed-tensors",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "stabilityai/stable-diffusion-xl-base-1.0",
    "task": "text-to-image",
    "library": "diffusers",
    "downloads": 1985844,
    "likes": 7367,
    "tags": [
      "diffusers",
      "onnx",
      "safetensors",
      "text-to-image",
      "stable-diffusion",
      "arxiv:2307.01952",
      "arxiv:2211.01324",
      "arxiv:2108.01073",
      "arxiv:2112.10752",
      "license:openrail++",
      "endpoints_compatible",
      "diffusers:StableDiffusionXLPipeline",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "LiquidAI/LFM2.5-Audio-1.5B",
    "task": "audio-to-audio",
    "library": "liquid-audio",
    "downloads": 2240,
    "likes": 303,
    "tags": [
      "liquid-audio",
      "safetensors",
      "liquid",
      "lfm2",
      "audio",
      "lfm2-audio",
      "speech-to-speech",
      "audio-to-audio",
      "en",
      "arxiv:2511.23404",
      "base_model:LiquidAI/LFM2-1.2B",
      "base_model:finetune:LiquidAI/LFM2-1.2B",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Phr00t/LTX2-Rapid-Merges",
    "task": "image-text-to-video",
    "library": null,
    "downloads": 0,
    "likes": 130,
    "tags": [
      "ltx2",
      "t2v",
      "i2v",
      "image-text-to-video",
      "base_model:Lightricks/LTX-2",
      "base_model:finetune:Lightricks/LTX-2",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "meta-llama/Llama-3.1-8B-Instruct",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 10135214,
    "likes": 5319,
    "tags": [
      "transformers",
      "safetensors",
      "llama",
      "text-generation",
      "facebook",
      "meta",
      "pytorch",
      "llama-3",
      "conversational",
      "en",
      "de",
      "fr",
      "it",
      "pt",
      "hi",
      "es",
      "th",
      "arxiv:2204.05149",
      "base_model:meta-llama/Llama-3.1-8B",
      "base_model:finetune:meta-llama/Llama-3.1-8B",
      "license:llama3.1",
      "eval-results",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "nvidia/nemotron-speech-streaming-en-0.6b",
    "task": "automatic-speech-recognition",
    "library": "nemo",
    "downloads": 8431,
    "likes": 430,
    "tags": [
      "nemo",
      "speech-recognition",
      "cache-aware ASR",
      "automatic-speech-recognition",
      "streaming-asr",
      "speech",
      "audio",
      "FastConformer",
      "RNNT",
      "Parakeet",
      "ASR",
      "pytorch",
      "NeMo",
      "dataset:nvidia/Granary",
      "dataset:YTC",
      "dataset:Yodas2",
      "dataset:LibriLight",
      "dataset:librispeech_asr",
      "dataset:fisher_corpus",
      "dataset:Switchboard-1",
      "dataset:WSJ-0",
      "dataset:WSJ-1",
      "dataset:National-Singapore-Corpus-Part-1",
      "dataset:National-Singapore-Corpus-Part-6",
      "dataset:vctk",
      "dataset:voxpopuli",
      "dataset:europarl",
      "dataset:multilingual_librispeech",
      "dataset:fleurs",
      "dataset:mozilla-foundation/common_voice_8_0",
      "dataset:MLCommons/peoples_speech",
      "dataset:google/speech_commands",
      "arxiv:2312.17279",
      "arxiv:2305.05084",
      "license:other",
      "model-index",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "black-forest-labs/FLUX.1-dev",
    "task": "text-to-image",
    "library": "diffusers",
    "downloads": 787220,
    "likes": 12203,
    "tags": [
      "diffusers",
      "safetensors",
      "text-to-image",
      "image-generation",
      "flux",
      "en",
      "license:other",
      "endpoints_compatible",
      "diffusers:FluxPipeline",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "black-forest-labs/FLUX.2-klein-9b-fp8",
    "task": "image-to-image",
    "library": "diffusers",
    "downloads": 24635,
    "likes": 70,
    "tags": [
      "diffusers",
      "image-generation",
      "image-editing",
      "flux",
      "diffusion-single-file",
      "image-to-image",
      "en",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Alissonerdx/BFS-Best-Face-Swap",
    "task": "image-to-image",
    "library": null,
    "downloads": 7379,
    "likes": 162,
    "tags": [
      "lora",
      "qwen-image-edit",
      "face-swap",
      "head-swap",
      "image-editing",
      "ai-generated",
      "comfyui",
      "bfs",
      "flux 2",
      "flux",
      "klein",
      "image-to-image",
      "en",
      "base_model:black-forest-labs/FLUX.2-klein-4B",
      "base_model:adapter:black-forest-labs/FLUX.2-klein-4B",
      "license:mit",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "black-forest-labs/FLUX.2-dev",
    "task": "image-to-image",
    "library": "diffusers",
    "downloads": 112127,
    "likes": 1283,
    "tags": [
      "diffusers",
      "safetensors",
      "image-generation",
      "image-editing",
      "flux",
      "diffusion-single-file",
      "image-to-image",
      "en",
      "license:other",
      "diffusers:Flux2Pipeline",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "hexgrad/Kokoro-82M",
    "task": "text-to-speech",
    "library": null,
    "downloads": 2092448,
    "likes": 5617,
    "tags": [
      "text-to-speech",
      "en",
      "arxiv:2306.07691",
      "arxiv:2203.02395",
      "base_model:yl4579/StyleTTS2-LJSpeech",
      "base_model:finetune:yl4579/StyleTTS2-LJSpeech",
      "doi:10.57967/hf/4329",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "cerebras/GLM-4.7-Flash-REAP-23B-A3B",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 1086,
    "likes": 32,
    "tags": [
      "transformers",
      "safetensors",
      "glm4_moe_lite",
      "text-generation",
      "glm",
      "MOE",
      "pruning",
      "compression",
      "conversational",
      "en",
      "arxiv:2510.13999",
      "base_model:zai-org/GLM-4.7-Flash",
      "base_model:finetune:zai-org/GLM-4.7-Flash",
      "license:mit",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "deepseek-ai/DeepSeek-OCR",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 3025224,
    "likes": 3115,
    "tags": [
      "transformers",
      "safetensors",
      "deepseek_vl_v2",
      "feature-extraction",
      "deepseek",
      "vision-language",
      "ocr",
      "custom_code",
      "image-text-to-text",
      "multilingual",
      "arxiv:2510.18234",
      "license:mit",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-TTS-Tokenizer-12Hz",
    "task": null,
    "library": null,
    "downloads": 11880,
    "likes": 31,
    "tags": [
      "safetensors",
      "qwen3_tts_tokenizer_12hz",
      "arxiv:2601.15621",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "openai/gpt-oss-120b",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 3009119,
    "likes": 4380,
    "tags": [
      "transformers",
      "safetensors",
      "gpt_oss",
      "text-generation",
      "vllm",
      "conversational",
      "arxiv:2508.10925",
      "license:apache-2.0",
      "endpoints_compatible",
      "8-bit",
      "mxfp4",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "kpsss34/FHDR_Uncensored",
    "task": "text-to-image",
    "library": "diffusers",
    "downloads": 4568,
    "likes": 63,
    "tags": [
      "diffusers",
      "safetensors",
      "gguf",
      "art",
      "text-to-image",
      "en",
      "base_model:black-forest-labs/FLUX.1-dev",
      "base_model:quantized:black-forest-labs/FLUX.1-dev",
      "license:other",
      "endpoints_compatible",
      "diffusers:FluxPipeline",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "dx8152/Qwen-Image-Edit-2511-Gaussian-Splash",
    "task": "image-to-image",
    "library": null,
    "downloads": 0,
    "likes": 132,
    "tags": [
      "lora",
      "image-to-image",
      "base_model:Qwen/Qwen-Image-Edit-2511",
      "base_model:adapter:Qwen/Qwen-Image-Edit-2511",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "black-forest-labs/FLUX.2-klein-base-9B",
    "task": "image-to-image",
    "library": "diffusers",
    "downloads": 23120,
    "likes": 134,
    "tags": [
      "diffusers",
      "safetensors",
      "image-generation",
      "image-editing",
      "flux",
      "diffusion-single-file",
      "image-to-image",
      "en",
      "license:other",
      "diffusers:Flux2KleinPipeline",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "bartowski/zai-org_GLM-4.7-Flash-GGUF",
    "task": "text-generation",
    "library": null,
    "downloads": 32979,
    "likes": 29,
    "tags": [
      "gguf",
      "text-generation",
      "en",
      "zh",
      "base_model:zai-org/GLM-4.7-Flash",
      "base_model:quantized:zai-org/GLM-4.7-Flash",
      "license:mit",
      "endpoints_compatible",
      "region:us",
      "imatrix",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "Kijai/WanVideo_comfy",
    "task": null,
    "library": "diffusion-single-file",
    "downloads": 6844673,
    "likes": 2041,
    "tags": [
      "diffusion-single-file",
      "comfyui",
      "base_model:Wan-AI/Wan2.1-VACE-1.3B",
      "base_model:finetune:Wan-AI/Wan2.1-VACE-1.3B",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "cyankiwi/GLM-4.7-Flash-AWQ-4bit",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 65028,
    "likes": 28,
    "tags": [
      "transformers",
      "safetensors",
      "glm4_moe_lite",
      "text-generation",
      "conversational",
      "en",
      "zh",
      "arxiv:2508.06471",
      "base_model:zai-org/GLM-4.7-Flash",
      "base_model:quantized:zai-org/GLM-4.7-Flash",
      "license:mit",
      "endpoints_compatible",
      "compressed-tensors",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "sentence-transformers/all-MiniLM-L6-v2",
    "task": "sentence-similarity",
    "library": "sentence-transformers",
    "downloads": 147643702,
    "likes": 4368,
    "tags": [
      "sentence-transformers",
      "pytorch",
      "tf",
      "rust",
      "onnx",
      "safetensors",
      "openvino",
      "bert",
      "feature-extraction",
      "sentence-similarity",
      "transformers",
      "en",
      "dataset:s2orc",
      "dataset:flax-sentence-embeddings/stackexchange_xml",
      "dataset:ms_marco",
      "dataset:gooaq",
      "dataset:yahoo_answers_topics",
      "dataset:code_search_net",
      "dataset:search_qa",
      "dataset:eli5",
      "dataset:snli",
      "dataset:multi_nli",
      "dataset:wikihow",
      "dataset:natural_questions",
      "dataset:trivia_qa",
      "dataset:embedding-data/sentence-compression",
      "dataset:embedding-data/flickr30k-captions",
      "dataset:embedding-data/altlex",
      "dataset:embedding-data/simple-wiki",
      "dataset:embedding-data/QQP",
      "dataset:embedding-data/SPECTER",
      "dataset:embedding-data/PAQ_pairs",
      "dataset:embedding-data/WikiAnswers",
      "arxiv:1904.06472",
      "arxiv:2102.07033",
      "arxiv:2104.08727",
      "arxiv:1704.05179",
      "arxiv:1810.09305",
      "license:apache-2.0",
      "text-embeddings-inference",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "LGAI-EXAONE/K-EXAONE-236B-A23B",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 13034,
    "likes": 519,
    "tags": [
      "transformers",
      "safetensors",
      "exaone_moe",
      "text-generation",
      "lg-ai",
      "exaone",
      "k-exaone",
      "conversational",
      "en",
      "ko",
      "es",
      "de",
      "ja",
      "vi",
      "arxiv:2601.01739",
      "license:other",
      "eval-results",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "thilina/mt5-sinhalese-english",
    "task": "translation",
    "library": "transformers",
    "downloads": 189,
    "likes": 65,
    "tags": [
      "transformers",
      "pytorch",
      "tf",
      "mt5",
      "text2text-generation",
      "translation",
      "si",
      "en",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "nvidia/parakeet-tdt-0.6b-v3",
    "task": "automatic-speech-recognition",
    "library": "nemo",
    "downloads": 84121,
    "likes": 580,
    "tags": [
      "nemo",
      "automatic-speech-recognition",
      "speech",
      "audio",
      "Transducer",
      "TDT",
      "FastConformer",
      "Conformer",
      "pytorch",
      "NeMo",
      "hf-asr-leaderboard",
      "en",
      "es",
      "fr",
      "de",
      "bg",
      "hr",
      "cs",
      "da",
      "nl",
      "et",
      "fi",
      "el",
      "hu",
      "it",
      "lv",
      "lt",
      "mt",
      "pl",
      "pt",
      "ro",
      "sk",
      "sl",
      "sv",
      "ru",
      "uk",
      "dataset:nvidia/Granary",
      "dataset:nemo/asr-set-3.0",
      "arxiv:2509.14128",
      "arxiv:2505.13404",
      "arxiv:2305.05084",
      "arxiv:2304.06795",
      "arxiv:2410.01036",
      "arxiv:2406.00899",
      "arxiv:2205.12446",
      "arxiv:2012.03411",
      "arxiv:2007.10310",
      "arxiv:1510.08484",
      "license:cc-by-4.0",
      "model-index",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "openai/gpt-oss-20b",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 6659981,
    "likes": 4242,
    "tags": [
      "transformers",
      "safetensors",
      "gpt_oss",
      "text-generation",
      "vllm",
      "conversational",
      "arxiv:2508.10925",
      "license:apache-2.0",
      "endpoints_compatible",
      "8-bit",
      "mxfp4",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Octen/Octen-Embedding-8B",
    "task": "sentence-similarity",
    "library": "sentence-transformers",
    "downloads": 6918,
    "likes": 57,
    "tags": [
      "sentence-transformers",
      "safetensors",
      "qwen3",
      "sentence-similarity",
      "feature-extraction",
      "embedding",
      "text-embedding",
      "retrieval",
      "en",
      "zh",
      "multilingual",
      "base_model:Qwen/Qwen3-Embedding-8B",
      "base_model:finetune:Qwen/Qwen3-Embedding-8B",
      "license:apache-2.0",
      "text-embeddings-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "iitolstykh/VIBE-Image-Edit",
    "task": "image-to-image",
    "library": "diffusers",
    "downloads": 486,
    "likes": 83,
    "tags": [
      "diffusers",
      "safetensors",
      "image-editing",
      "text-guided-editing",
      "diffusion",
      "sana",
      "qwen-vl",
      "multimodal",
      "image-to-image",
      "en",
      "arxiv:2601.02242",
      "base_model:Efficient-Large-Model/SANA1.5_1.6B_1024px",
      "base_model:finetune:Efficient-Large-Model/SANA1.5_1.6B_1024px",
      "diffusers:VIBESanaEditingPipeline",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Comfy-Org/vae-text-encorder-for-flux-klein-9b",
    "task": null,
    "library": null,
    "downloads": 0,
    "likes": 78,
    "tags": [
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "google/functiongemma-270m-it",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 90502,
    "likes": 851,
    "tags": [
      "transformers",
      "safetensors",
      "gemma3_text",
      "text-generation",
      "gemma3",
      "gemma",
      "google",
      "functiongemma",
      "conversational",
      "license:gemma",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "unsloth/FLUX.2-klein-9B-GGUF",
    "task": "image-to-image",
    "library": "ggml",
    "downloads": 35572,
    "likes": 60,
    "tags": [
      "ggml",
      "gguf",
      "image-generation",
      "unsloth",
      "image-editing",
      "flux",
      "diffusion-single-file",
      "image-to-image",
      "en",
      "base_model:black-forest-labs/FLUX.2-klein-9B",
      "base_model:quantized:black-forest-labs/FLUX.2-klein-9B",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "LiquidAI/LFM2.5-1.2B-Thinking-GGUF",
    "task": "text-generation",
    "library": null,
    "downloads": 16634,
    "likes": 25,
    "tags": [
      "gguf",
      "liquid",
      "lfm2.5",
      "edge",
      "llama.cpp",
      "text-generation",
      "en",
      "ar",
      "zh",
      "fr",
      "de",
      "ja",
      "ko",
      "es",
      "base_model:LiquidAI/LFM2.5-1.2B-Thinking",
      "base_model:quantized:LiquidAI/LFM2.5-1.2B-Thinking",
      "license:other",
      "endpoints_compatible",
      "region:us",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-Coder-30B-A3B-Instruct",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 478257,
    "likes": 894,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3_moe",
      "text-generation",
      "conversational",
      "arxiv:2505.09388",
      "license:apache-2.0",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "microsoft/VibeVoice-1.5B",
    "task": "text-to-speech",
    "library": "transformers",
    "downloads": 326661,
    "likes": 2186,
    "tags": [
      "transformers",
      "safetensors",
      "vibevoice",
      "text-generation",
      "Podcast",
      "text-to-speech",
      "en",
      "zh",
      "arxiv:2508.19205",
      "arxiv:2412.08635",
      "license:mit",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "nvidia/Alpamayo-R1-10B",
    "task": "robotics",
    "library": "transformers",
    "downloads": 35228,
    "likes": 333,
    "tags": [
      "transformers",
      "safetensors",
      "alpamayo_r1",
      "robotics",
      "dataset:nvidia/PhysicalAI-Autonomous-Vehicles",
      "dataset:nvidia/PhysicalAI-Autonomous-Vehicles-NuRec",
      "arxiv:2511.00088",
      "license:other",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "lodestones/Chroma2-Kaleidoscope",
    "task": "text-to-image",
    "library": null,
    "downloads": 0,
    "likes": 24,
    "tags": [
      "text-to-image",
      "base_model:black-forest-labs/FLUX.2-klein-base-4B",
      "base_model:finetune:black-forest-labs/FLUX.2-klein-base-4B",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "lightonai/LightOnOCR-1B-1025",
    "task": "image-to-text",
    "library": "transformers",
    "downloads": 39587,
    "likes": 218,
    "tags": [
      "transformers",
      "safetensors",
      "mistral3",
      "text-generation",
      "ocr",
      "document-understanding",
      "vision-language",
      "pdf",
      "tables",
      "forms",
      "image-to-text",
      "en",
      "fr",
      "de",
      "es",
      "it",
      "nl",
      "pt",
      "sv",
      "da",
      "arxiv:2601.14251",
      "arxiv:2412.13663",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:eu"
    ],
    "description": ""
  },
  {
    "id": "FunAudioLLM/Fun-CosyVoice3-0.5B-2512",
    "task": "text-to-speech",
    "library": null,
    "downloads": 4280,
    "likes": 424,
    "tags": [
      "onnx",
      "safetensors",
      "text-to-speech",
      "zh",
      "en",
      "fr",
      "es",
      "ja",
      "ko",
      "it",
      "ru",
      "de",
      "arxiv:2505.17589",
      "arxiv:2412.10117",
      "arxiv:2407.05407",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "unsloth/GLM-4.7-GGUF",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 128129,
    "likes": 184,
    "tags": [
      "transformers",
      "gguf",
      "text-generation",
      "en",
      "zh",
      "arxiv:2508.06471",
      "base_model:zai-org/GLM-4.7",
      "base_model:quantized:zai-org/GLM-4.7",
      "license:mit",
      "endpoints_compatible",
      "region:us",
      "imatrix",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-VL-Embedding-2B",
    "task": "feature-extraction",
    "library": "transformers",
    "downloads": 151910,
    "likes": 271,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3_vl",
      "image-to-text",
      "multimodal embedding",
      "qwen",
      "embedding",
      "feature-extraction",
      "arxiv:2601.04720",
      "base_model:Qwen/Qwen3-VL-2B-Instruct",
      "base_model:finetune:Qwen/Qwen3-VL-2B-Instruct",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "meituan-longcat/LongCat-Flash-Thinking-2601",
    "task": "text-generation",
    "library": "LongCat-Flash-Thinking-2601",
    "downloads": 1607,
    "likes": 89,
    "tags": [
      "LongCat-Flash-Thinking-2601",
      "safetensors",
      "transformers",
      "text-generation",
      "conversational",
      "custom_code",
      "license:mit",
      "eval-results",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "openbmb/AgentCPM-Report-GGUF",
    "task": null,
    "library": null,
    "downloads": 449,
    "likes": 23,
    "tags": [
      "gguf",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-VL-8B-Instruct",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 2006799,
    "likes": 683,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3_vl",
      "image-to-text",
      "image-text-to-text",
      "conversational",
      "arxiv:2505.09388",
      "arxiv:2502.13923",
      "arxiv:2409.12191",
      "arxiv:2308.12966",
      "license:apache-2.0",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Arunk25/Qwen-Image-Edit-Rapid-AIO-GGUF",
    "task": "image-text-to-image",
    "library": null,
    "downloads": 84203,
    "likes": 131,
    "tags": [
      "gguf",
      "image-text-to-image",
      "base_model:Phr00t/Qwen-Image-Edit-Rapid-AIO",
      "base_model:quantized:Phr00t/Qwen-Image-Edit-Rapid-AIO",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "google/medasr",
    "task": "automatic-speech-recognition",
    "library": "transformers",
    "downloads": 10710,
    "likes": 267,
    "tags": [
      "transformers",
      "safetensors",
      "lasr_ctc",
      "medical-asr",
      "radiology",
      "medical",
      "automatic-speech-recognition",
      "en",
      "arxiv:2005.08100",
      "arxiv:2304.13134",
      "arxiv:2309.08105",
      "license:other",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "NousResearch/NousCoder-14B",
    "task": "text-generation",
    "library": null,
    "downloads": 2057,
    "likes": 177,
    "tags": [
      "safetensors",
      "qwen3",
      "text-generation",
      "conversational",
      "dataset:livecodebench/code_generation_lite",
      "dataset:agentica-org/DeepCoder-Preview-Dataset",
      "dataset:NousResearch/lcb_test",
      "dataset:NousResearch/RLVR_Coding_Problems",
      "base_model:Qwen/Qwen3-14B",
      "base_model:finetune:Qwen/Qwen3-14B",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "fal/flux-2-klein-4b-spritesheet-lora",
    "task": "image-to-image",
    "library": null,
    "downloads": 0,
    "likes": 22,
    "tags": [
      "flux",
      "flux-2-klein",
      "flux-lora",
      "lora",
      "sprite-sheet",
      "game-asset",
      "2x2-grid",
      "multi-view",
      "isometric",
      "top-down",
      "side-view",
      "image-to-image",
      "fal-ai",
      "template:diffusion-lora",
      "en",
      "base_model:black-forest-labs/FLUX.2-klein-4B",
      "base_model:adapter:black-forest-labs/FLUX.2-klein-4B",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "BAAI/bge-m3",
    "task": "sentence-similarity",
    "library": "sentence-transformers",
    "downloads": 9801678,
    "likes": 2677,
    "tags": [
      "sentence-transformers",
      "pytorch",
      "onnx",
      "xlm-roberta",
      "feature-extraction",
      "sentence-similarity",
      "arxiv:2402.03216",
      "arxiv:2004.04906",
      "arxiv:2106.14807",
      "arxiv:2107.05720",
      "arxiv:2004.12832",
      "license:mit",
      "text-embeddings-inference",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-0.6B",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 8517029,
    "likes": 1004,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "conversational",
      "arxiv:2505.09388",
      "base_model:Qwen/Qwen3-0.6B-Base",
      "base_model:finetune:Qwen/Qwen3-0.6B-Base",
      "license:apache-2.0",
      "text-generation-inference",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "PaddlePaddle/PaddleOCR-VL",
    "task": "image-text-to-text",
    "library": "PaddleOCR",
    "downloads": 15613,
    "likes": 1509,
    "tags": [
      "PaddleOCR",
      "safetensors",
      "paddleocr_vl",
      "ERNIE4.5",
      "PaddlePaddle",
      "image-to-text",
      "ocr",
      "document-parse",
      "layout",
      "table",
      "formula",
      "chart",
      "image-text-to-text",
      "conversational",
      "custom_code",
      "en",
      "zh",
      "multilingual",
      "arxiv:2510.14528",
      "base_model:baidu/ERNIE-4.5-0.3B-Paddle",
      "base_model:finetune:baidu/ERNIE-4.5-0.3B-Paddle",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen-Image-2512",
    "task": "text-to-image",
    "library": "diffusers",
    "downloads": 135927,
    "likes": 624,
    "tags": [
      "diffusers",
      "safetensors",
      "text-to-image",
      "en",
      "zh",
      "arxiv:2508.02324",
      "license:apache-2.0",
      "diffusers:QwenImagePipeline",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "stepfun-ai/Step3-VL-10B-Base",
    "task": "image-text-to-text",
    "library": null,
    "downloads": 8758,
    "likes": 44,
    "tags": [
      "safetensors",
      "step_robotics",
      "image-text-to-text",
      "custom_code",
      "arxiv:2601.09668",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "meituan-longcat/LongCat-Flash-Thinking-ZigZag",
    "task": "text-generation",
    "library": "LongCat-Flash-Thinking-ZigZag",
    "downloads": 17,
    "likes": 21,
    "tags": [
      "LongCat-Flash-Thinking-ZigZag",
      "safetensors",
      "transformers",
      "text-generation",
      "conversational",
      "custom_code",
      "arxiv:2512.23966",
      "license:mit",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "openai/whisper-large-v3",
    "task": "automatic-speech-recognition",
    "library": "transformers",
    "downloads": 6258653,
    "likes": 5334,
    "tags": [
      "transformers",
      "pytorch",
      "jax",
      "safetensors",
      "whisper",
      "automatic-speech-recognition",
      "audio",
      "hf-asr-leaderboard",
      "en",
      "zh",
      "de",
      "es",
      "ru",
      "ko",
      "fr",
      "ja",
      "pt",
      "tr",
      "pl",
      "ca",
      "nl",
      "ar",
      "sv",
      "it",
      "id",
      "hi",
      "fi",
      "vi",
      "he",
      "uk",
      "el",
      "ms",
      "cs",
      "ro",
      "da",
      "hu",
      "ta",
      "no",
      "th",
      "ur",
      "hr",
      "bg",
      "lt",
      "la",
      "mi",
      "ml",
      "cy",
      "sk",
      "te",
      "fa",
      "lv",
      "bn",
      "sr",
      "az",
      "sl",
      "kn",
      "et",
      "mk",
      "br",
      "eu",
      "is",
      "hy",
      "ne",
      "mn",
      "bs",
      "kk",
      "sq",
      "sw",
      "gl",
      "mr",
      "pa",
      "si",
      "km",
      "sn",
      "yo",
      "so",
      "af",
      "oc",
      "ka",
      "be",
      "tg",
      "sd",
      "gu",
      "am",
      "yi",
      "lo",
      "uz",
      "fo",
      "ht",
      "ps",
      "tk",
      "nn",
      "mt",
      "sa",
      "lb",
      "my",
      "bo",
      "tl",
      "mg",
      "as",
      "tt",
      "haw",
      "ln",
      "ha",
      "ba",
      "jw",
      "su",
      "arxiv:2212.04356",
      "license:apache-2.0",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "tencent/Hunyuan3D-2.1",
    "task": "image-to-3d",
    "library": "hunyuan3d-2",
    "downloads": 21302,
    "likes": 840,
    "tags": [
      "hunyuan3d-2",
      "diffusers",
      "safetensors",
      "image-to-3d",
      "text-to-3d",
      "en",
      "zh",
      "arxiv:2506.15442",
      "arxiv:2501.12202",
      "arxiv:2411.02293",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "XiaomiMiMo/MiMo-V2-Flash",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 62888,
    "likes": 600,
    "tags": [
      "transformers",
      "safetensors",
      "mimo_v2_flash",
      "text-generation",
      "conversational",
      "custom_code",
      "license:mit",
      "fp8",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "lilylilith/AnyPose",
    "task": "image-to-image",
    "library": "diffusers",
    "downloads": 37158,
    "likes": 401,
    "tags": [
      "diffusers",
      "LoRA",
      "lora",
      "Qwen-Image-Edit",
      "Qwen-Image",
      "image-to-image",
      "base_model:Qwen/Qwen-Image-Edit-2511",
      "base_model:adapter:Qwen/Qwen-Image-Edit-2511",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "fal/FLUX.2-dev-Turbo",
    "task": "text-to-image",
    "library": "diffusers",
    "downloads": 17393,
    "likes": 312,
    "tags": [
      "diffusers",
      "image-generation",
      "flux",
      "lora",
      "distillation",
      "turbo",
      "text-to-image",
      "en",
      "base_model:black-forest-labs/FLUX.2-dev",
      "base_model:adapter:black-forest-labs/FLUX.2-dev",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-VL-Embedding-8B",
    "task": "feature-extraction",
    "library": "transformers",
    "downloads": 105717,
    "likes": 298,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3_vl",
      "image-to-text",
      "multimodal embedding",
      "qwen",
      "embedding",
      "feature-extraction",
      "arxiv:2601.04720",
      "base_model:Qwen/Qwen3-VL-8B-Instruct",
      "base_model:finetune:Qwen/Qwen3-VL-8B-Instruct",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-VL-Reranker-2B",
    "task": "text-ranking",
    "library": "transformers",
    "downloads": 81264,
    "likes": 153,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3_vl",
      "image-to-text",
      "multimodal rerank",
      "text rerank",
      "text-ranking",
      "arxiv:2601.04720",
      "base_model:Qwen/Qwen3-VL-2B-Instruct",
      "base_model:finetune:Qwen/Qwen3-VL-2B-Instruct",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "unsloth/LTX-2-GGUF",
    "task": "image-to-video",
    "library": "ggml",
    "downloads": 22429,
    "likes": 78,
    "tags": [
      "ggml",
      "gguf",
      "image-to-video",
      "unsloth",
      "text-to-video",
      "video-to-video",
      "image-text-to-video",
      "audio-to-video",
      "text-to-audio",
      "video-to-audio",
      "audio-to-audio",
      "text-to-audio-video",
      "image-to-audio-video",
      "image-text-to-audio-video",
      "ltx-2",
      "ltx-video",
      "ltxv",
      "lightricks",
      "en",
      "de",
      "es",
      "fr",
      "ja",
      "ko",
      "zh",
      "it",
      "pt",
      "arxiv:2601.03233",
      "base_model:Lightricks/LTX-2",
      "base_model:quantized:Lightricks/LTX-2",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "cyrildiagne/flux2-klein9b-lora-mlsharp-3d-repair",
    "task": null,
    "library": "ml-sharp",
    "downloads": 0,
    "likes": 20,
    "tags": [
      "ml-sharp",
      "flux",
      "flux2",
      "klein",
      "mlsharp",
      "camera",
      "gaussian-splats",
      "dataset:DL3DV/DL3DV-ALL-2K",
      "base_model:black-forest-labs/FLUX.2-klein-base-9B",
      "base_model:finetune:black-forest-labs/FLUX.2-klein-base-9B",
      "license:cc-by-nc-4.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "ResembleAI/chatterbox",
    "task": "text-to-speech",
    "library": "chatterbox",
    "downloads": 575141,
    "likes": 1444,
    "tags": [
      "chatterbox",
      "text-to-speech",
      "speech",
      "speech-generation",
      "voice-cloning",
      "multilingual-tts",
      "ar",
      "da",
      "de",
      "el",
      "en",
      "es",
      "fi",
      "fr",
      "he",
      "hi",
      "it",
      "ja",
      "ko",
      "ms",
      "nl",
      "no",
      "pl",
      "pt",
      "ru",
      "sv",
      "sw",
      "tr",
      "zh",
      "license:mit",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "google/gemma-3n-E2B-it-litert-lm",
    "task": "text-generation",
    "library": "litert-lm",
    "downloads": 19377,
    "likes": 300,
    "tags": [
      "litert-lm",
      "text-generation",
      "arxiv:1905.07830",
      "arxiv:1905.10044",
      "arxiv:1911.11641",
      "arxiv:1904.09728",
      "arxiv:1705.03551",
      "arxiv:1911.01547",
      "arxiv:1907.10641",
      "arxiv:1903.00161",
      "arxiv:2210.03057",
      "arxiv:2502.12404",
      "arxiv:2411.19799",
      "arxiv:2009.03300",
      "arxiv:2502.21228",
      "arxiv:2311.12022",
      "arxiv:2403.07974",
      "arxiv:2108.07732",
      "arxiv:2107.03374",
      "license:gemma",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "IndexTeam/IndexTTS-2",
    "task": "text-to-speech",
    "library": null,
    "downloads": 18924,
    "likes": 613,
    "tags": [
      "safetensors",
      "text-to-speech",
      "en",
      "zh",
      "arxiv:2506.21619",
      "arxiv:2502.05512",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "rednote-hilab/dots.ocr",
    "task": "image-text-to-text",
    "library": "dots_ocr",
    "downloads": 245143,
    "likes": 1215,
    "tags": [
      "dots_ocr",
      "safetensors",
      "text-generation",
      "image-to-text",
      "ocr",
      "document-parse",
      "layout",
      "table",
      "formula",
      "transformers",
      "custom_code",
      "image-text-to-text",
      "conversational",
      "en",
      "zh",
      "multilingual",
      "license:mit",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Phr00t/WAN2.2-14B-Rapid-AllInOne",
    "task": "image-to-video",
    "library": "wan2.2",
    "downloads": 0,
    "likes": 1374,
    "tags": [
      "wan2.2",
      "wan",
      "accelerator",
      "image-to-video",
      "base_model:Wan-AI/Wan2.2-I2V-A14B",
      "base_model:finetune:Wan-AI/Wan2.2-I2V-A14B",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "LiquidAI/LFM2.5-1.2B-Instruct-GGUF",
    "task": "text-generation",
    "library": null,
    "downloads": 36496,
    "likes": 115,
    "tags": [
      "gguf",
      "liquid",
      "lfm2.5",
      "edge",
      "llama.cpp",
      "text-generation",
      "en",
      "ar",
      "zh",
      "fr",
      "de",
      "ja",
      "ko",
      "es",
      "base_model:LiquidAI/LFM2.5-1.2B-Instruct",
      "base_model:quantized:LiquidAI/LFM2.5-1.2B-Instruct",
      "license:other",
      "endpoints_compatible",
      "region:us",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "zilliz/semantic-highlight-bilingual-v1",
    "task": "token-classification",
    "library": null,
    "downloads": 1951,
    "likes": 71,
    "tags": [
      "safetensors",
      "open_provence",
      "RAG",
      "highlight",
      "context-pruning",
      "context-engineering",
      "semantic-highlight",
      "token-classification",
      "custom_code",
      "zh",
      "en",
      "dataset:zilliz/msmarco-context-relevance-with-think",
      "dataset:zilliz/natural_questions-context-relevance-with-think",
      "dataset:zilliz/gooaq-context-relevance-130k-context-relevance-with-think",
      "dataset:zilliz/wikipedia_zh_cn_500k-context-relevance-with-think",
      "dataset:zilliz/mmarco_chinese_200k-context-relevance-with-think",
      "dataset:zilliz/dureader-context-relevance-with-think",
      "arxiv:2501.16214",
      "arxiv:2402.03216",
      "base_model:BAAI/bge-reranker-v2-m3",
      "base_model:finetune:BAAI/bge-reranker-v2-m3",
      "license:mit",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "HeartMuLa/HeartMuLaGen",
    "task": "text-to-audio",
    "library": null,
    "downloads": 0,
    "likes": 21,
    "tags": [
      "music",
      "art",
      "text-to-audio",
      "zh",
      "en",
      "ja",
      "ko",
      "es",
      "arxiv:2601.10547",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "fal/flux-2-klein-4B-outpaint-lora",
    "task": "image-to-image",
    "library": null,
    "downloads": 0,
    "likes": 19,
    "tags": [
      "flux",
      "flux-2-klein",
      "flux-lora",
      "lora",
      "outpainting",
      "image-extension",
      "green-screen",
      "inpainting",
      "image-to-image",
      "fal-ai",
      "template:diffusion-lora",
      "en",
      "base_model:black-forest-labs/FLUX.2-klein-4B",
      "base_model:adapter:black-forest-labs/FLUX.2-klein-4B",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "ngxson/GLM-4.7-Flash-GGUF",
    "task": null,
    "library": null,
    "downloads": 10732,
    "likes": 19,
    "tags": [
      "gguf",
      "base_model:zai-org/GLM-4.7-Flash",
      "base_model:quantized:zai-org/GLM-4.7-Flash",
      "endpoints_compatible",
      "region:us",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "coqui/XTTS-v2",
    "task": "text-to-speech",
    "library": "coqui",
    "downloads": 5612257,
    "likes": 3343,
    "tags": [
      "coqui",
      "text-to-speech",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "pyannote/speaker-diarization-3.1",
    "task": "automatic-speech-recognition",
    "library": "pyannote-audio",
    "downloads": 13310141,
    "likes": 1460,
    "tags": [
      "pyannote-audio",
      "pyannote",
      "pyannote-audio-pipeline",
      "audio",
      "voice",
      "speech",
      "speaker",
      "speaker-diarization",
      "speaker-change-detection",
      "voice-activity-detection",
      "overlapped-speech-detection",
      "automatic-speech-recognition",
      "arxiv:2111.14448",
      "arxiv:2012.01477",
      "license:mit",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "black-forest-labs/FLUX.1-schnell",
    "task": "text-to-image",
    "library": "diffusers",
    "downloads": 623062,
    "likes": 4562,
    "tags": [
      "diffusers",
      "safetensors",
      "text-to-image",
      "image-generation",
      "flux",
      "en",
      "license:apache-2.0",
      "endpoints_compatible",
      "diffusers:FluxPipeline",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen-Image-Edit",
    "task": "image-to-image",
    "library": "diffusers",
    "downloads": 44847,
    "likes": 2285,
    "tags": [
      "diffusers",
      "safetensors",
      "image-to-image",
      "en",
      "zh",
      "arxiv:2508.02324",
      "license:apache-2.0",
      "diffusers:QwenImageEditPipeline",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "unsloth/FLUX.2-klein-4B-GGUF",
    "task": "image-to-image",
    "library": "ggml",
    "downloads": 19200,
    "likes": 60,
    "tags": [
      "ggml",
      "gguf",
      "text-to-image",
      "unsloth",
      "image-editing",
      "flux",
      "diffusion-single-file",
      "image-to-image",
      "en",
      "base_model:black-forest-labs/FLUX.2-klein-4B",
      "base_model:quantized:black-forest-labs/FLUX.2-klein-4B",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "google/gemma-3-27b-it",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 1479920,
    "likes": 1830,
    "tags": [
      "transformers",
      "safetensors",
      "gemma3",
      "image-to-text",
      "image-text-to-text",
      "conversational",
      "arxiv:1905.07830",
      "arxiv:1905.10044",
      "arxiv:1911.11641",
      "arxiv:1904.09728",
      "arxiv:1705.03551",
      "arxiv:1911.01547",
      "arxiv:1907.10641",
      "arxiv:1903.00161",
      "arxiv:2009.03300",
      "arxiv:2304.06364",
      "arxiv:2103.03874",
      "arxiv:2110.14168",
      "arxiv:2311.12022",
      "arxiv:2108.07732",
      "arxiv:2107.03374",
      "arxiv:2210.03057",
      "arxiv:2106.03193",
      "arxiv:1910.11856",
      "arxiv:2502.12404",
      "arxiv:2502.21228",
      "arxiv:2404.16816",
      "arxiv:2104.12756",
      "arxiv:2311.16502",
      "arxiv:2203.10244",
      "arxiv:2404.12390",
      "arxiv:1810.12440",
      "arxiv:1908.02660",
      "arxiv:2312.11805",
      "base_model:google/gemma-3-27b-pt",
      "base_model:finetune:google/gemma-3-27b-pt",
      "license:gemma",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-4B-Instruct-2507",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 2949303,
    "likes": 663,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "conversational",
      "arxiv:2505.09388",
      "license:apache-2.0",
      "text-generation-inference",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "DiffSynth-Studio/Qwen-Image-Edit-F2P",
    "task": "image-to-image",
    "library": "diffusers",
    "downloads": 6487,
    "likes": 88,
    "tags": [
      "diffusers",
      "lora",
      "image-to-image",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "moonshotai/Kimi-K2-Thinking",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 246047,
    "likes": 1636,
    "tags": [
      "transformers",
      "safetensors",
      "kimi_k2",
      "text-generation",
      "conversational",
      "custom_code",
      "license:other",
      "eval-results",
      "endpoints_compatible",
      "compressed-tensors",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 370575,
    "likes": 592,
    "tags": [
      "transformers",
      "safetensors",
      "nemotron_h",
      "feature-extraction",
      "nvidia",
      "pytorch",
      "text-generation",
      "conversational",
      "custom_code",
      "en",
      "es",
      "fr",
      "de",
      "ja",
      "it",
      "dataset:nvidia/Nemotron-Pretraining-Code-v1",
      "dataset:nvidia/Nemotron-CC-v2",
      "dataset:nvidia/Nemotron-Pretraining-SFT-v1",
      "dataset:nvidia/Nemotron-CC-Math-v1",
      "dataset:nvidia/Nemotron-Pretraining-Code-v2",
      "dataset:nvidia/Nemotron-Pretraining-Specialized-v1",
      "dataset:nvidia/Nemotron-CC-v2.1",
      "dataset:nvidia/Nemotron-CC-Code-v1",
      "dataset:nvidia/Nemotron-Pretraining-Dataset-sample",
      "dataset:nvidia/Nemotron-Competitive-Programming-v1",
      "dataset:nvidia/Nemotron-Math-v2",
      "dataset:nvidia/Nemotron-Agentic-v1",
      "dataset:nvidia/Nemotron-Math-Proofs-v1",
      "dataset:nvidia/Nemotron-Instruction-Following-Chat-v1",
      "dataset:nvidia/Nemotron-Science-v1",
      "dataset:nvidia/Nemotron-3-Nano-RL-Training-Blend",
      "arxiv:2512.20848",
      "arxiv:2512.20856",
      "license:other",
      "eval-results",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen-Image-Layered",
    "task": "image-text-to-image",
    "library": "diffusers",
    "downloads": 16351,
    "likes": 973,
    "tags": [
      "diffusers",
      "safetensors",
      "image-text-to-image",
      "en",
      "zh",
      "arxiv:2512.15603",
      "base_model:Qwen/Qwen-Image",
      "base_model:finetune:Qwen/Qwen-Image",
      "license:apache-2.0",
      "diffusers:QwenImageLayeredPipeline",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "salakash/AskBuddyX",
    "task": "text-generation",
    "library": "mlx-lm",
    "downloads": 358,
    "likes": 28,
    "tags": [
      "mlx-lm",
      "qwen2",
      "code",
      "coding-assistant",
      "lora",
      "mlx",
      "apple-silicon",
      "qwen2.5",
      "text-generation",
      "en",
      "dataset:flwrlabs/code-alpaca-20k",
      "dataset:m-a-p/Code-Feedback",
      "base_model:Qwen/Qwen2.5-Coder-0.5B-Instruct",
      "base_model:adapter:Qwen/Qwen2.5-Coder-0.5B-Instruct",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "microsoft/FrogMini-14B-2510",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 381,
    "likes": 58,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "conversational",
      "arxiv:2510.19898",
      "base_model:Qwen/Qwen3-14B",
      "base_model:finetune:Qwen/Qwen3-14B",
      "license:mit",
      "text-generation-inference",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "facebook/ShapeR",
    "task": null,
    "library": null,
    "downloads": 188,
    "likes": 32,
    "tags": [
      "3d-reconstruction",
      "3d-generation",
      "arxiv:2601.11514",
      "license:cc-by-nc-4.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "fal/flux-2-klein-4B-zoom-lora",
    "task": "image-to-image",
    "library": null,
    "downloads": 0,
    "likes": 17,
    "tags": [
      "flux",
      "flux-2-klein",
      "flux-lora",
      "lora",
      "zoom",
      "image-enhancement",
      "red-highlight",
      "image-to-image",
      "fal-ai",
      "template:diffusion-lora",
      "en",
      "base_model:black-forest-labs/FLUX.2-klein-4B",
      "base_model:adapter:black-forest-labs/FLUX.2-klein-4B",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "marksverdhei/GLM-4.7-Flash-FP8",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 16162,
    "likes": 17,
    "tags": [
      "transformers",
      "safetensors",
      "glm4_moe_lite",
      "text-generation",
      "fp8",
      "quantized",
      "glm4",
      "moe",
      "conversational",
      "base_model:zai-org/GLM-4.7-Flash",
      "base_model:quantized:zai-org/GLM-4.7-Flash",
      "license:mit",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "nvidia/Qwen3-8B-DMS-8x",
    "task": null,
    "library": "transformers",
    "downloads": 301,
    "likes": 17,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "nvidia",
      "pytorch",
      "kvcache",
      "custom_code",
      "dataset:open-r1/OpenR1-Math-220k",
      "arxiv:2506.05345",
      "arxiv:2505.09388",
      "arxiv:2305.20050",
      "arxiv:2107.03374",
      "arxiv:2311.07911",
      "base_model:Qwen/Qwen3-8B",
      "base_model:finetune:Qwen/Qwen3-8B",
      "license:other",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "noctrex/GLM-4.7-Flash-MXFP4_MOE-GGUF",
    "task": "text-generation",
    "library": null,
    "downloads": 8548,
    "likes": 17,
    "tags": [
      "gguf",
      "text-generation",
      "base_model:zai-org/GLM-4.7-Flash",
      "base_model:quantized:zai-org/GLM-4.7-Flash",
      "endpoints_compatible",
      "region:us",
      "imatrix",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "meta-llama/Llama-3.2-1B-Instruct",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 2778762,
    "likes": 1267,
    "tags": [
      "transformers",
      "safetensors",
      "llama",
      "text-generation",
      "facebook",
      "meta",
      "pytorch",
      "llama-3",
      "conversational",
      "en",
      "de",
      "fr",
      "it",
      "pt",
      "hi",
      "es",
      "th",
      "arxiv:2204.05149",
      "arxiv:2405.16406",
      "license:llama3.2",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "deepseek-ai/DeepSeek-R1",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 384161,
    "likes": 12968,
    "tags": [
      "transformers",
      "safetensors",
      "deepseek_v3",
      "text-generation",
      "conversational",
      "custom_code",
      "arxiv:2501.12948",
      "license:mit",
      "eval-results",
      "text-generation-inference",
      "endpoints_compatible",
      "fp8",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "microsoft/VibeVoice-Realtime-0.5B",
    "task": "text-to-speech",
    "library": "transformers",
    "downloads": 289783,
    "likes": 1071,
    "tags": [
      "transformers",
      "safetensors",
      "vibevoice_streaming",
      "Realtime TTS",
      "Streaming text input",
      "Long-form speech generation",
      "text-to-speech",
      "en",
      "arxiv:2508.19205",
      "arxiv:2412.08635",
      "base_model:Qwen/Qwen2.5-0.5B",
      "base_model:finetune:Qwen/Qwen2.5-0.5B",
      "license:mit",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "prithivMLmods/Qwen-Image-Edit-2511-Unblur-Upscale",
    "task": "image-to-image",
    "library": "diffusers",
    "downloads": 9043,
    "likes": 73,
    "tags": [
      "diffusers",
      "lora",
      "art",
      "image-to-image",
      "en",
      "base_model:Qwen/Qwen-Image-Edit-2511",
      "base_model:adapter:Qwen/Qwen-Image-Edit-2511",
      "doi:10.57967/hf/7521",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "nvidia/parakeet-ctc-0.6b-Vietnamese",
    "task": "automatic-speech-recognition",
    "library": "nemo",
    "downloads": 154,
    "likes": 16,
    "tags": [
      "nemo",
      "Nemo",
      "ASR",
      "Pytorch",
      "FastConformer",
      "Parakeet",
      "CTC",
      "automatic-speech-recognition",
      "audio",
      "speech",
      "vi",
      "arxiv:2305.05084",
      "arxiv:2005.08100",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "BennyDaBall/Qwen3-4b-Z-Image-Engineer-V2.5",
    "task": null,
    "library": null,
    "downloads": 2679,
    "likes": 18,
    "tags": [
      "gguf",
      "image-generation",
      "prompt-engineering",
      "qwen",
      "photography",
      "base_model:Tongyi-MAI/Z-Image-Turbo",
      "base_model:quantized:Tongyi-MAI/Z-Image-Turbo",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "mistralai/Mistral-7B-Instruct-v0.3",
    "task": null,
    "library": "vllm",
    "downloads": 907186,
    "likes": 2364,
    "tags": [
      "vllm",
      "safetensors",
      "mistral",
      "mistral-common",
      "base_model:mistralai/Mistral-7B-v0.3",
      "base_model:finetune:mistralai/Mistral-7B-v0.3",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "google/gemma-3-4b-it",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 835276,
    "likes": 1121,
    "tags": [
      "transformers",
      "safetensors",
      "gemma3",
      "image-to-text",
      "image-text-to-text",
      "conversational",
      "arxiv:1905.07830",
      "arxiv:1905.10044",
      "arxiv:1911.11641",
      "arxiv:1904.09728",
      "arxiv:1705.03551",
      "arxiv:1911.01547",
      "arxiv:1907.10641",
      "arxiv:1903.00161",
      "arxiv:2009.03300",
      "arxiv:2304.06364",
      "arxiv:2103.03874",
      "arxiv:2110.14168",
      "arxiv:2311.12022",
      "arxiv:2108.07732",
      "arxiv:2107.03374",
      "arxiv:2210.03057",
      "arxiv:2106.03193",
      "arxiv:1910.11856",
      "arxiv:2502.12404",
      "arxiv:2502.21228",
      "arxiv:2404.16816",
      "arxiv:2104.12756",
      "arxiv:2311.16502",
      "arxiv:2203.10244",
      "arxiv:2404.12390",
      "arxiv:1810.12440",
      "arxiv:1908.02660",
      "arxiv:2312.11805",
      "base_model:google/gemma-3-4b-pt",
      "base_model:finetune:google/gemma-3-4b-pt",
      "license:gemma",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-FP8",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 729677,
    "likes": 262,
    "tags": [
      "transformers",
      "safetensors",
      "nemotron_h",
      "feature-extraction",
      "nvidia",
      "pytorch",
      "text-generation",
      "conversational",
      "custom_code",
      "en",
      "es",
      "fr",
      "de",
      "ja",
      "it",
      "dataset:nvidia/Nemotron-Pretraining-Code-v1",
      "dataset:nvidia/Nemotron-CC-v2",
      "dataset:nvidia/Nemotron-Pretraining-SFT-v1",
      "dataset:nvidia/Nemotron-CC-Math-v1",
      "dataset:nvidia/Nemotron-Pretraining-Code-v2",
      "dataset:nvidia/Nemotron-Pretraining-Specialized-v1",
      "dataset:nvidia/Nemotron-CC-v2.1",
      "dataset:nvidia/Nemotron-CC-Code-v1",
      "dataset:nvidia/Nemotron-Pretraining-Dataset-sample",
      "dataset:nvidia/Nemotron-Competitive-Programming-v1",
      "dataset:nvidia/Nemotron-Math-v2",
      "dataset:nvidia/Nemotron-Agentic-v1",
      "dataset:nvidia/Nemotron-Math-Proofs-v1",
      "dataset:nvidia/Nemotron-Instruction-Following-Chat-v1",
      "dataset:nvidia/Nemotron-Science-v1",
      "dataset:nvidia/Nemotron-3-Nano-RL-Training-Blend",
      "arxiv:2512.20848",
      "arxiv:2512.20856",
      "base_model:nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16",
      "base_model:quantized:nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "RomixERR/Pornmaster_v1-Z-Images-Turbo",
    "task": "text-to-image",
    "library": "diffusers",
    "downloads": 2533,
    "likes": 19,
    "tags": [
      "diffusers",
      "text-to-image",
      "lora",
      "template:diffusion-lora",
      "base_model:Tongyi-MAI/Z-Image-Turbo",
      "base_model:adapter:Tongyi-MAI/Z-Image-Turbo",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "YatharthS/NovaSR",
    "task": "audio-to-audio",
    "library": null,
    "downloads": 558,
    "likes": 68,
    "tags": [
      "pytorch",
      "audio-to-audio",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "HeartMuLa/HeartCodec-oss",
    "task": "text-to-audio",
    "library": null,
    "downloads": 7125,
    "likes": 15,
    "tags": [
      "safetensors",
      "heartcodec",
      "music",
      "art",
      "text-to-audio",
      "zh",
      "en",
      "ja",
      "ko",
      "es",
      "arxiv:2601.10547",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "kakaocorp/kanana-2-30b-a3b-thinking-2601",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 1128,
    "likes": 54,
    "tags": [
      "transformers",
      "safetensors",
      "deepseek_v3",
      "text-generation",
      "conversational",
      "base_model:kakaocorp/kanana-2-30b-a3b-mid-2601",
      "base_model:finetune:kakaocorp/kanana-2-30b-a3b-mid-2601",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "mlx-community/GLM-4.7-Flash-8bit",
    "task": "text-generation",
    "library": "mlx",
    "downloads": 4357,
    "likes": 15,
    "tags": [
      "mlx",
      "safetensors",
      "glm4_moe_lite",
      "text-generation",
      "conversational",
      "en",
      "zh",
      "base_model:zai-org/GLM-4.7-Flash",
      "base_model:quantized:zai-org/GLM-4.7-Flash",
      "license:mit",
      "8-bit",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "fal/flux-2-klein-4B-background-remove-lora",
    "task": "image-to-image",
    "library": null,
    "downloads": 0,
    "likes": 15,
    "tags": [
      "flux",
      "flux-2-klein",
      "flux-lora",
      "lora",
      "background-removal",
      "subject-isolation",
      "image-editing",
      "image-to-image",
      "fal-ai",
      "template:diffusion-lora",
      "en",
      "base_model:black-forest-labs/FLUX.2-klein-4B",
      "base_model:adapter:black-forest-labs/FLUX.2-klein-4B",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Overworld/Waypoint-1-Medium",
    "task": null,
    "library": null,
    "downloads": 0,
    "likes": 15,
    "tags": [
      "WM",
      "Diffusion",
      "Egocentric",
      "en",
      "license:cc-by-nc-sa-4.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "DavidAU/GLM-4.7-Flash-Uncensored-Heretic-NEO-CODE-Imatrix-MAX-GGUF",
    "task": "text-generation",
    "library": null,
    "downloads": 18456,
    "likes": 15,
    "tags": [
      "gguf",
      "GLM 4.7 Flash",
      "thinking",
      "reasoning",
      "NEO Imatrix",
      "MAX Quants",
      "16 bit precision output tensor",
      "heretic",
      "uncensored",
      "abliterated",
      "deep reasoning",
      "fine tune",
      "creative",
      "creative writing",
      "fiction writing",
      "plot generation",
      "sub-plot generation",
      "story generation",
      "scene continue",
      "storytelling",
      "fiction story",
      "science fiction",
      "romance",
      "all genres",
      "story",
      "writing",
      "vivid prosing",
      "vivid writing",
      "fiction",
      "roleplaying",
      "bfloat16",
      "swearing",
      "rp",
      "horror",
      "text-generation",
      "en",
      "zh",
      "base_model:Olafangensan/GLM-4.7-Flash-heretic",
      "base_model:quantized:Olafangensan/GLM-4.7-Flash-heretic",
      "license:mit",
      "endpoints_compatible",
      "region:us",
      "imatrix",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "rootsautomation/GutenOCR-7B",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 30,
    "likes": 15,
    "tags": [
      "transformers",
      "safetensors",
      "qwen2_5_vl",
      "image-to-text",
      "ocr",
      "vision",
      "qwen2.5-vl",
      "pdf",
      "document-understanding",
      "image-text-to-text",
      "conversational",
      "en",
      "arxiv:2601.14490",
      "base_model:Qwen/Qwen2.5-VL-7B-Instruct",
      "base_model:finetune:Qwen/Qwen2.5-VL-7B-Instruct",
      "license:cc-by-nc-4.0",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "HeartMuLa/HeartMuLa-RL-oss-3B-20260123",
    "task": null,
    "library": null,
    "downloads": 1574,
    "likes": 15,
    "tags": [
      "safetensors",
      "heartmula",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "kyutai/moshiko-pytorch-bf16",
    "task": null,
    "library": "moshi",
    "downloads": 113161,
    "likes": 213,
    "tags": [
      "moshi",
      "safetensors",
      "en",
      "license:cc-by-4.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "openai/whisper-large-v3-turbo",
    "task": "automatic-speech-recognition",
    "library": "transformers",
    "downloads": 2788847,
    "likes": 2784,
    "tags": [
      "transformers",
      "safetensors",
      "whisper",
      "automatic-speech-recognition",
      "audio",
      "en",
      "zh",
      "de",
      "es",
      "ru",
      "ko",
      "fr",
      "ja",
      "pt",
      "tr",
      "pl",
      "ca",
      "nl",
      "ar",
      "sv",
      "it",
      "id",
      "hi",
      "fi",
      "vi",
      "he",
      "uk",
      "el",
      "ms",
      "cs",
      "ro",
      "da",
      "hu",
      "ta",
      "no",
      "th",
      "ur",
      "hr",
      "bg",
      "lt",
      "la",
      "mi",
      "ml",
      "cy",
      "sk",
      "te",
      "fa",
      "lv",
      "bn",
      "sr",
      "az",
      "sl",
      "kn",
      "et",
      "mk",
      "br",
      "eu",
      "is",
      "hy",
      "ne",
      "mn",
      "bs",
      "kk",
      "sq",
      "sw",
      "gl",
      "mr",
      "pa",
      "si",
      "km",
      "sn",
      "yo",
      "so",
      "af",
      "oc",
      "ka",
      "be",
      "tg",
      "sd",
      "gu",
      "am",
      "yi",
      "lo",
      "uz",
      "fo",
      "ht",
      "ps",
      "tk",
      "nn",
      "mt",
      "sa",
      "lb",
      "my",
      "bo",
      "tl",
      "mg",
      "as",
      "tt",
      "haw",
      "ln",
      "ha",
      "ba",
      "jw",
      "su",
      "arxiv:2212.04356",
      "base_model:openai/whisper-large-v3",
      "base_model:finetune:openai/whisper-large-v3",
      "license:mit",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-1.7B",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 3536474,
    "likes": 401,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "conversational",
      "arxiv:2505.09388",
      "base_model:Qwen/Qwen3-1.7B-Base",
      "base_model:finetune:Qwen/Qwen3-1.7B-Base",
      "license:apache-2.0",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "unsloth/Qwen3-Coder-30B-A3B-Instruct-GGUF",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 103506,
    "likes": 408,
    "tags": [
      "transformers",
      "gguf",
      "unsloth",
      "qwen3",
      "qwen",
      "text-generation",
      "arxiv:2505.09388",
      "base_model:Qwen/Qwen3-Coder-30B-A3B-Instruct",
      "base_model:quantized:Qwen/Qwen3-Coder-30B-A3B-Instruct",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us",
      "imatrix",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-VL-30B-A3B-Instruct",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 753206,
    "likes": 516,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3_vl_moe",
      "image-to-text",
      "image-text-to-text",
      "conversational",
      "arxiv:2505.09388",
      "arxiv:2502.13923",
      "arxiv:2409.12191",
      "arxiv:2308.12966",
      "license:apache-2.0",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "nphSi/Z-Image-Lora",
    "task": "text-to-image",
    "library": "diffusers",
    "downloads": 12124,
    "likes": 20,
    "tags": [
      "diffusers",
      "text-to-image",
      "lora",
      "safetensors",
      "template:diffusion-lora",
      "z-image",
      "dataset:nphSi/LoRa_Datasets",
      "base_model:ostris/Z-Image-De-Turbo",
      "base_model:adapter:ostris/Z-Image-De-Turbo",
      "license:creativeml-openrail-m",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "ResembleAI/chatterbox-turbo",
    "task": "text-to-speech",
    "library": null,
    "downloads": 0,
    "likes": 578,
    "tags": [
      "text-to-speech",
      "speech",
      "speech-generation",
      "voice-cloning",
      "en",
      "license:mit",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "zai-org/GLM-4.6V-Flash",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 119807,
    "likes": 563,
    "tags": [
      "transformers",
      "safetensors",
      "glm4v",
      "image-to-text",
      "image-text-to-text",
      "conversational",
      "zh",
      "en",
      "arxiv:2507.01006",
      "license:mit",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "FutureMa/Eva-4B",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 689,
    "likes": 95,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "finance",
      "earnings-calls",
      "financial-nlp",
      "text-classification",
      "llm-as-judge",
      "distillation",
      "conversational",
      "en",
      "arxiv:2601.09142",
      "base_model:Qwen/Qwen3-4B-Instruct-2507",
      "base_model:finetune:Qwen/Qwen3-4B-Instruct-2507",
      "license:apache-2.0",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "TeichAI/GLM-4.7-Flash-Claude-Opus-4.5-High-Reasoning-Distill-GGUF",
    "task": null,
    "library": null,
    "downloads": 4222,
    "likes": 14,
    "tags": [
      "gguf",
      "text-generation-inference",
      "llama.cpp",
      "unsloth",
      "glm4_moe_lite",
      "dataset:TeichAI/claude-4.5-opus-high-reasoning-250x",
      "base_model:TeichAI/GLM-4.7-Flash-Claude-Opus-4.5-High-Reasoning-Distill",
      "base_model:quantized:TeichAI/GLM-4.7-Flash-Claude-Opus-4.5-High-Reasoning-Distill",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "openai-community/gpt2",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 7082312,
    "likes": 3096,
    "tags": [
      "transformers",
      "pytorch",
      "tf",
      "jax",
      "tflite",
      "rust",
      "onnx",
      "safetensors",
      "gpt2",
      "text-generation",
      "exbert",
      "en",
      "doi:10.57967/hf/0039",
      "license:mit",
      "text-generation-inference",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "fishaudio/fish-speech-1.5",
    "task": "text-to-speech",
    "library": null,
    "downloads": 2846,
    "likes": 680,
    "tags": [
      "dual_ar",
      "text-to-speech",
      "zh",
      "en",
      "de",
      "ja",
      "fr",
      "es",
      "ko",
      "ar",
      "nl",
      "ru",
      "it",
      "pl",
      "pt",
      "arxiv:2411.01156",
      "license:cc-by-nc-sa-4.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-8B",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 4198263,
    "likes": 874,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "conversational",
      "arxiv:2309.00071",
      "arxiv:2505.09388",
      "base_model:Qwen/Qwen3-8B-Base",
      "base_model:finetune:Qwen/Qwen3-8B-Base",
      "license:apache-2.0",
      "text-generation-inference",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-Embedding-0.6B",
    "task": "feature-extraction",
    "library": "sentence-transformers",
    "downloads": 2014165,
    "likes": 841,
    "tags": [
      "sentence-transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "transformers",
      "sentence-similarity",
      "feature-extraction",
      "text-embeddings-inference",
      "arxiv:2506.05176",
      "base_model:Qwen/Qwen3-0.6B-Base",
      "base_model:finetune:Qwen/Qwen3-0.6B-Base",
      "license:apache-2.0",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "tencent/HunyuanVideo-1.5",
    "task": "text-to-video",
    "library": "HunyuanVideo-1.5",
    "downloads": 426908,
    "likes": 698,
    "tags": [
      "HunyuanVideo-1.5",
      "diffusers",
      "safetensors",
      "text-to-video",
      "image-to-video",
      "en",
      "zh",
      "arxiv:2511.18870",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "SandboxAQ/AQAffinity",
    "task": null,
    "library": null,
    "downloads": 0,
    "likes": 13,
    "tags": [
      "chemistry",
      "biology",
      "protein",
      "ligand",
      "binding",
      "affinity",
      "binding affinity",
      "drug discovery",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "unsloth/Nemotron-3-Nano-30B-A3B-GGUF",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 102897,
    "likes": 233,
    "tags": [
      "transformers",
      "gguf",
      "nvidia",
      "unsloth",
      "text-generation",
      "en",
      "es",
      "fr",
      "de",
      "ja",
      "it",
      "dataset:nvidia/Nemotron-Pretraining-Code-v1",
      "dataset:nvidia/Nemotron-CC-v2",
      "dataset:nvidia/Nemotron-Pretraining-SFT-v1",
      "dataset:nvidia/Nemotron-CC-Math-v1",
      "dataset:nvidia/Nemotron-Pretraining-Code-v2",
      "dataset:nvidia/Nemotron-Pretraining-Specialized-v1",
      "dataset:nvidia/Nemotron-CC-v2.1",
      "dataset:nvidia/Nemotron-CC-Code-v1",
      "dataset:nvidia/Nemotron-Pretraining-Dataset-sample",
      "dataset:nvidia/Nemotron-Competitive-Programming-v1",
      "dataset:nvidia/Nemotron-Math-v2",
      "dataset:nvidia/Nemotron-Agentic-v1",
      "dataset:nvidia/Nemotron-Math-Proofs-v1",
      "dataset:nvidia/Nemotron-Instruction-Following-Chat-v1",
      "dataset:nvidia/Nemotron-Science-v1",
      "dataset:nvidia/Nemotron-3-Nano-RL-Training-Blend",
      "base_model:nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16",
      "base_model:quantized:nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16",
      "license:other",
      "endpoints_compatible",
      "region:us",
      "imatrix",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "lightx2v/Qwen-Image-Edit-2511-Lightning",
    "task": "image-to-image",
    "library": "diffusers",
    "downloads": 422889,
    "likes": 344,
    "tags": [
      "diffusers",
      "safetensors",
      "diffusion-single-file",
      "comfyui",
      "distillation",
      "LoRA",
      "lora",
      "Qwen-Image",
      "Qwen-Image-Edit",
      "image-to-image",
      "base_model:Qwen/Qwen-Image-Edit-2511",
      "base_model:adapter:Qwen/Qwen-Image-Edit-2511",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "unsloth/MiniMax-M2.1-GGUF",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 146631,
    "likes": 156,
    "tags": [
      "transformers",
      "gguf",
      "unsloth",
      "text-generation",
      "arxiv:2509.06501",
      "base_model:MiniMaxAI/MiniMax-M2.1",
      "base_model:quantized:MiniMaxAI/MiniMax-M2.1",
      "license:other",
      "endpoints_compatible",
      "region:us",
      "imatrix",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "voyageai/voyage-4-nano",
    "task": "feature-extraction",
    "library": "sentence-transformers",
    "downloads": 16516,
    "likes": 41,
    "tags": [
      "sentence-transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "transformers",
      "feature-extraction",
      "custom_code",
      "multilingual",
      "license:apache-2.0",
      "text-embeddings-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "allenai/HiRO-ACE",
    "task": null,
    "library": "fme",
    "downloads": 0,
    "likes": 13,
    "tags": [
      "fme",
      "arxiv:2512.18224",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "kakaocorp/kanana-2-30b-a3b-instruct-2601",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 467,
    "likes": 52,
    "tags": [
      "transformers",
      "safetensors",
      "deepseek_v3",
      "text-generation",
      "conversational",
      "base_model:kakaocorp/kanana-2-30b-a3b-mid-2601",
      "base_model:finetune:kakaocorp/kanana-2-30b-a3b-mid-2601",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Comfy-Org/vae-text-encorder-for-flux-klein-4b",
    "task": null,
    "library": null,
    "downloads": 0,
    "likes": 44,
    "tags": [
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "ag14850/Mosquito",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 0,
    "likes": 13,
    "tags": [
      "transformers",
      "pytorch",
      "t5",
      "question-answering",
      "knowledge",
      "tiny",
      "efficient",
      "edge",
      "mobile",
      "distillation",
      "iot",
      "text2text-generation",
      "en",
      "base_model:google/t5-v1_1-base",
      "base_model:finetune:google/t5-v1_1-base",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "lilylilith/QIE-2511-MP-AnyLight",
    "task": "image-to-image",
    "library": "diffusers",
    "downloads": 702,
    "likes": 13,
    "tags": [
      "diffusers",
      "LoRA",
      "lora",
      "Qwen-Image-Edit",
      "Qwen-Image",
      "image-to-image",
      "base_model:Qwen/Qwen-Image-Edit-2511",
      "base_model:adapter:Qwen/Qwen-Image-Edit-2511",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "meta-llama/Llama-3.1-8B",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 2574281,
    "likes": 2036,
    "tags": [
      "transformers",
      "safetensors",
      "llama",
      "text-generation",
      "facebook",
      "meta",
      "pytorch",
      "llama-3",
      "en",
      "de",
      "fr",
      "it",
      "pt",
      "hi",
      "es",
      "th",
      "arxiv:2204.05149",
      "license:llama3.1",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen2.5-7B-Instruct",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 7181311,
    "likes": 1024,
    "tags": [
      "transformers",
      "safetensors",
      "qwen2",
      "text-generation",
      "chat",
      "conversational",
      "en",
      "arxiv:2309.00071",
      "arxiv:2407.10671",
      "base_model:Qwen/Qwen2.5-7B",
      "base_model:finetune:Qwen/Qwen2.5-7B",
      "license:apache-2.0",
      "text-generation-inference",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "stabilityai/stable-diffusion-3.5-large",
    "task": "text-to-image",
    "library": "diffusers",
    "downloads": 83559,
    "likes": 3330,
    "tags": [
      "diffusers",
      "safetensors",
      "text-to-image",
      "stable-diffusion",
      "en",
      "arxiv:2403.03206",
      "license:other",
      "diffusers:StableDiffusion3Pipeline",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "litert-community/Gemma3-1B-IT",
    "task": "text-generation",
    "library": "litert-lm",
    "downloads": 21484,
    "likes": 486,
    "tags": [
      "litert-lm",
      "chat",
      "text-generation",
      "license:gemma",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "google/medgemma-4b-it",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 411320,
    "likes": 857,
    "tags": [
      "transformers",
      "safetensors",
      "gemma3",
      "image-to-text",
      "medical",
      "radiology",
      "clinical-reasoning",
      "dermatology",
      "pathology",
      "ophthalmology",
      "chest-x-ray",
      "image-text-to-text",
      "conversational",
      "arxiv:2303.15343",
      "arxiv:2507.05201",
      "arxiv:2405.03162",
      "arxiv:2106.14463",
      "arxiv:2412.03555",
      "arxiv:2501.19393",
      "arxiv:2009.13081",
      "arxiv:2102.09542",
      "arxiv:2411.15640",
      "arxiv:2404.05590",
      "arxiv:2501.18362",
      "base_model:google/medgemma-4b-pt",
      "base_model:finetune:google/medgemma-4b-pt",
      "license:other",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "google/gemma-3n-E4B-it-litert-lm",
    "task": "text-generation",
    "library": "litert-lm",
    "downloads": 19912,
    "likes": 297,
    "tags": [
      "litert-lm",
      "text-generation",
      "arxiv:1905.07830",
      "arxiv:1905.10044",
      "arxiv:1911.11641",
      "arxiv:1904.09728",
      "arxiv:1705.03551",
      "arxiv:1911.01547",
      "arxiv:1907.10641",
      "arxiv:1903.00161",
      "arxiv:2210.03057",
      "arxiv:2502.12404",
      "arxiv:2411.19799",
      "arxiv:2009.03300",
      "arxiv:2502.21228",
      "arxiv:2311.12022",
      "arxiv:2403.07974",
      "arxiv:2108.07732",
      "arxiv:2107.03374",
      "license:gemma",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "DavidAU/OpenAi-GPT-oss-20b-abliterated-uncensored-NEO-Imatrix-gguf",
    "task": "text-generation",
    "library": null,
    "downloads": 106048,
    "likes": 413,
    "tags": [
      "gguf",
      "gpt_oss",
      "gpt-oss",
      "openai",
      "mxfp4",
      "programming",
      "code generation",
      "code",
      "coding",
      "coder",
      "chat",
      "reasoning",
      "thinking",
      "r1",
      "cot",
      "deepseek",
      "128k context",
      "general usage",
      "problem solving",
      "brainstorming",
      "solve riddles",
      "uncensored",
      "abliterated",
      "Neo",
      "MOE",
      "Mixture of Experts",
      "24 experts",
      "NEO Imatrix",
      "Imatrix",
      "DI-Matrix",
      "Tri-Matrix",
      "text-generation",
      "en",
      "base_model:huihui-ai/Huihui-gpt-oss-20b-BF16-abliterated",
      "base_model:quantized:huihui-ai/Huihui-gpt-oss-20b-BF16-abliterated",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us",
      "imatrix",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "lodestones/Chroma1-Radiance",
    "task": null,
    "library": null,
    "downloads": 0,
    "likes": 137,
    "tags": [
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Jonny001/Qwen-Image-Edit-Remove-Clothes",
    "task": "image-to-image",
    "library": "diffusers",
    "downloads": 5333,
    "likes": 34,
    "tags": [
      "diffusers",
      "image-generation",
      "lora",
      "Qwen-Image",
      "image-to-image",
      "en",
      "base_model:Qwen/Qwen-Image-Edit",
      "base_model:adapter:Qwen/Qwen-Image-Edit",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Wan-AI/Wan2.2-Animate-14B",
    "task": "video-to-video",
    "library": "diffusers",
    "downloads": 67063,
    "likes": 995,
    "tags": [
      "diffusers",
      "onnx",
      "safetensors",
      "video-to-video",
      "arxiv:2503.20314",
      "base_model:Wan-AI/Wan2.2-I2V-A14B",
      "base_model:quantized:Wan-AI/Wan2.2-I2V-A14B",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Prior-Labs/tabpfn_2_5",
    "task": "tabular-classification",
    "library": null,
    "downloads": 106617,
    "likes": 136,
    "tags": [
      "chemistry",
      "biology",
      "finance",
      "legal",
      "climate",
      "medical",
      "tabular-classification",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "allenai/Molmo2-8B",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 64481,
    "likes": 132,
    "tags": [
      "transformers",
      "safetensors",
      "molmo2",
      "image-to-text",
      "multimodal",
      "olmo",
      "molmo",
      "image-text-to-text",
      "conversational",
      "custom_code",
      "en",
      "dataset:allenai/Molmo2-Cap",
      "dataset:allenai/Molmo2-VideoCapQA",
      "dataset:allenai/Molmo2-VideoSubtitleQA",
      "dataset:allenai/Molmo2-AskModelAnything",
      "dataset:allenai/Molmo2-VideoPoint",
      "dataset:allenai/Molmo2-VideoTrack",
      "dataset:allenai/Molmo2-MultiImageQA",
      "dataset:allenai/Molmo2-SynMultiImageQA",
      "dataset:allenai/Molmo2-MultiImagePoint",
      "base_model:Qwen/Qwen3-8B",
      "base_model:finetune:Qwen/Qwen3-8B",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  }
]