[
  {
    "id": "zai-org/GLM-5",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 128078,
    "likes": 1205,
    "tags": [
      "transformers",
      "safetensors",
      "glm_moe_dsa",
      "text-generation",
      "conversational",
      "en",
      "zh",
      "license:mit",
      "eval-results",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "MiniMaxAI/MiniMax-M2.5",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 11092,
    "likes": 616,
    "tags": [
      "transformers",
      "safetensors",
      "minimax_m2",
      "text-generation",
      "conversational",
      "custom_code",
      "license:other",
      "eval-results",
      "endpoints_compatible",
      "fp8",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "openbmb/MiniCPM-SALA",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 2986,
    "likes": 443,
    "tags": [
      "transformers",
      "safetensors",
      "minicpm_sala",
      "text-generation",
      "conversational",
      "custom_code",
      "zh",
      "en",
      "arxiv:2509.24663",
      "arxiv:2601.22156",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Nanbeige/Nanbeige4.1-3B",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 11129,
    "likes": 424,
    "tags": [
      "transformers",
      "safetensors",
      "llama",
      "text-generation",
      "llm",
      "nanbeige",
      "conversational",
      "en",
      "zh",
      "base_model:Nanbeige/Nanbeige4-3B-Base",
      "base_model:finetune:Nanbeige/Nanbeige4-3B-Base",
      "license:apache-2.0",
      "eval-results",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "moonshotai/Kimi-K2.5",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 756817,
    "likes": 2187,
    "tags": [
      "transformers",
      "safetensors",
      "kimi_k25",
      "feature-extraction",
      "compressed-tensors",
      "image-text-to-text",
      "conversational",
      "custom_code",
      "arxiv:2602.02276",
      "license:other",
      "eval-results",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "zai-org/GLM-OCR",
    "task": "image-to-text",
    "library": "transformers",
    "downloads": 855997,
    "likes": 1048,
    "tags": [
      "transformers",
      "safetensors",
      "glm_ocr",
      "image-text-to-text",
      "image-to-text",
      "zh",
      "en",
      "fr",
      "es",
      "ru",
      "de",
      "ja",
      "ko",
      "license:mit",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-Coder-Next",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 270983,
    "likes": 870,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3_next",
      "text-generation",
      "conversational",
      "license:apache-2.0",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "openbmb/MiniCPM-o-4_5",
    "task": "any-to-any",
    "library": "transformers",
    "downloads": 45216,
    "likes": 847,
    "tags": [
      "transformers",
      "onnx",
      "safetensors",
      "minicpmo",
      "feature-extraction",
      "minicpm-o",
      "minicpm-v",
      "multimodal",
      "full-duplex",
      "any-to-any",
      "custom_code",
      "arxiv:2408.01800",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "inclusionAI/Ming-flash-omni-2.0",
    "task": "any-to-any",
    "library": "diffusers",
    "downloads": 6303,
    "likes": 212,
    "tags": [
      "diffusers",
      "onnx",
      "safetensors",
      "bailingmm_moe_v2_lite",
      "any-to-any",
      "custom_code",
      "en",
      "arxiv:2506.09344",
      "arxiv:2510.24821",
      "license:mit",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "OpenMOSS-Team/MOSS-TTS",
    "task": "text-to-speech",
    "library": null,
    "downloads": 5784,
    "likes": 191,
    "tags": [
      "safetensors",
      "moss_tts_delay",
      "text-to-speech",
      "custom_code",
      "zh",
      "en",
      "de",
      "es",
      "fr",
      "ja",
      "it",
      "he",
      "ko",
      "ru",
      "fa",
      "ar",
      "pl",
      "pt",
      "cs",
      "da",
      "sv",
      "hu",
      "el",
      "tr",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "inclusionAI/Ring-2.5-1T",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 1762,
    "likes": 174,
    "tags": [
      "transformers",
      "safetensors",
      "bailing_hybrid",
      "text-generation",
      "conversational",
      "custom_code",
      "license:mit",
      "compressed-tensors",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "ACE-Step/Ace-Step1.5",
    "task": "text-to-audio",
    "library": "transformers",
    "downloads": 37048,
    "likes": 554,
    "tags": [
      "transformers",
      "diffusers",
      "safetensors",
      "acestep",
      "feature-extraction",
      "audio",
      "music",
      "text2music",
      "text-to-audio",
      "custom_code",
      "arxiv:2602.00744",
      "license:mit",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "unsloth/GLM-5-GGUF",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 31276,
    "likes": 153,
    "tags": [
      "transformers",
      "gguf",
      "unsloth",
      "glm_moe_dsa",
      "text-generation",
      "en",
      "zh",
      "base_model:zai-org/GLM-5",
      "base_model:quantized:zai-org/GLM-5",
      "license:mit",
      "endpoints_compatible",
      "region:us",
      "imatrix",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "mistralai/Voxtral-Mini-4B-Realtime-2602",
    "task": "automatic-speech-recognition",
    "library": "vllm",
    "downloads": 5992,
    "likes": 532,
    "tags": [
      "vllm",
      "mistral-common",
      "automatic-speech-recognition",
      "en",
      "fr",
      "es",
      "de",
      "ru",
      "zh",
      "ja",
      "it",
      "pt",
      "nl",
      "ar",
      "hi",
      "ko",
      "arxiv:2602.11298",
      "base_model:mistralai/Ministral-3-3B-Base-2512",
      "base_model:finetune:mistralai/Ministral-3-3B-Base-2512",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "stepfun-ai/Step-3.5-Flash",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 281905,
    "likes": 613,
    "tags": [
      "transformers",
      "safetensors",
      "step3p5",
      "text-generation",
      "conversational",
      "custom_code",
      "arxiv:2602.10604",
      "arxiv:2601.05593",
      "arxiv:2507.19427",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "circlestone-labs/Anima",
    "task": null,
    "library": "diffusion-single-file",
    "downloads": 132786,
    "likes": 602,
    "tags": [
      "diffusion-single-file",
      "comfyui",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "nvidia/personaplex-7b-v1",
    "task": "audio-to-audio",
    "library": "moshi",
    "downloads": 330082,
    "likes": 1841,
    "tags": [
      "moshi",
      "safetensors",
      "personaplex",
      "speech-to-speech",
      "audio-to-audio",
      "en",
      "arxiv:2602.06053",
      "arxiv:2503.04721",
      "arxiv:2110.13900",
      "arxiv:2410.00037",
      "base_model:kyutai/moshiko-pytorch-bf16",
      "base_model:finetune:kyutai/moshiko-pytorch-bf16",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "unsloth/Qwen3-Coder-Next-GGUF",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 316285,
    "likes": 318,
    "tags": [
      "transformers",
      "gguf",
      "qwen3_next",
      "unsloth",
      "qwen",
      "qwen3",
      "text-generation",
      "base_model:Qwen/Qwen3-Coder-Next",
      "base_model:quantized:Qwen/Qwen3-Coder-Next",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us",
      "imatrix",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "inference-net/Schematron-3B",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 4557,
    "likes": 310,
    "tags": [
      "transformers",
      "safetensors",
      "llama",
      "text-generation",
      "conversational",
      "base_model:meta-llama/Llama-3.2-3B-Instruct",
      "base_model:finetune:meta-llama/Llama-3.2-3B-Instruct",
      "license:llama3.2",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "UCSB-SURFI/VulnLLM-R-7B",
    "task": "text-generation",
    "library": null,
    "downloads": 4023,
    "likes": 158,
    "tags": [
      "safetensors",
      "qwen2",
      "security",
      "vulnerability-detection",
      "code-analysis",
      "reasoning",
      "llm",
      "text-generation",
      "conversational",
      "en",
      "code",
      "arxiv:2512.07533",
      "base_model:Qwen/Qwen2.5-7B-Instruct",
      "base_model:finetune:Qwen/Qwen2.5-7B-Instruct",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "OpenMOSS-Team/MOVA-360p",
    "task": "image-to-video",
    "library": "diffusers",
    "downloads": 5539,
    "likes": 175,
    "tags": [
      "diffusers",
      "safetensors",
      "image-to-video",
      "image-text-to-video",
      "image-to-audio-video",
      "image-text-to-audio-video",
      "MOVA",
      "OpenMOSS",
      "SII",
      "MOSI",
      "sglang-diffusion",
      "arxiv:2602.08794",
      "license:apache-2.0",
      "diffusers:MOVA",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "FireRedTeam/FireRed-Image-Edit-1.0",
    "task": "image-to-image",
    "library": "diffusers",
    "downloads": 320,
    "likes": 113,
    "tags": [
      "diffusers",
      "safetensors",
      "en",
      "zh",
      "license:apache-2.0",
      "diffusers:QwenImageEditPlusPipeline",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "TeichAI/GLM-4.7-Flash-Claude-Opus-4.5-High-Reasoning-Distill-GGUF",
    "task": null,
    "library": null,
    "downloads": 52930,
    "likes": 280,
    "tags": [
      "gguf",
      "text-generation-inference",
      "llama.cpp",
      "unsloth",
      "glm4_moe_lite",
      "dataset:TeichAI/claude-4.5-opus-high-reasoning-250x",
      "base_model:TeichAI/GLM-4.7-Flash-Claude-Opus-4.5-High-Reasoning-Distill",
      "base_model:quantized:TeichAI/GLM-4.7-Flash-Claude-Opus-4.5-High-Reasoning-Distill",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "AIDC-AI/Ovis2.6-30B-A3B",
    "task": "image-text-to-text",
    "library": null,
    "downloads": 2107,
    "likes": 100,
    "tags": [
      "safetensors",
      "ovis2_6_moe",
      "image-text-to-text",
      "conversational",
      "custom_code",
      "arxiv:2508.11737",
      "arxiv:2405.20797",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "ytu-ce-cosmos/Turkish-Gemma-9b-T1",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 3321,
    "likes": 130,
    "tags": [
      "transformers",
      "safetensors",
      "gemma2",
      "text-generation",
      "Turkish",
      "DPO",
      "SFT",
      "conversational",
      "instruction",
      "reasoning",
      "thinking",
      "tr",
      "license:gemma",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "zai-org/GLM-5-FP8",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 103976,
    "likes": 98,
    "tags": [
      "transformers",
      "safetensors",
      "glm_moe_dsa",
      "text-generation",
      "conversational",
      "en",
      "zh",
      "license:mit",
      "endpoints_compatible",
      "fp8",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Lightricks/LTX-2",
    "task": "image-to-video",
    "library": "diffusers",
    "downloads": 2186942,
    "likes": 1536,
    "tags": [
      "diffusers",
      "safetensors",
      "image-to-video",
      "text-to-video",
      "video-to-video",
      "image-text-to-video",
      "audio-to-video",
      "text-to-audio",
      "video-to-audio",
      "audio-to-audio",
      "text-to-audio-video",
      "image-to-audio-video",
      "image-text-to-audio-video",
      "ltx-2",
      "ltx-video",
      "ltxv",
      "lightricks",
      "en",
      "de",
      "es",
      "fr",
      "ja",
      "ko",
      "zh",
      "it",
      "pt",
      "arxiv:2601.03233",
      "license:other",
      "diffusers:LTX2Pipeline",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "DavidAU/GLM-4.7-Flash-Uncensored-Heretic-NEO-CODE-Imatrix-MAX-GGUF",
    "task": "text-generation",
    "library": null,
    "downloads": 77523,
    "likes": 211,
    "tags": [
      "gguf",
      "GLM 4.7 Flash",
      "thinking",
      "reasoning",
      "NEO Imatrix",
      "MAX Quants",
      "16 bit precision output tensor",
      "heretic",
      "uncensored",
      "abliterated",
      "deep reasoning",
      "fine tune",
      "creative",
      "creative writing",
      "fiction writing",
      "plot generation",
      "sub-plot generation",
      "story generation",
      "scene continue",
      "storytelling",
      "fiction story",
      "science fiction",
      "romance",
      "all genres",
      "story",
      "writing",
      "vivid prosing",
      "vivid writing",
      "fiction",
      "roleplaying",
      "bfloat16",
      "swearing",
      "rp",
      "horror",
      "text-generation",
      "en",
      "zh",
      "base_model:Olafangensan/GLM-4.7-Flash-heretic",
      "base_model:quantized:Olafangensan/GLM-4.7-Flash-heretic",
      "license:mit",
      "endpoints_compatible",
      "region:us",
      "imatrix",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "zai-org/GLM-4.7-Flash",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 1617234,
    "likes": 1526,
    "tags": [
      "transformers",
      "safetensors",
      "glm4_moe_lite",
      "text-generation",
      "conversational",
      "en",
      "zh",
      "arxiv:2508.06471",
      "license:mit",
      "eval-results",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-ASR-1.7B",
    "task": "automatic-speech-recognition",
    "library": null,
    "downloads": 324430,
    "likes": 481,
    "tags": [
      "safetensors",
      "qwen3_asr",
      "automatic-speech-recognition",
      "arxiv:2601.21337",
      "license:apache-2.0",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "tencent/HunyuanImage-3.0-Instruct",
    "task": "image-to-image",
    "library": null,
    "downloads": 1211,
    "likes": 353,
    "tags": [
      "safetensors",
      "hunyuan_image_3_moe",
      "image-to-image",
      "custom_code",
      "arxiv:2509.23951",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Soul-AILab/SoulX-Singer",
    "task": "text-to-speech",
    "library": "huggingface_hub",
    "downloads": 303,
    "likes": 85,
    "tags": [
      "huggingface_hub",
      "text-to-audio",
      "music",
      "singing-voice-synthesis",
      "svs",
      "zero-shot",
      "text-to-speech",
      "en",
      "zh",
      "arxiv:2602.07803",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "inclusionAI/LLaDA2.1-mini",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 9878,
    "likes": 77,
    "tags": [
      "transformers",
      "safetensors",
      "llada2_moe",
      "text-generation",
      "dllm",
      "diffusion",
      "llm",
      "text_generation",
      "conversational",
      "custom_code",
      "arxiv:2602.08676",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "kugelaudio/kugelaudio-0-open",
    "task": "text-to-speech",
    "library": null,
    "downloads": 22517,
    "likes": 159,
    "tags": [
      "safetensors",
      "kugelaudio",
      "text-to-speech",
      "tts",
      "speech-synthesis",
      "audio-generation",
      "european-languages",
      "diffusion",
      "autoregressive",
      "en",
      "de",
      "fr",
      "es",
      "it",
      "pt",
      "nl",
      "pl",
      "ru",
      "uk",
      "cs",
      "ro",
      "hu",
      "sv",
      "da",
      "fi",
      "no",
      "el",
      "bg",
      "sk",
      "hr",
      "sr",
      "tr",
      "license:mit",
      "model-index",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Tongyi-MAI/Z-Image-Turbo",
    "task": "text-to-image",
    "library": "diffusers",
    "downloads": 819990,
    "likes": 4117,
    "tags": [
      "diffusers",
      "safetensors",
      "text-to-image",
      "en",
      "arxiv:2511.22699",
      "arxiv:2511.22677",
      "arxiv:2511.13649",
      "license:apache-2.0",
      "diffusers:ZImagePipeline",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-Coder-Next-GGUF",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 39169,
    "likes": 159,
    "tags": [
      "transformers",
      "gguf",
      "text-generation",
      "arxiv:2309.00071",
      "license:apache-2.0",
      "endpoints_compatible",
      "deploy:azure",
      "region:us",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-TTS-12Hz-1.7B-CustomVoice",
    "task": "text-to-speech",
    "library": null,
    "downloads": 628944,
    "likes": 949,
    "tags": [
      "safetensors",
      "qwen3_tts",
      "text-to-speech",
      "arxiv:2601.15621",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "internlm/Intern-S1-Pro",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 16906,
    "likes": 253,
    "tags": [
      "transformers",
      "safetensors",
      "interns1_pro",
      "text-generation",
      "image-text-to-text",
      "conversational",
      "custom_code",
      "arxiv:2508.15763",
      "license:apache-2.0",
      "fp8",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "unsloth/MiniMax-M2.5-GGUF",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 17247,
    "likes": 68,
    "tags": [
      "transformers",
      "gguf",
      "unsloth",
      "minimax_m2",
      "text-generation",
      "base_model:MiniMaxAI/MiniMax-M2.5",
      "base_model:quantized:MiniMaxAI/MiniMax-M2.5",
      "license:other",
      "endpoints_compatible",
      "region:us",
      "imatrix",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "meta-llama/Llama-3.1-8B-Instruct",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 5633386,
    "likes": 5455,
    "tags": [
      "transformers",
      "safetensors",
      "llama",
      "text-generation",
      "facebook",
      "meta",
      "pytorch",
      "llama-3",
      "conversational",
      "en",
      "de",
      "fr",
      "it",
      "pt",
      "hi",
      "es",
      "th",
      "arxiv:2204.05149",
      "base_model:meta-llama/Llama-3.1-8B",
      "base_model:finetune:meta-llama/Llama-3.1-8B",
      "license:llama3.1",
      "eval-results",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Tongyi-MAI/Z-Image",
    "task": "text-to-image",
    "library": "diffusers",
    "downloads": 25768,
    "likes": 914,
    "tags": [
      "diffusers",
      "safetensors",
      "text-to-image",
      "en",
      "arxiv:2511.22699",
      "license:apache-2.0",
      "diffusers:ZImagePipeline",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "nineninesix/kani-tts-2-en",
    "task": "text-to-speech",
    "library": "transformers",
    "downloads": 247,
    "likes": 64,
    "tags": [
      "transformers",
      "safetensors",
      "lfm2",
      "text-generation",
      "text-to-speech",
      "en",
      "dataset:laion/Emolia",
      "arxiv:2511.23404",
      "arxiv:2501.15907",
      "arxiv:2506.09827",
      "base_model:nineninesix/kani-tts-2-pt",
      "base_model:finetune:nineninesix/kani-tts-2-pt",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "jdopensource/JoyAI-LLM-Flash",
    "task": "text-generation",
    "library": null,
    "downloads": 58,
    "likes": 61,
    "tags": [
      "safetensors",
      "joyai_llm_flash",
      "text-generation",
      "conversational",
      "custom_code",
      "zh",
      "en",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "openai/gpt-oss-20b",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 5486839,
    "likes": 4362,
    "tags": [
      "transformers",
      "safetensors",
      "gpt_oss",
      "text-generation",
      "vllm",
      "conversational",
      "arxiv:2508.10925",
      "license:apache-2.0",
      "endpoints_compatible",
      "8-bit",
      "mxfp4",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "unsloth/GLM-4.7-Flash-GGUF",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 407742,
    "likes": 473,
    "tags": [
      "transformers",
      "gguf",
      "unsloth",
      "text-generation",
      "en",
      "zh",
      "arxiv:2508.06471",
      "base_model:zai-org/GLM-4.7-Flash",
      "base_model:quantized:zai-org/GLM-4.7-Flash",
      "license:mit",
      "endpoints_compatible",
      "deploy:azure",
      "region:us",
      "imatrix",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "deepseek-ai/DeepSeek-OCR-2",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 1087713,
    "likes": 755,
    "tags": [
      "transformers",
      "safetensors",
      "deepseek_vl_v2",
      "feature-extraction",
      "deepseek",
      "vision-language",
      "ocr",
      "custom_code",
      "image-text-to-text",
      "multilingual",
      "arxiv:2601.20552",
      "arxiv:2510.18234",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "openbmb/MiniCPM-o-4_5-gguf",
    "task": "any-to-any",
    "library": "transformers",
    "downloads": 37365,
    "likes": 70,
    "tags": [
      "transformers",
      "gguf",
      "minicpm-o",
      "minicpm-v",
      "multimodal",
      "full-duplex",
      "any-to-any",
      "arxiv:2408.01800",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "inclusionAI/LLaDA2.1-flash",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 443,
    "likes": 56,
    "tags": [
      "transformers",
      "safetensors",
      "llada2_moe",
      "text-generation",
      "dllm",
      "diffusion",
      "llm",
      "text_generation",
      "conversational",
      "custom_code",
      "arxiv:2602.08676",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "deepgenteam/DeepGen-1.0",
    "task": "image-to-image",
    "library": null,
    "downloads": 0,
    "likes": 55,
    "tags": [
      "image-to-image",
      "dataset:Alex11556666/Reason_Tuning",
      "arxiv:2602.12205",
      "base_model:Qwen/Qwen2.5-VL-3B-Instruct",
      "base_model:finetune:Qwen/Qwen2.5-VL-3B-Instruct",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "fal/Qwen-Image-Edit-2511-Multiple-Angles-LoRA",
    "task": "image-to-image",
    "library": "diffusers",
    "downloads": 65317,
    "likes": 993,
    "tags": [
      "diffusers",
      "qwen",
      "qwen-image-edit",
      "qwen-image-edit-2511",
      "lora",
      "multi-angle",
      "camera-angles",
      "camera-control",
      "image-editing",
      "image-to-image",
      "gaussian-splatting",
      "fal",
      "en",
      "base_model:Qwen/Qwen-Image-Edit-2511",
      "base_model:adapter:Qwen/Qwen-Image-Edit-2511",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Alissonerdx/BFS-Best-Face-Swap-Video",
    "task": "image-to-video",
    "library": "diffusers",
    "downloads": 168,
    "likes": 108,
    "tags": [
      "diffusers",
      "ltx-2",
      "ic-lora",
      "head-swap",
      "video-to-video",
      "image-to-video",
      "bfs",
      "lora",
      "base_model:Lightricks/LTX-2",
      "base_model:adapter:Lightricks/LTX-2",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Aratako/MioTTS-2.6B",
    "task": "text-to-speech",
    "library": "transformers",
    "downloads": 174,
    "likes": 48,
    "tags": [
      "transformers",
      "safetensors",
      "lfm2",
      "text-generation",
      "speech",
      "tts",
      "voice",
      "text-to-speech",
      "ja",
      "en",
      "dataset:nvidia/hifitts-2",
      "dataset:amphion/Emilia-Dataset",
      "base_model:LiquidAI/LFM2-2.6B",
      "base_model:finetune:LiquidAI/LFM2-2.6B",
      "license:other",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "DMindAI/DMind-3-nano",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 0,
    "likes": 47,
    "tags": [
      "transformers",
      "safetensors",
      "function-calling",
      "tool-use",
      "crypto",
      "blockchain",
      "solana",
      "ethereum",
      "on-device",
      "privacy",
      "edge-ai",
      "mobile",
      "wallet",
      "standard-protocol",
      "text-generation",
      "en",
      "zh",
      "base_model:google/functiongemma-270m-it",
      "base_model:finetune:google/functiongemma-270m-it",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "alibaba-pai/Z-Image-Fun-Lora-Distill",
    "task": "text-to-image",
    "library": "videox_fun",
    "downloads": 6993,
    "likes": 64,
    "tags": [
      "videox_fun",
      "lora",
      "text-to-image",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "FutureMa/Eva-4B-V2",
    "task": "text-classification",
    "library": "transformers",
    "downloads": 601,
    "likes": 112,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "finance",
      "earnings-calls",
      "evasion-detection",
      "nlp",
      "text-classification",
      "en",
      "dataset:FutureMa/EvasionBench",
      "arxiv:2601.09142",
      "base_model:Qwen/Qwen3-4B-Instruct-2507",
      "base_model:finetune:Qwen/Qwen3-4B-Instruct-2507",
      "license:apache-2.0",
      "eval-results",
      "text-embeddings-inference",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "MiniMaxAI/MiniMax-M2.1",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 82670,
    "likes": 1271,
    "tags": [
      "transformers",
      "safetensors",
      "minimax_m2",
      "text-generation",
      "conversational",
      "custom_code",
      "arxiv:2509.06501",
      "license:other",
      "eval-results",
      "endpoints_compatible",
      "fp8",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "DMindAI/DMind-3",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 10,
    "likes": 45,
    "tags": [
      "transformers",
      "safetensors",
      "gpt_oss",
      "text-generation",
      "web3",
      "finance",
      "defi",
      "chain-of-thought",
      "sft",
      "security-audit",
      "on-device-ai",
      "conversational",
      "en",
      "zh",
      "base_model:openai/gpt-oss-20b",
      "base_model:finetune:openai/gpt-oss-20b",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "openai/gpt-oss-120b",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 3326846,
    "likes": 4491,
    "tags": [
      "transformers",
      "safetensors",
      "gpt_oss",
      "text-generation",
      "vllm",
      "conversational",
      "arxiv:2508.10925",
      "license:apache-2.0",
      "endpoints_compatible",
      "8-bit",
      "mxfp4",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "facebook/sam3",
    "task": "mask-generation",
    "library": "transformers",
    "downloads": 1713780,
    "likes": 1563,
    "tags": [
      "transformers",
      "safetensors",
      "sam3_video",
      "feature-extraction",
      "sam3",
      "mask-generation",
      "en",
      "license:other",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "PaddlePaddle/PaddleOCR-VL-1.5",
    "task": "image-text-to-text",
    "library": "PaddleOCR",
    "downloads": 14463,
    "likes": 394,
    "tags": [
      "PaddleOCR",
      "safetensors",
      "paddleocr_vl",
      "ERNIE4.5",
      "PaddlePaddle",
      "image-to-text",
      "ocr",
      "document-parse",
      "layout",
      "table",
      "formula",
      "chart",
      "seal",
      "spotting",
      "image-text-to-text",
      "conversational",
      "custom_code",
      "en",
      "zh",
      "multilingual",
      "arxiv:2601.21957",
      "base_model:baidu/ERNIE-4.5-0.3B-Paddle",
      "base_model:finetune:baidu/ERNIE-4.5-0.3B-Paddle",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "sentence-transformers/all-MiniLM-L6-v2",
    "task": "sentence-similarity",
    "library": "sentence-transformers",
    "downloads": 159084214,
    "likes": 4475,
    "tags": [
      "sentence-transformers",
      "pytorch",
      "tf",
      "rust",
      "onnx",
      "safetensors",
      "openvino",
      "bert",
      "feature-extraction",
      "sentence-similarity",
      "transformers",
      "en",
      "dataset:s2orc",
      "dataset:flax-sentence-embeddings/stackexchange_xml",
      "dataset:ms_marco",
      "dataset:gooaq",
      "dataset:yahoo_answers_topics",
      "dataset:code_search_net",
      "dataset:search_qa",
      "dataset:eli5",
      "dataset:snli",
      "dataset:multi_nli",
      "dataset:wikihow",
      "dataset:natural_questions",
      "dataset:trivia_qa",
      "dataset:embedding-data/sentence-compression",
      "dataset:embedding-data/flickr30k-captions",
      "dataset:embedding-data/altlex",
      "dataset:embedding-data/simple-wiki",
      "dataset:embedding-data/QQP",
      "dataset:embedding-data/SPECTER",
      "dataset:embedding-data/PAQ_pairs",
      "dataset:embedding-data/WikiAnswers",
      "arxiv:1904.06472",
      "arxiv:2102.07033",
      "arxiv:2104.08727",
      "arxiv:1704.05179",
      "arxiv:1810.09305",
      "license:apache-2.0",
      "text-embeddings-inference",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "black-forest-labs/FLUX.1-dev",
    "task": "text-to-image",
    "library": "diffusers",
    "downloads": 753377,
    "likes": 12308,
    "tags": [
      "diffusers",
      "safetensors",
      "text-to-image",
      "image-generation",
      "flux",
      "en",
      "license:other",
      "endpoints_compatible",
      "diffusers:FluxPipeline",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "DMindAI/DMind-3-mini",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 78,
    "likes": 43,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "web3",
      "finance",
      "defi",
      "chain-of-thought",
      "sft",
      "security-audit",
      "on-device-ai",
      "conversational",
      "en",
      "zh",
      "base_model:Qwen/Qwen3-4B-Thinking-2507",
      "base_model:finetune:Qwen/Qwen3-4B-Thinking-2507",
      "license:apache-2.0",
      "text-generation-inference",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "black-forest-labs/FLUX.2-klein-9B",
    "task": "image-to-image",
    "library": "diffusers",
    "downloads": 89530,
    "likes": 417,
    "tags": [
      "diffusers",
      "safetensors",
      "image-generation",
      "image-editing",
      "flux",
      "diffusion-single-file",
      "image-to-image",
      "en",
      "license:other",
      "diffusers:Flux2KleinPipeline",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Phr00t/Qwen-Image-Edit-Rapid-AIO",
    "task": "text-to-image",
    "library": "comfyUI",
    "downloads": 0,
    "likes": 1628,
    "tags": [
      "comfyUI",
      "qwen",
      "qwen-edit",
      "t2i",
      "i2i",
      "text-to-image",
      "base_model:Qwen/Qwen-Image-Edit-2511",
      "base_model:finetune:Qwen/Qwen-Image-Edit-2511",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Phr00t/LTX2-Rapid-Merges",
    "task": "image-text-to-video",
    "library": null,
    "downloads": 0,
    "likes": 304,
    "tags": [
      "ltx2",
      "t2v",
      "i2v",
      "image-text-to-video",
      "base_model:Lightricks/LTX-2",
      "base_model:finetune:Lightricks/LTX-2",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "AngelSlim/HY-1.8B-2Bit",
    "task": null,
    "library": null,
    "downloads": 203,
    "likes": 41,
    "tags": [
      "safetensors",
      "hunyuan_v1_dense",
      "hy",
      "quant",
      "2bit",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-8B",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 4642058,
    "likes": 934,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "conversational",
      "arxiv:2309.00071",
      "arxiv:2505.09388",
      "base_model:Qwen/Qwen3-8B-Base",
      "base_model:finetune:Qwen/Qwen3-8B-Base",
      "license:apache-2.0",
      "text-generation-inference",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "OpenResearcher/OpenResearcher-30B-A3B",
    "task": null,
    "library": null,
    "downloads": 1139,
    "likes": 40,
    "tags": [
      "safetensors",
      "nemotron_h",
      "custom_code",
      "dataset:OpenResearcher/OpenResearcher-Dataset",
      "base_model:nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-Base-BF16",
      "base_model:finetune:nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-Base-BF16",
      "license:mit",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "lm-provers/QED-Nano",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 150,
    "likes": 40,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "conversational",
      "en",
      "dataset:lm-provers/FineProofs-RL",
      "arxiv:2602.03773",
      "base_model:lm-provers/QED-Nano-SFT",
      "base_model:finetune:lm-provers/QED-Nano-SFT",
      "license:apache-2.0",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "hexgrad/Kokoro-82M",
    "task": "text-to-speech",
    "library": null,
    "downloads": 7171510,
    "likes": 5699,
    "tags": [
      "text-to-speech",
      "en",
      "arxiv:2306.07691",
      "arxiv:2203.02395",
      "base_model:yl4579/StyleTTS2-LJSpeech",
      "base_model:finetune:yl4579/StyleTTS2-LJSpeech",
      "doi:10.57967/hf/4329",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "microsoft/VibeVoice-ASR",
    "task": "automatic-speech-recognition",
    "library": "transformers",
    "downloads": 495190,
    "likes": 863,
    "tags": [
      "transformers",
      "safetensors",
      "vibevoice",
      "ASR",
      "Transcriptoin",
      "Diarization",
      "Speech-to-Text",
      "automatic-speech-recognition",
      "en",
      "zh",
      "es",
      "pt",
      "de",
      "ja",
      "ko",
      "fr",
      "ru",
      "id",
      "sv",
      "it",
      "he",
      "nl",
      "pl",
      "no",
      "tr",
      "th",
      "ar",
      "hu",
      "ca",
      "cs",
      "da",
      "fa",
      "af",
      "hi",
      "fi",
      "et",
      "aa",
      "el",
      "ro",
      "vi",
      "bg",
      "is",
      "sl",
      "sk",
      "lt",
      "sw",
      "uk",
      "kl",
      "lv",
      "hr",
      "ne",
      "sr",
      "tl",
      "yi",
      "ms",
      "ur",
      "mn",
      "hy",
      "jv",
      "arxiv:2601.18184",
      "license:mit",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "nvidia/parakeet-tdt-0.6b-v3",
    "task": "automatic-speech-recognition",
    "library": "nemo",
    "downloads": 76511,
    "likes": 642,
    "tags": [
      "nemo",
      "automatic-speech-recognition",
      "speech",
      "audio",
      "Transducer",
      "TDT",
      "FastConformer",
      "Conformer",
      "pytorch",
      "NeMo",
      "hf-asr-leaderboard",
      "en",
      "es",
      "fr",
      "de",
      "bg",
      "hr",
      "cs",
      "da",
      "nl",
      "et",
      "fi",
      "el",
      "hu",
      "it",
      "lv",
      "lt",
      "mt",
      "pl",
      "pt",
      "ro",
      "sk",
      "sl",
      "sv",
      "ru",
      "uk",
      "dataset:nvidia/Granary",
      "dataset:nemo/asr-set-3.0",
      "arxiv:2509.14128",
      "arxiv:2505.13404",
      "arxiv:2305.05084",
      "arxiv:2304.06795",
      "arxiv:2410.01036",
      "arxiv:2406.00899",
      "arxiv:2205.12446",
      "arxiv:2012.03411",
      "arxiv:2007.10310",
      "arxiv:1510.08484",
      "license:cc-by-4.0",
      "model-index",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Octen/Octen-Embedding-8B",
    "task": "sentence-similarity",
    "library": "sentence-transformers",
    "downloads": 7759,
    "likes": 141,
    "tags": [
      "sentence-transformers",
      "safetensors",
      "qwen3",
      "sentence-similarity",
      "feature-extraction",
      "embedding",
      "text-embedding",
      "retrieval",
      "en",
      "zh",
      "multilingual",
      "base_model:Qwen/Qwen3-Embedding-8B",
      "base_model:finetune:Qwen/Qwen3-Embedding-8B",
      "license:apache-2.0",
      "text-embeddings-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "black-forest-labs/FLUX.2-dev",
    "task": "image-to-image",
    "library": "diffusers",
    "downloads": 162720,
    "likes": 1366,
    "tags": [
      "diffusers",
      "safetensors",
      "image-generation",
      "image-editing",
      "flux",
      "diffusion-single-file",
      "image-to-image",
      "en",
      "license:other",
      "diffusers:Flux2Pipeline",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "zai-org/GLM-4.7",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 124475,
    "likes": 1920,
    "tags": [
      "transformers",
      "safetensors",
      "glm4_moe",
      "text-generation",
      "conversational",
      "en",
      "zh",
      "arxiv:2508.06471",
      "license:mit",
      "eval-results",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "nvidia/Kimi-K2.5-NVFP4",
    "task": "text-generation",
    "library": "Model Optimizer",
    "downloads": 37774,
    "likes": 45,
    "tags": [
      "Model Optimizer",
      "safetensors",
      "kimi_k25",
      "nvidia",
      "ModelOpt",
      "Kimi-K2",
      "quantized",
      "FP4",
      "text-generation",
      "conversational",
      "custom_code",
      "base_model:moonshotai/Kimi-K2.5",
      "base_model:quantized:moonshotai/Kimi-K2.5",
      "license:other",
      "modelopt",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "ubergarm/MiniMax-M2.5-GGUF",
    "task": "text-generation",
    "library": null,
    "downloads": 11544,
    "likes": 36,
    "tags": [
      "gguf",
      "imatrix",
      "conversational",
      "minimax_m2",
      "ik_llama.cpp",
      "text-generation",
      "base_model:MiniMaxAI/MiniMax-M2.5",
      "base_model:quantized:MiniMaxAI/MiniMax-M2.5",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "tarteel-ai/whisper-base-ar-quran",
    "task": "automatic-speech-recognition",
    "library": "transformers",
    "downloads": 9840,
    "likes": 109,
    "tags": [
      "transformers",
      "pytorch",
      "tensorboard",
      "whisper",
      "automatic-speech-recognition",
      "generated_from_trainer",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "pyannote/speaker-diarization-3.1",
    "task": "automatic-speech-recognition",
    "library": "pyannote-audio",
    "downloads": 13004189,
    "likes": 1544,
    "tags": [
      "pyannote-audio",
      "pyannote",
      "pyannote-audio-pipeline",
      "audio",
      "voice",
      "speech",
      "speaker",
      "speaker-diarization",
      "speaker-change-detection",
      "voice-activity-detection",
      "overlapped-speech-detection",
      "automatic-speech-recognition",
      "arxiv:2111.14448",
      "arxiv:2012.01477",
      "license:mit",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "google/medgemma-1.5-4b-it",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 171715,
    "likes": 451,
    "tags": [
      "transformers",
      "safetensors",
      "gemma3",
      "image-text-to-text",
      "medical",
      "radiology",
      "clinical-reasoning",
      "dermatology",
      "pathology",
      "ophthalmology",
      "chest-x-ray",
      "conversational",
      "arxiv:2303.15343",
      "arxiv:2507.05201",
      "arxiv:2406.19578",
      "arxiv:2405.03162",
      "arxiv:2106.14463",
      "arxiv:2009.13081",
      "arxiv:2203.14371",
      "arxiv:1909.06146",
      "arxiv:2102.09542",
      "arxiv:2411.15640",
      "arxiv:2404.05590",
      "arxiv:2501.18362",
      "arxiv:1605.01397",
      "arxiv:1901.07031",
      "arxiv:2403.17834",
      "arxiv:2402.16040",
      "license:other",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "ruv/ruvltra-claude-code",
    "task": "text-generation",
    "library": "gguf",
    "downloads": 4732,
    "likes": 60,
    "tags": [
      "gguf",
      "ruvltra",
      "claude-code",
      "code-generation",
      "sona",
      "adaptive-learning",
      "self-learning",
      "swarm-optimized",
      "quantized",
      "llama-cpp",
      "text-generation-inference",
      "first-of-its-kind",
      "text-generation",
      "en",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us",
      "imatrix",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "BAAI/bge-m3",
    "task": "sentence-similarity",
    "library": "sentence-transformers",
    "downloads": 14287788,
    "likes": 2755,
    "tags": [
      "sentence-transformers",
      "pytorch",
      "onnx",
      "xlm-roberta",
      "feature-extraction",
      "sentence-similarity",
      "arxiv:2402.03216",
      "arxiv:2004.04906",
      "arxiv:2106.14807",
      "arxiv:2107.05720",
      "arxiv:2004.12832",
      "license:mit",
      "text-embeddings-inference",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "microsoft/TRELLIS.2-4B",
    "task": "image-to-3d",
    "library": "trellis2",
    "downloads": 0,
    "likes": 614,
    "tags": [
      "trellis2",
      "image-to-3d",
      "en",
      "arxiv:2512.14692",
      "license:mit",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "black-forest-labs/FLUX.2-klein-4B",
    "task": "image-to-image",
    "library": "diffusers",
    "downloads": 171727,
    "likes": 469,
    "tags": [
      "diffusers",
      "safetensors",
      "text-to-image",
      "image-editing",
      "flux",
      "diffusion-single-file",
      "image-to-image",
      "en",
      "license:apache-2.0",
      "diffusers:Flux2KleinPipeline",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "stepfun-ai/Step-3.5-Flash-GGUF-Q4_K_S",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 13605,
    "likes": 129,
    "tags": [
      "transformers",
      "gguf",
      "step3p5",
      "text-generation",
      "custom_code",
      "arxiv:2602.10604",
      "arxiv:2601.05593",
      "arxiv:2507.19427",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us",
      "imatrix",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "rednote-hilab/dots.ocr-1.5",
    "task": "image-text-to-text",
    "library": "dots_ocr_1_5",
    "downloads": 0,
    "likes": 34,
    "tags": [
      "dots_ocr_1_5",
      "safetensors",
      "dots_ocr",
      "text-generation",
      "image-to-text",
      "ocr",
      "document-parse",
      "layout",
      "table",
      "formula",
      "transformers",
      "custom_code",
      "image-text-to-text",
      "conversational",
      "en",
      "zh",
      "multilingual",
      "license:mit",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "mistralai/Mistral-7B-Instruct-v0.3",
    "task": null,
    "library": "vllm",
    "downloads": 1175030,
    "likes": 2419,
    "tags": [
      "vllm",
      "safetensors",
      "mistral",
      "mistral-common",
      "base_model:mistralai/Mistral-7B-v0.3",
      "base_model:finetune:mistralai/Mistral-7B-v0.3",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Comfy-Org/ace_step_1.5_ComfyUI_files",
    "task": null,
    "library": null,
    "downloads": 0,
    "likes": 95,
    "tags": [
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "justdubit/justdubit",
    "task": "video-to-video",
    "library": "peft",
    "downloads": 0,
    "likes": 31,
    "tags": [
      "peft",
      "video-dubbing",
      "lip-sync",
      "audio-video",
      "lora",
      "diffusion",
      "ltx-2",
      "justdubit",
      "video-to-video",
      "en",
      "multilingual",
      "dataset:justdubit/audiovisual_translation_dub",
      "base_model:Lightricks/LTX-2",
      "base_model:adapter:Lightricks/LTX-2",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "OpenMOSS-Team/MOSS-TTSD-v1.0",
    "task": "text-to-speech",
    "library": "transformers",
    "downloads": 1134,
    "likes": 31,
    "tags": [
      "transformers",
      "safetensors",
      "moss_tts_delay",
      "feature-extraction",
      "text-to-speech",
      "custom_code",
      "zh",
      "en",
      "de",
      "es",
      "fr",
      "ja",
      "it",
      "he",
      "ko",
      "ru",
      "fa",
      "ar",
      "pl",
      "pt",
      "cs",
      "da",
      "sv",
      "hu",
      "el",
      "tr",
      "arxiv:2602.10934",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-ASR-0.6B",
    "task": "automatic-speech-recognition",
    "library": null,
    "downloads": 73488,
    "likes": 201,
    "tags": [
      "safetensors",
      "qwen3_asr",
      "automatic-speech-recognition",
      "arxiv:2601.21337",
      "license:apache-2.0",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "OpenMOSS-Team/MOSS-TTS-Realtime",
    "task": "text-to-speech",
    "library": "transformers",
    "downloads": 2289,
    "likes": 30,
    "tags": [
      "transformers",
      "safetensors",
      "moss_tts_realtime",
      "text-to-speech",
      "audio",
      "moss-tts",
      "zh",
      "en",
      "de",
      "es",
      "fr",
      "ja",
      "it",
      "he",
      "ko",
      "ru",
      "fa",
      "ar",
      "pl",
      "pt",
      "cs",
      "da",
      "sv",
      "hu",
      "el",
      "tr",
      "arxiv:2602.10934",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "kyutai/hibiki-zero-3b-pytorch-bf16",
    "task": "audio-to-audio",
    "library": null,
    "downloads": 368,
    "likes": 30,
    "tags": [
      "hibiki",
      "audio-to-audio",
      "fr",
      "es",
      "pt",
      "de",
      "en",
      "arxiv:2410.00037",
      "arxiv:2502.03382",
      "arxiv:2602.11072",
      "base_model:kyutai/hibiki-zero-3b-pytorch-bf16",
      "base_model:finetune:kyutai/hibiki-zero-3b-pytorch-bf16",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-0.6B",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 10034367,
    "likes": 1076,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "conversational",
      "arxiv:2505.09388",
      "base_model:Qwen/Qwen3-0.6B-Base",
      "base_model:finetune:Qwen/Qwen3-0.6B-Base",
      "license:apache-2.0",
      "text-generation-inference",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-Coder-Next-FP8",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 155229,
    "likes": 75,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3_next",
      "text-generation",
      "conversational",
      "license:apache-2.0",
      "endpoints_compatible",
      "fp8",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "huihui-ai/Huihui-Qwen3-Coder-Next-abliterated",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 896,
    "likes": 29,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3_next",
      "text-generation",
      "abliterated",
      "uncensored",
      "conversational",
      "base_model:Qwen/Qwen3-Coder-Next",
      "base_model:finetune:Qwen/Qwen3-Coder-Next",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "deepseek-ai/DeepSeek-V3.2",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 335001,
    "likes": 1244,
    "tags": [
      "transformers",
      "safetensors",
      "deepseek_v32",
      "text-generation",
      "conversational",
      "base_model:deepseek-ai/DeepSeek-V3.2-Exp-Base",
      "base_model:finetune:deepseek-ai/DeepSeek-V3.2-Exp-Base",
      "license:mit",
      "eval-results",
      "endpoints_compatible",
      "fp8",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "google/translategemma-4b-it",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 139246,
    "likes": 624,
    "tags": [
      "transformers",
      "safetensors",
      "gemma3",
      "image-text-to-text",
      "conversational",
      "arxiv:2601.09012",
      "arxiv:2503.19786",
      "license:gemma",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "kyutai/pocket-tts",
    "task": null,
    "library": "pocket-tts",
    "downloads": 64470,
    "likes": 549,
    "tags": [
      "pocket-tts",
      "en",
      "arxiv:2509.06926",
      "license:cc-by-4.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "AngelSlim/HY-1.8B-2Bit-GGUF",
    "task": null,
    "library": null,
    "downloads": 3222,
    "likes": 27,
    "tags": [
      "gguf",
      "hunyuan_v1_dense",
      "hy",
      "quant",
      "2bit",
      "endpoints_compatible",
      "region:us",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "OpenMOSS-Team/MOSS-Audio-Tokenizer",
    "task": "feature-extraction",
    "library": "transformers",
    "downloads": 4953,
    "likes": 27,
    "tags": [
      "transformers",
      "safetensors",
      "moss-audio-tokenizer",
      "feature-extraction",
      "audio",
      "audio-tokenizer",
      "neural-codec",
      "moss-tts-family",
      "MOSS Audio Tokenizer",
      "speech-tokenizer",
      "trust-remote-code",
      "custom_code",
      "arxiv:2602.10934",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "inclusionAI/Ling-2.5-1T",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 0,
    "likes": 27,
    "tags": [
      "transformers",
      "safetensors",
      "bailing_hybrid",
      "text-generation",
      "conversational",
      "custom_code",
      "license:mit",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "stabilityai/stable-diffusion-xl-base-1.0",
    "task": "text-to-image",
    "library": "diffusers",
    "downloads": 2044724,
    "likes": 7435,
    "tags": [
      "diffusers",
      "onnx",
      "safetensors",
      "text-to-image",
      "stable-diffusion",
      "arxiv:2307.01952",
      "arxiv:2211.01324",
      "arxiv:2108.01073",
      "arxiv:2112.10752",
      "license:openrail++",
      "endpoints_compatible",
      "diffusers:StableDiffusionXLPipeline",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-VL-8B-Instruct",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 2970259,
    "likes": 755,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3_vl",
      "image-text-to-text",
      "conversational",
      "arxiv:2505.09388",
      "arxiv:2502.13923",
      "arxiv:2409.12191",
      "arxiv:2308.12966",
      "license:apache-2.0",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "lightonai/LightOnOCR-2-1B",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 211421,
    "likes": 520,
    "tags": [
      "transformers",
      "safetensors",
      "mistral3",
      "text-generation",
      "ocr",
      "document-understanding",
      "vision-language",
      "pdf",
      "tables",
      "forms",
      "image-text-to-text",
      "conversational",
      "en",
      "fr",
      "de",
      "es",
      "it",
      "nl",
      "pt",
      "sv",
      "da",
      "zh",
      "ja",
      "arxiv:2601.14251",
      "arxiv:2412.13663",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:eu"
    ],
    "description": ""
  },
  {
    "id": "fal/flux-2-klein-4b-spritesheet-lora",
    "task": "image-to-image",
    "library": null,
    "downloads": 0,
    "likes": 54,
    "tags": [
      "flux",
      "flux-2-klein",
      "flux-lora",
      "lora",
      "sprite-sheet",
      "game-asset",
      "2x2-grid",
      "multi-view",
      "isometric",
      "top-down",
      "side-view",
      "image-to-image",
      "fal-ai",
      "template:diffusion-lora",
      "en",
      "base_model:black-forest-labs/FLUX.2-klein-4B",
      "base_model:adapter:black-forest-labs/FLUX.2-klein-4B",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "robbyant/lingbot-world-base-cam",
    "task": "image-to-video",
    "library": "diffusers",
    "downloads": 0,
    "likes": 311,
    "tags": [
      "diffusers",
      "safetensors",
      "World Model",
      "image-to-video",
      "en",
      "arxiv:2601.20540",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "OpenMOSS-Team/MOSS-VoiceGenerator",
    "task": "text-to-speech",
    "library": null,
    "downloads": 1309,
    "likes": 26,
    "tags": [
      "safetensors",
      "moss_tts_delay",
      "text-to-speech",
      "custom_code",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "openai/whisper-large-v3",
    "task": "automatic-speech-recognition",
    "library": "transformers",
    "downloads": 6080134,
    "likes": 5393,
    "tags": [
      "transformers",
      "pytorch",
      "jax",
      "safetensors",
      "whisper",
      "automatic-speech-recognition",
      "audio",
      "hf-asr-leaderboard",
      "en",
      "zh",
      "de",
      "es",
      "ru",
      "ko",
      "fr",
      "ja",
      "pt",
      "tr",
      "pl",
      "ca",
      "nl",
      "ar",
      "sv",
      "it",
      "id",
      "hi",
      "fi",
      "vi",
      "he",
      "uk",
      "el",
      "ms",
      "cs",
      "ro",
      "da",
      "hu",
      "ta",
      "no",
      "th",
      "ur",
      "hr",
      "bg",
      "lt",
      "la",
      "mi",
      "ml",
      "cy",
      "sk",
      "te",
      "fa",
      "lv",
      "bn",
      "sr",
      "az",
      "sl",
      "kn",
      "et",
      "mk",
      "br",
      "eu",
      "is",
      "hy",
      "ne",
      "mn",
      "bs",
      "kk",
      "sq",
      "sw",
      "gl",
      "mr",
      "pa",
      "si",
      "km",
      "sn",
      "yo",
      "so",
      "af",
      "oc",
      "ka",
      "be",
      "tg",
      "sd",
      "gu",
      "am",
      "yi",
      "lo",
      "uz",
      "fo",
      "ht",
      "ps",
      "tk",
      "nn",
      "mt",
      "sa",
      "lb",
      "my",
      "bo",
      "tl",
      "mg",
      "as",
      "tt",
      "haw",
      "ln",
      "ha",
      "ba",
      "jw",
      "su",
      "arxiv:2212.04356",
      "license:apache-2.0",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Phr00t/WAN2.2-14B-Rapid-AllInOne",
    "task": "image-to-video",
    "library": "wan2.2",
    "downloads": 0,
    "likes": 1420,
    "tags": [
      "wan2.2",
      "wan",
      "accelerator",
      "image-to-video",
      "base_model:Wan-AI/Wan2.2-I2V-A14B",
      "base_model:finetune:Wan-AI/Wan2.2-I2V-A14B",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Alissonerdx/BFS-Best-Face-Swap",
    "task": "image-to-image",
    "library": "diffusers",
    "downloads": 45128,
    "likes": 234,
    "tags": [
      "diffusers",
      "lora",
      "qwen-image-edit",
      "face-swap",
      "head-swap",
      "image-editing",
      "ai-generated",
      "comfyui",
      "bfs",
      "flux 2",
      "flux",
      "klein",
      "image-to-image",
      "en",
      "base_model:Qwen/Qwen-Image-Edit-2511",
      "base_model:adapter:Qwen/Qwen-Image-Edit-2511",
      "license:mit",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "unsloth/GLM-4.7-Flash-REAP-23B-A3B-GGUF",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 59715,
    "likes": 144,
    "tags": [
      "transformers",
      "gguf",
      "glm",
      "unsloth",
      "MOE",
      "pruning",
      "compression",
      "text-generation",
      "en",
      "arxiv:2510.13999",
      "base_model:cerebras/GLM-4.7-Flash-REAP-23B-A3B",
      "base_model:quantized:cerebras/GLM-4.7-Flash-REAP-23B-A3B",
      "license:mit",
      "endpoints_compatible",
      "region:us",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "OpenMOSS-Team/MOVA-720p",
    "task": "any-to-any",
    "library": "diffusers",
    "downloads": 2184,
    "likes": 111,
    "tags": [
      "diffusers",
      "safetensors",
      "image-to-video",
      "image-text-to-video",
      "image-to-audio-video",
      "image-text-to-audio-video",
      "MOVA",
      "OpenMOSS",
      "SII",
      "MOSI",
      "sglang-diffusion",
      "any-to-any",
      "arxiv:2602.08794",
      "license:apache-2.0",
      "diffusers:MOVA",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "nineninesix/kani-tts-2-pt",
    "task": "text-to-speech",
    "library": "transformers",
    "downloads": 91,
    "likes": 25,
    "tags": [
      "transformers",
      "safetensors",
      "lfm2",
      "text-generation",
      "text-to-speech",
      "en",
      "es",
      "ky",
      "dataset:laion/Emolia",
      "arxiv:2511.23404",
      "arxiv:2501.15907",
      "arxiv:2506.09827",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "google/gemma-3-4b-it",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 1158047,
    "likes": 1179,
    "tags": [
      "transformers",
      "safetensors",
      "gemma3",
      "image-text-to-text",
      "conversational",
      "arxiv:1905.07830",
      "arxiv:1905.10044",
      "arxiv:1911.11641",
      "arxiv:1904.09728",
      "arxiv:1705.03551",
      "arxiv:1911.01547",
      "arxiv:1907.10641",
      "arxiv:1903.00161",
      "arxiv:2009.03300",
      "arxiv:2304.06364",
      "arxiv:2103.03874",
      "arxiv:2110.14168",
      "arxiv:2311.12022",
      "arxiv:2108.07732",
      "arxiv:2107.03374",
      "arxiv:2210.03057",
      "arxiv:2106.03193",
      "arxiv:1910.11856",
      "arxiv:2502.12404",
      "arxiv:2502.21228",
      "arxiv:2404.16816",
      "arxiv:2104.12756",
      "arxiv:2311.16502",
      "arxiv:2203.10244",
      "arxiv:2404.12390",
      "arxiv:1810.12440",
      "arxiv:1908.02660",
      "arxiv:2312.11805",
      "base_model:google/gemma-3-4b-pt",
      "base_model:finetune:google/gemma-3-4b-pt",
      "license:gemma",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-4B-Instruct-2507",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 3373708,
    "likes": 724,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "conversational",
      "arxiv:2505.09388",
      "license:apache-2.0",
      "eval-results",
      "text-generation-inference",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "nvidia/parakeet-ctc-0.6b-Vietnamese",
    "task": "automatic-speech-recognition",
    "library": "nemo",
    "downloads": 2095,
    "likes": 75,
    "tags": [
      "nemo",
      "Nemo",
      "ASR",
      "Pytorch",
      "FastConformer",
      "Parakeet",
      "CTC",
      "automatic-speech-recognition",
      "audio",
      "speech",
      "vi",
      "arxiv:2305.05084",
      "arxiv:2005.08100",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Cordux/flux2-klein-4B-uncensored-text-encoder",
    "task": null,
    "library": null,
    "downloads": 1207,
    "likes": 26,
    "tags": [
      "gguf",
      "qwen3",
      "abliterated",
      "uncensored",
      "text-generation-inference",
      "flux2",
      "klein",
      "base_model:huihui-ai/Qwen3-4B-abliterated",
      "base_model:quantized:huihui-ai/Qwen3-4B-abliterated",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "salakash/Minimalism",
    "task": "text-generation",
    "library": "mlx-lm",
    "downloads": 363,
    "likes": 27,
    "tags": [
      "mlx-lm",
      "qwen2",
      "code",
      "coding-assistant",
      "lora",
      "mlx",
      "apple-silicon",
      "qwen2.5",
      "text-generation",
      "en",
      "dataset:flwrlabs/code-alpaca-20k",
      "dataset:m-a-p/Code-Feedback",
      "base_model:Qwen/Qwen2.5-Coder-0.5B-Instruct",
      "base_model:adapter:Qwen/Qwen2.5-Coder-0.5B-Instruct",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "inclusionAI/ZwZ-8B",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 113,
    "likes": 24,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3_vl",
      "image-text-to-text",
      "conversational",
      "en",
      "dataset:inclusionAI/ZwZ-RL-VQA",
      "dataset:inclusionAI/ZoomBench",
      "arxiv:2602.11858",
      "base_model:Qwen/Qwen3-VL-8B-Instruct",
      "base_model:finetune:Qwen/Qwen3-VL-8B-Instruct",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-NVFP4",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 215294,
    "likes": 98,
    "tags": [
      "transformers",
      "safetensors",
      "nemotron_h",
      "feature-extraction",
      "nvidia",
      "pytorch",
      "text-generation",
      "conversational",
      "custom_code",
      "en",
      "es",
      "fr",
      "de",
      "ja",
      "it",
      "dataset:nvidia/Nemotron-Pretraining-Code-v1",
      "dataset:nvidia/Nemotron-CC-v2",
      "dataset:nvidia/Nemotron-Pretraining-SFT-v1",
      "dataset:nvidia/Nemotron-CC-Math-v1",
      "dataset:nvidia/Nemotron-Pretraining-Code-v2",
      "dataset:nvidia/Nemotron-Pretraining-Specialized-v1",
      "dataset:nvidia/Nemotron-CC-v2.1",
      "dataset:nvidia/Nemotron-CC-Code-v1",
      "dataset:nvidia/Nemotron-Pretraining-Dataset-sample",
      "dataset:nvidia/Nemotron-Competitive-Programming-v1",
      "dataset:nvidia/Nemotron-Math-v2",
      "dataset:nvidia/Nemotron-Agentic-v1",
      "dataset:nvidia/Nemotron-Math-Proofs-v1",
      "dataset:nvidia/Nemotron-Instruction-Following-Chat-v1",
      "dataset:nvidia/Nemotron-Science-v1",
      "dataset:nvidia/Nemotron-3-Nano-RL-Training-Blend",
      "arxiv:2512.20848",
      "arxiv:2512.20856",
      "arxiv:2601.20088",
      "base_model:nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16",
      "base_model:quantized:nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "BennyDaBall/Qwen3-4b-Z-Image-Engineer-V4",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 7060,
    "likes": 28,
    "tags": [
      "transformers",
      "safetensors",
      "gguf",
      "text-generation",
      "prompt-engineering",
      "image-generation",
      "qwen3",
      "en",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen-Image",
    "task": "text-to-image",
    "library": "diffusers",
    "downloads": 152268,
    "likes": 2389,
    "tags": [
      "diffusers",
      "safetensors",
      "text-to-image",
      "en",
      "zh",
      "arxiv:2508.02324",
      "license:apache-2.0",
      "diffusers:QwenImagePipeline",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "nvidia/music-flamingo-2601-hf",
    "task": "audio-text-to-text",
    "library": "transformers",
    "downloads": 10054,
    "likes": 69,
    "tags": [
      "transformers",
      "safetensors",
      "musicflamingo",
      "text-generation",
      "music/songs",
      "music understanding",
      "music reasoning",
      "audio-text-to-text",
      "en",
      "dataset:nvidia/MF-Skills",
      "arxiv:2511.10289",
      "arxiv:2505.13032",
      "license:other",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "ACE-Step/acestep-transcriber",
    "task": "audio-text-to-text",
    "library": "transformers",
    "downloads": 648,
    "likes": 30,
    "tags": [
      "transformers",
      "safetensors",
      "qwen2_5_omni",
      "text-to-audio",
      "music",
      "audio",
      "audio-text-to-text",
      "arxiv:2602.00744",
      "license:mit",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "unsloth/Kimi-K2.5-GGUF",
    "task": null,
    "library": "transformers",
    "downloads": 41761,
    "likes": 210,
    "tags": [
      "transformers",
      "gguf",
      "unsloth",
      "kimi_k25",
      "base_model:moonshotai/Kimi-K2.5",
      "base_model:quantized:moonshotai/Kimi-K2.5",
      "license:other",
      "endpoints_compatible",
      "region:us",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "GuangyuanSD/Z-Image-Distilled",
    "task": "text-to-image",
    "library": null,
    "downloads": 6787,
    "likes": 99,
    "tags": [
      "safetensors",
      "Z",
      "text-to-image",
      "en",
      "zh",
      "base_model:Tongyi-MAI/Z-Image",
      "base_model:finetune:Tongyi-MAI/Z-Image",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "concavity-ai/superlinear-exp-v0.1",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 72,
    "likes": 22,
    "tags": [
      "transformers",
      "safetensors",
      "long-context",
      "superlinear-attention",
      "subquadratic",
      "causal-lm",
      "text-generation",
      "conversational",
      "arxiv:2601.18401",
      "base_model:nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16",
      "base_model:finetune:nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16",
      "license:other",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "unsloth/Qwen3-Coder-30B-A3B-Instruct-GGUF",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 157572,
    "likes": 468,
    "tags": [
      "transformers",
      "gguf",
      "unsloth",
      "qwen3",
      "qwen",
      "text-generation",
      "arxiv:2505.09388",
      "base_model:Qwen/Qwen3-Coder-30B-A3B-Instruct",
      "base_model:quantized:Qwen/Qwen3-Coder-30B-A3B-Instruct",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us",
      "imatrix",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "google/functiongemma-270m-it",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 71764,
    "likes": 899,
    "tags": [
      "transformers",
      "safetensors",
      "gemma3_text",
      "text-generation",
      "gemma3",
      "gemma",
      "google",
      "functiongemma",
      "conversational",
      "license:gemma",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "bakrianoo/arabic-legal-documents-ocr-1.0",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 1111,
    "likes": 21,
    "tags": [
      "transformers",
      "safetensors",
      "gemma3",
      "image-text-to-text",
      "vision",
      "image-to-text",
      "multimodal",
      "ocr",
      "arabic",
      "vllm",
      "lora",
      "llama-factory",
      "conversational",
      "ar",
      "en",
      "dataset:custom",
      "base_model:google/gemma-3-4b-it",
      "base_model:adapter:google/gemma-3-4b-it",
      "license:gemma",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-TTS-12Hz-1.7B-Base",
    "task": null,
    "library": null,
    "downloads": 754392,
    "likes": 308,
    "tags": [
      "safetensors",
      "qwen3_tts",
      "arxiv:2601.15621",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "ACE-Step/acestep-v15-sft",
    "task": "text-to-audio",
    "library": "transformers",
    "downloads": 3623,
    "likes": 34,
    "tags": [
      "transformers",
      "safetensors",
      "acestep",
      "feature-extraction",
      "audio",
      "music",
      "text2music",
      "text-to-audio",
      "custom_code",
      "arxiv:2602.00744",
      "license:mit",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "ACE-Step/acestep-v15-base",
    "task": "text-to-audio",
    "library": "transformers",
    "downloads": 5825,
    "likes": 48,
    "tags": [
      "transformers",
      "safetensors",
      "acestep",
      "feature-extraction",
      "audio",
      "music",
      "text2music",
      "text-to-audio",
      "custom_code",
      "arxiv:2602.00744",
      "license:mit",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Alibaba-DAMO-Academy/RynnBrain-2B",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 283,
    "likes": 21,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3_vl",
      "image-text-to-text",
      "robotics",
      "embodied-ai",
      "egocentric",
      "spatiotemporal",
      "vision-language-model",
      "video-understanding",
      "grounding",
      "planning",
      "navigation",
      "ocr",
      "video-text-to-text",
      "custom_code",
      "conversational",
      "en",
      "zh",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "pyannote/segmentation-3.0",
    "task": "voice-activity-detection",
    "library": "pyannote-audio",
    "downloads": 13773360,
    "likes": 799,
    "tags": [
      "pyannote-audio",
      "pytorch",
      "pyannote",
      "pyannote-audio-model",
      "audio",
      "voice",
      "speech",
      "speaker",
      "speaker-diarization",
      "speaker-change-detection",
      "speaker-segmentation",
      "voice-activity-detection",
      "overlapped-speech-detection",
      "resegmentation",
      "license:mit",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen2.5-Coder-7B-Instruct",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 1349958,
    "likes": 642,
    "tags": [
      "transformers",
      "safetensors",
      "qwen2",
      "text-generation",
      "code",
      "codeqwen",
      "chat",
      "qwen",
      "qwen-coder",
      "conversational",
      "en",
      "arxiv:2409.12186",
      "arxiv:2309.00071",
      "arxiv:2407.10671",
      "base_model:Qwen/Qwen2.5-Coder-7B",
      "base_model:finetune:Qwen/Qwen2.5-Coder-7B",
      "license:apache-2.0",
      "text-generation-inference",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "meta-llama/Llama-3.2-3B-Instruct",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 2224882,
    "likes": 1985,
    "tags": [
      "transformers",
      "safetensors",
      "llama",
      "text-generation",
      "facebook",
      "meta",
      "pytorch",
      "llama-3",
      "conversational",
      "en",
      "de",
      "fr",
      "it",
      "pt",
      "hi",
      "es",
      "th",
      "arxiv:2204.05149",
      "arxiv:2405.16406",
      "license:llama3.2",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Wan-AI/Wan2.2-Animate-14B",
    "task": "video-to-video",
    "library": "diffusers",
    "downloads": 53595,
    "likes": 1044,
    "tags": [
      "diffusers",
      "onnx",
      "safetensors",
      "video-to-video",
      "arxiv:2503.20314",
      "base_model:Wan-AI/Wan2.2-I2V-A14B",
      "base_model:quantized:Wan-AI/Wan2.2-I2V-A14B",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "MiniMaxAI/MiniMax-M2",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 465043,
    "likes": 1484,
    "tags": [
      "transformers",
      "safetensors",
      "minimax_m2",
      "text-generation",
      "conversational",
      "custom_code",
      "arxiv:2504.07164",
      "arxiv:2509.06501",
      "arxiv:2509.13160",
      "license:other",
      "eval-results",
      "endpoints_compatible",
      "fp8",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "nvidia/Cosmos-Reason2-8B",
    "task": "image-text-to-text",
    "library": "cosmos",
    "downloads": 188115,
    "likes": 124,
    "tags": [
      "cosmos",
      "safetensors",
      "qwen3_vl",
      "nvidia",
      "conversational",
      "image-text-to-text",
      "base_model:Qwen/Qwen3-VL-8B-Instruct",
      "base_model:finetune:Qwen/Qwen3-VL-8B-Instruct",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "LiquidAI/LFM2.5-1.2B-Instruct",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 83871,
    "likes": 489,
    "tags": [
      "transformers",
      "safetensors",
      "lfm2",
      "text-generation",
      "liquid",
      "lfm2.5",
      "edge",
      "conversational",
      "en",
      "ar",
      "zh",
      "fr",
      "de",
      "ja",
      "ko",
      "es",
      "arxiv:2511.23404",
      "base_model:LiquidAI/LFM2.5-1.2B-Base",
      "base_model:finetune:LiquidAI/LFM2.5-1.2B-Base",
      "license:other",
      "eval-results",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "tencent/HY3D-Bench",
    "task": "image-to-3d",
    "library": "hunyuan3d-2",
    "downloads": 47,
    "likes": 35,
    "tags": [
      "hunyuan3d-2",
      "image-to-3d",
      "text-to-3d",
      "dataset:tencent/HY3D-Bench",
      "arxiv:2602.03907",
      "arxiv:2509.06784",
      "arxiv:2509.08643",
      "arxiv:2509.21245",
      "arxiv:2506.15442",
      "arxiv:2501.12202",
      "arxiv:2411.02293",
      "base_model:tencent/Hunyuan3D-2.1",
      "base_model:finetune:tencent/Hunyuan3D-2.1",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "trillionlabs/gWorld-8B",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 691,
    "likes": 49,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3_vl",
      "image-text-to-text",
      "conversational",
      "en",
      "ko",
      "arxiv:2602.01576",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-Coder-Next-Base",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 1570,
    "likes": 54,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3_next",
      "text-generation",
      "conversational",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "SnJake/Ref2Font",
    "task": "text-to-image",
    "library": null,
    "downloads": 100,
    "likes": 27,
    "tags": [
      "lora",
      "flux",
      "flux.2",
      "flux.2-klein-9b",
      "image-to-image",
      "text-to-image",
      "font",
      "typography",
      "atlas",
      "comfyui",
      "safetensors",
      "base_model:black-forest-labs/FLUX.2-klein-9B",
      "base_model:adapter:black-forest-labs/FLUX.2-klein-9B",
      "license:mit",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "ortegaalfredo/MechaEpstein-8000-GGUF",
    "task": null,
    "library": null,
    "downloads": 1700,
    "likes": 20,
    "tags": [
      "gguf",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "opendatalab/PDF-Extract-Kit-1.0",
    "task": null,
    "library": null,
    "downloads": 0,
    "likes": 107,
    "tags": [
      "onnx",
      "safetensors",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "google/gemma-3-27b-it",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 1709349,
    "likes": 1872,
    "tags": [
      "transformers",
      "safetensors",
      "gemma3",
      "image-text-to-text",
      "conversational",
      "arxiv:1905.07830",
      "arxiv:1905.10044",
      "arxiv:1911.11641",
      "arxiv:1904.09728",
      "arxiv:1705.03551",
      "arxiv:1911.01547",
      "arxiv:1907.10641",
      "arxiv:1903.00161",
      "arxiv:2009.03300",
      "arxiv:2304.06364",
      "arxiv:2103.03874",
      "arxiv:2110.14168",
      "arxiv:2311.12022",
      "arxiv:2108.07732",
      "arxiv:2107.03374",
      "arxiv:2210.03057",
      "arxiv:2106.03193",
      "arxiv:1910.11856",
      "arxiv:2502.12404",
      "arxiv:2502.21228",
      "arxiv:2404.16816",
      "arxiv:2104.12756",
      "arxiv:2311.16502",
      "arxiv:2203.10244",
      "arxiv:2404.12390",
      "arxiv:1810.12440",
      "arxiv:1908.02660",
      "arxiv:2312.11805",
      "base_model:google/gemma-3-27b-pt",
      "base_model:finetune:google/gemma-3-27b-pt",
      "license:gemma",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "fishaudio/s1-mini",
    "task": "text-to-speech",
    "library": null,
    "downloads": 4928,
    "likes": 584,
    "tags": [
      "dual_ar",
      "text-to-speech",
      "zh",
      "en",
      "de",
      "ja",
      "fr",
      "es",
      "ko",
      "ar",
      "nl",
      "ru",
      "it",
      "pl",
      "pt",
      "license:cc-by-nc-sa-4.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "google/gemma-3n-E2B-it-litert-lm",
    "task": "text-generation",
    "library": "litert-lm",
    "downloads": 20060,
    "likes": 344,
    "tags": [
      "litert-lm",
      "text-generation",
      "arxiv:1905.07830",
      "arxiv:1905.10044",
      "arxiv:1911.11641",
      "arxiv:1904.09728",
      "arxiv:1705.03551",
      "arxiv:1911.01547",
      "arxiv:1907.10641",
      "arxiv:1903.00161",
      "arxiv:2210.03057",
      "arxiv:2502.12404",
      "arxiv:2411.19799",
      "arxiv:2009.03300",
      "arxiv:2502.21228",
      "arxiv:2311.12022",
      "arxiv:2403.07974",
      "arxiv:2108.07732",
      "arxiv:2107.03374",
      "license:gemma",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "google/gemma-3n-E4B-it-litert-lm",
    "task": "text-generation",
    "library": "litert-lm",
    "downloads": 21165,
    "likes": 334,
    "tags": [
      "litert-lm",
      "text-generation",
      "arxiv:1905.07830",
      "arxiv:1905.10044",
      "arxiv:1911.11641",
      "arxiv:1904.09728",
      "arxiv:1705.03551",
      "arxiv:1911.01547",
      "arxiv:1907.10641",
      "arxiv:1903.00161",
      "arxiv:2210.03057",
      "arxiv:2502.12404",
      "arxiv:2411.19799",
      "arxiv:2009.03300",
      "arxiv:2502.21228",
      "arxiv:2311.12022",
      "arxiv:2403.07974",
      "arxiv:2108.07732",
      "arxiv:2107.03374",
      "license:gemma",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "unsloth/gpt-oss-20b-GGUF",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 156928,
    "likes": 590,
    "tags": [
      "transformers",
      "gguf",
      "gpt_oss",
      "text-generation",
      "openai",
      "unsloth",
      "base_model:openai/gpt-oss-20b",
      "base_model:quantized:openai/gpt-oss-20b",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen-Image-Edit-2511",
    "task": "image-to-image",
    "library": "diffusers",
    "downloads": 125039,
    "likes": 807,
    "tags": [
      "diffusers",
      "safetensors",
      "image-to-image",
      "en",
      "zh",
      "arxiv:2508.02324",
      "license:apache-2.0",
      "diffusers:QwenImageEditPlusPipeline",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Kijai/LTXV2_comfy",
    "task": null,
    "library": null,
    "downloads": 107350,
    "likes": 408,
    "tags": [
      "gguf",
      "comfyui",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "inclusionAI/UI-Venus-1.5-8B",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 381,
    "likes": 19,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3_vl",
      "image-text-to-text",
      "multimodel",
      "gui",
      "agent",
      "conversational",
      "arxiv:2602.09082",
      "arxiv:2508.10833",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "black-forest-labs/FLUX.1-schnell",
    "task": "text-to-image",
    "library": "diffusers",
    "downloads": 661385,
    "likes": 4610,
    "tags": [
      "diffusers",
      "safetensors",
      "text-to-image",
      "image-generation",
      "flux",
      "en",
      "license:apache-2.0",
      "endpoints_compatible",
      "diffusers:FluxPipeline",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "deepseek-ai/DeepSeek-OCR",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 2981893,
    "likes": 3149,
    "tags": [
      "transformers",
      "safetensors",
      "deepseek_vl_v2",
      "feature-extraction",
      "deepseek",
      "vision-language",
      "ocr",
      "custom_code",
      "image-text-to-text",
      "multilingual",
      "arxiv:2510.18234",
      "license:mit",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "kpsss34/FHDR_Uncensored",
    "task": "text-to-image",
    "library": "diffusers",
    "downloads": 8082,
    "likes": 118,
    "tags": [
      "diffusers",
      "safetensors",
      "gguf",
      "art",
      "text-to-image",
      "en",
      "base_model:black-forest-labs/FLUX.1-dev",
      "base_model:quantized:black-forest-labs/FLUX.1-dev",
      "license:other",
      "endpoints_compatible",
      "diffusers:FluxPipeline",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "unsloth/MiniMax-M2.1-GGUF",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 59069,
    "likes": 187,
    "tags": [
      "transformers",
      "gguf",
      "unsloth",
      "minimax_m2",
      "text-generation",
      "arxiv:2509.06501",
      "base_model:MiniMaxAI/MiniMax-M2.1",
      "base_model:quantized:MiniMaxAI/MiniMax-M2.1",
      "license:other",
      "endpoints_compatible",
      "region:us",
      "imatrix",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-VL-Embedding-8B",
    "task": "feature-extraction",
    "library": "transformers",
    "downloads": 366319,
    "likes": 345,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3_vl",
      "image-text-to-text",
      "multimodal embedding",
      "qwen",
      "embedding",
      "feature-extraction",
      "arxiv:2601.04720",
      "base_model:Qwen/Qwen3-VL-8B-Instruct",
      "base_model:finetune:Qwen/Qwen3-VL-8B-Instruct",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "RuneXX/LTX-2-Workflows",
    "task": null,
    "library": null,
    "downloads": 0,
    "likes": 241,
    "tags": [
      "ltx",
      "ltx-2",
      "comfyui",
      "comfy",
      "GGUF",
      "ltx-video",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "fashn-ai/fashn-vton-1.5",
    "task": "image-to-image",
    "library": "pytorch",
    "downloads": 0,
    "likes": 86,
    "tags": [
      "pytorch",
      "safetensors",
      "virtual-try-on",
      "diffusion",
      "mmdit",
      "fashion",
      "image-generation",
      "pixel-space",
      "image-to-image",
      "en",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-TTS-12Hz-1.7B-VoiceDesign",
    "task": "text-to-speech",
    "library": "qwen-tts",
    "downloads": 313152,
    "likes": 251,
    "tags": [
      "qwen-tts",
      "safetensors",
      "qwen3_tts",
      "audio",
      "tts",
      "qwen",
      "multilingual",
      "text-to-speech",
      "arxiv:2601.15621",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "inclusionAI/UI-Venus-1.5-30B-A3B",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 268,
    "likes": 18,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3_vl_moe",
      "image-text-to-text",
      "multimodel",
      "gui",
      "agent",
      "conversational",
      "arxiv:2602.09082",
      "arxiv:2508.10833",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen2.5-7B-Instruct",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 12142981,
    "likes": 1072,
    "tags": [
      "transformers",
      "safetensors",
      "qwen2",
      "text-generation",
      "chat",
      "conversational",
      "en",
      "arxiv:2309.00071",
      "arxiv:2407.10671",
      "base_model:Qwen/Qwen2.5-7B",
      "base_model:finetune:Qwen/Qwen2.5-7B",
      "license:apache-2.0",
      "text-generation-inference",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "openai/whisper-large-v3-turbo",
    "task": "automatic-speech-recognition",
    "library": "transformers",
    "downloads": 3131711,
    "likes": 2821,
    "tags": [
      "transformers",
      "safetensors",
      "whisper",
      "automatic-speech-recognition",
      "audio",
      "en",
      "zh",
      "de",
      "es",
      "ru",
      "ko",
      "fr",
      "ja",
      "pt",
      "tr",
      "pl",
      "ca",
      "nl",
      "ar",
      "sv",
      "it",
      "id",
      "hi",
      "fi",
      "vi",
      "he",
      "uk",
      "el",
      "ms",
      "cs",
      "ro",
      "da",
      "hu",
      "ta",
      "no",
      "th",
      "ur",
      "hr",
      "bg",
      "lt",
      "la",
      "mi",
      "ml",
      "cy",
      "sk",
      "te",
      "fa",
      "lv",
      "bn",
      "sr",
      "az",
      "sl",
      "kn",
      "et",
      "mk",
      "br",
      "eu",
      "is",
      "hy",
      "ne",
      "mn",
      "bs",
      "kk",
      "sq",
      "sw",
      "gl",
      "mr",
      "pa",
      "si",
      "km",
      "sn",
      "yo",
      "so",
      "af",
      "oc",
      "ka",
      "be",
      "tg",
      "sd",
      "gu",
      "am",
      "yi",
      "lo",
      "uz",
      "fo",
      "ht",
      "ps",
      "tk",
      "nn",
      "mt",
      "sa",
      "lb",
      "my",
      "bo",
      "tl",
      "mg",
      "as",
      "tt",
      "haw",
      "ln",
      "ha",
      "ba",
      "jw",
      "su",
      "arxiv:2212.04356",
      "base_model:openai/whisper-large-v3",
      "base_model:finetune:openai/whisper-large-v3",
      "license:mit",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "FunAudioLLM/Fun-CosyVoice3-0.5B-2512",
    "task": "text-to-speech",
    "library": null,
    "downloads": 4439,
    "likes": 457,
    "tags": [
      "onnx",
      "safetensors",
      "text-to-speech",
      "zh",
      "en",
      "fr",
      "es",
      "ja",
      "ko",
      "it",
      "ru",
      "de",
      "arxiv:2505.17589",
      "arxiv:2412.10117",
      "arxiv:2407.05407",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen-Image-2512",
    "task": "text-to-image",
    "library": "diffusers",
    "downloads": 160079,
    "likes": 663,
    "tags": [
      "diffusers",
      "safetensors",
      "text-to-image",
      "en",
      "zh",
      "arxiv:2508.02324",
      "license:apache-2.0",
      "diffusers:QwenImagePipeline",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Soul-AILab/SoulX-FlashHead-1_3B",
    "task": "image-to-video",
    "library": "diffusers",
    "downloads": 0,
    "likes": 17,
    "tags": [
      "diffusers",
      "safetensors",
      "image-to-video",
      "dataset:Soul-AILab/VividHead",
      "arxiv:2602.07449",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "YatharthS/LavaSR",
    "task": "audio-to-audio",
    "library": null,
    "downloads": 109,
    "likes": 17,
    "tags": [
      "audio-to-audio",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "jdopensource/JoyAI-LLM-Flash-Base",
    "task": "text-generation",
    "library": null,
    "downloads": 37,
    "likes": 17,
    "tags": [
      "safetensors",
      "joyai_llm_flash",
      "text-generation",
      "custom_code",
      "zh",
      "en",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Kijai/WanVideo_comfy",
    "task": null,
    "library": "diffusion-single-file",
    "downloads": 6831902,
    "likes": 2092,
    "tags": [
      "diffusion-single-file",
      "comfyui",
      "base_model:Wan-AI/Wan2.1-VACE-1.3B",
      "base_model:finetune:Wan-AI/Wan2.1-VACE-1.3B",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-Embedding-8B",
    "task": "feature-extraction",
    "library": "sentence-transformers",
    "downloads": 1768428,
    "likes": 582,
    "tags": [
      "sentence-transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "transformers",
      "sentence-similarity",
      "feature-extraction",
      "text-embeddings-inference",
      "arxiv:2506.05176",
      "base_model:Qwen/Qwen3-8B-Base",
      "base_model:finetune:Qwen/Qwen3-8B-Base",
      "license:apache-2.0",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "LGAI-EXAONE/EXAONE-4.0-1.2B",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 70250,
    "likes": 165,
    "tags": [
      "transformers",
      "safetensors",
      "exaone4",
      "text-generation",
      "lg-ai",
      "exaone",
      "exaone-4.0",
      "conversational",
      "en",
      "ko",
      "es",
      "arxiv:2507.11407",
      "license:other",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-Omni-30B-A3B-Instruct",
    "task": "any-to-any",
    "library": "transformers",
    "downloads": 727636,
    "likes": 847,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3_omni_moe",
      "text-to-audio",
      "multimodal",
      "any-to-any",
      "en",
      "license:other",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "p-e-w/gemma-3-12b-it-heretic",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 684,
    "likes": 43,
    "tags": [
      "transformers",
      "safetensors",
      "gemma3",
      "image-text-to-text",
      "heretic",
      "uncensored",
      "decensored",
      "abliterated",
      "conversational",
      "arxiv:1905.07830",
      "arxiv:1905.10044",
      "arxiv:1911.11641",
      "arxiv:1904.09728",
      "arxiv:1705.03551",
      "arxiv:1911.01547",
      "arxiv:1907.10641",
      "arxiv:1903.00161",
      "arxiv:2009.03300",
      "arxiv:2304.06364",
      "arxiv:2103.03874",
      "arxiv:2110.14168",
      "arxiv:2311.12022",
      "arxiv:2108.07732",
      "arxiv:2107.03374",
      "arxiv:2210.03057",
      "arxiv:2106.03193",
      "arxiv:1910.11856",
      "arxiv:2502.12404",
      "arxiv:2502.21228",
      "arxiv:2404.16816",
      "arxiv:2104.12756",
      "arxiv:2311.16502",
      "arxiv:2203.10244",
      "arxiv:2404.12390",
      "arxiv:1810.12440",
      "arxiv:1908.02660",
      "arxiv:2312.11805",
      "base_model:google/gemma-3-12b-pt",
      "base_model:finetune:google/gemma-3-12b-pt",
      "license:gemma",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "nvidia/Qwen3-Next-80B-A3B-Thinking-NVFP4",
    "task": "text-generation",
    "library": "Model Optimizer",
    "downloads": 59393,
    "likes": 44,
    "tags": [
      "Model Optimizer",
      "safetensors",
      "qwen3_next",
      "nvidia",
      "ModelOpt",
      "Qwen3",
      "quantized",
      "NVFP4",
      "nvfp4",
      "text-generation",
      "conversational",
      "base_model:Qwen/Qwen3-Next-80B-A3B-Thinking",
      "base_model:quantized:Qwen/Qwen3-Next-80B-A3B-Thinking",
      "license:apache-2.0",
      "modelopt",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "voyageai/voyage-4-nano",
    "task": "feature-extraction",
    "library": "sentence-transformers",
    "downloads": 51961,
    "likes": 85,
    "tags": [
      "sentence-transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "transformers",
      "feature-extraction",
      "custom_code",
      "multilingual",
      "license:apache-2.0",
      "text-embeddings-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-VL-Embedding-2B",
    "task": "feature-extraction",
    "library": "transformers",
    "downloads": 719321,
    "likes": 313,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3_vl",
      "image-text-to-text",
      "multimodal embedding",
      "qwen",
      "embedding",
      "feature-extraction",
      "arxiv:2601.04720",
      "base_model:Qwen/Qwen3-VL-2B-Instruct",
      "base_model:finetune:Qwen/Qwen3-VL-2B-Instruct",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "ACE-Step/acestep-captioner",
    "task": "text-to-audio",
    "library": "transformers",
    "downloads": 1180,
    "likes": 32,
    "tags": [
      "transformers",
      "safetensors",
      "qwen2_5_omni",
      "text-to-audio",
      "music",
      "audio",
      "arxiv:2602.00744",
      "license:mit",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "unsloth/Z-Image-GGUF",
    "task": "text-to-image",
    "library": "ggml",
    "downloads": 26194,
    "likes": 108,
    "tags": [
      "ggml",
      "gguf",
      "unsloth",
      "quantized",
      "text-to-image",
      "en",
      "arxiv:2511.22699",
      "base_model:Tongyi-MAI/Z-Image",
      "base_model:quantized:Tongyi-MAI/Z-Image",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "ubergarm/Step-3.5-Flash-GGUF",
    "task": "text-generation",
    "library": null,
    "downloads": 6272,
    "likes": 29,
    "tags": [
      "gguf",
      "imatrix",
      "conversational",
      "ik_llama.cpp",
      "step3p5",
      "text-generation",
      "base_model:stepfun-ai/Step-3.5-Flash",
      "base_model:quantized:stepfun-ai/Step-3.5-Flash",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Aryanne/acestep-v15-test-merges",
    "task": null,
    "library": null,
    "downloads": 0,
    "likes": 16,
    "tags": [
      "merge",
      "base_model:ACE-Step/Ace-Step1.5",
      "base_model:merge:ACE-Step/Ace-Step1.5",
      "base_model:ACE-Step/acestep-v15-base",
      "base_model:merge:ACE-Step/acestep-v15-base",
      "license:mit",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "OpenMOSS-Team/MOSS-SoundEffect",
    "task": "text-to-audio",
    "library": null,
    "downloads": 792,
    "likes": 16,
    "tags": [
      "safetensors",
      "moss_tts_delay",
      "text-to-audio",
      "custom_code",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Edge-Quant/Nanbeige4.1-3B-Q4_K_M-GGUF",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 2545,
    "likes": 16,
    "tags": [
      "transformers",
      "gguf",
      "llm",
      "nanbeige",
      "llama-cpp",
      "gguf-my-repo",
      "text-generation",
      "en",
      "zh",
      "base_model:Nanbeige/Nanbeige4.1-3B",
      "base_model:quantized:Nanbeige/Nanbeige4.1-3B",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "cocorang/FireRed-Image-Edit-1.0-FP8_And_BF16",
    "task": null,
    "library": null,
    "downloads": 0,
    "likes": 16,
    "tags": [
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "medicalai/ClinicalBERT",
    "task": "fill-mask",
    "library": "transformers",
    "downloads": 49536,
    "likes": 336,
    "tags": [
      "transformers",
      "pytorch",
      "distilbert",
      "fill-mask",
      "medical",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "coqui/XTTS-v2",
    "task": "text-to-speech",
    "library": "coqui",
    "downloads": 6504033,
    "likes": 3391,
    "tags": [
      "coqui",
      "text-to-speech",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "deepseek-ai/DeepSeek-R1",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 539731,
    "likes": 13009,
    "tags": [
      "transformers",
      "safetensors",
      "deepseek_v3",
      "text-generation",
      "conversational",
      "custom_code",
      "arxiv:2501.12948",
      "license:mit",
      "eval-results",
      "text-generation-inference",
      "endpoints_compatible",
      "fp8",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "openbmb/MiniCPM-V-4_5",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 73538,
    "likes": 1064,
    "tags": [
      "transformers",
      "safetensors",
      "minicpmv",
      "feature-extraction",
      "minicpm-v",
      "vision",
      "ocr",
      "multi-image",
      "video",
      "custom_code",
      "image-text-to-text",
      "conversational",
      "multilingual",
      "dataset:openbmb/RLAIF-V-Dataset",
      "arxiv:2509.18154",
      "arxiv:2403.11703",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "fdtn-ai/Foundation-Sec-8B-Reasoning",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 2196,
    "likes": 32,
    "tags": [
      "transformers",
      "safetensors",
      "llama",
      "text-generation",
      "security",
      "fdtn-sec",
      "conversational",
      "en",
      "arxiv:2601.21051",
      "base_model:fdtn-ai/Foundation-Sec-8B",
      "base_model:finetune:fdtn-ai/Foundation-Sec-8B",
      "license:other",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 861882,
    "likes": 630,
    "tags": [
      "transformers",
      "safetensors",
      "nemotron_h",
      "feature-extraction",
      "nvidia",
      "pytorch",
      "text-generation",
      "conversational",
      "custom_code",
      "en",
      "es",
      "fr",
      "de",
      "ja",
      "it",
      "dataset:nvidia/Nemotron-Pretraining-Code-v1",
      "dataset:nvidia/Nemotron-CC-v2",
      "dataset:nvidia/Nemotron-Pretraining-SFT-v1",
      "dataset:nvidia/Nemotron-CC-Math-v1",
      "dataset:nvidia/Nemotron-Pretraining-Code-v2",
      "dataset:nvidia/Nemotron-Pretraining-Specialized-v1",
      "dataset:nvidia/Nemotron-CC-v2.1",
      "dataset:nvidia/Nemotron-CC-Code-v1",
      "dataset:nvidia/Nemotron-Pretraining-Dataset-sample",
      "dataset:nvidia/Nemotron-Competitive-Programming-v1",
      "dataset:nvidia/Nemotron-Math-v2",
      "dataset:nvidia/Nemotron-Agentic-v1",
      "dataset:nvidia/Nemotron-Math-Proofs-v1",
      "dataset:nvidia/Nemotron-Instruction-Following-Chat-v1",
      "dataset:nvidia/Nemotron-Science-v1",
      "dataset:nvidia/Nemotron-3-Nano-RL-Training-Blend",
      "arxiv:2512.20848",
      "arxiv:2512.20856",
      "license:other",
      "eval-results",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "PaddlePaddle/PP-DocLayoutV3",
    "task": "image-segmentation",
    "library": "PaddleOCR",
    "downloads": 8679,
    "likes": 41,
    "tags": [
      "PaddleOCR",
      "PaddlePaddle",
      "image-segmentation",
      "ocr",
      "layout",
      "layout_detection",
      "en",
      "zh",
      "multilingual",
      "arxiv:2601.21957",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "YatharthS/LuxTTS",
    "task": "text-to-speech",
    "library": null,
    "downloads": 2296,
    "likes": 135,
    "tags": [
      "onnx",
      "text-to-speech",
      "en",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "wikeeyang/Flux2-Klein-9B-True-V1",
    "task": "text-to-image",
    "library": "diffusers",
    "downloads": 6931,
    "likes": 67,
    "tags": [
      "diffusers",
      "gguf",
      "text-to-image",
      "en",
      "zh",
      "base_model:black-forest-labs/FLUX.2-klein-9B",
      "base_model:finetune:black-forest-labs/FLUX.2-klein-9B",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "nvidia/C-RADIOv4-H",
    "task": "feature-extraction",
    "library": "transformers",
    "downloads": 8096,
    "likes": 48,
    "tags": [
      "transformers",
      "safetensors",
      "feature-extraction",
      "custom_code",
      "arxiv:2312.06709",
      "arxiv:2410.01680",
      "arxiv:2412.07679",
      "arxiv:2502.16025",
      "arxiv:2601.17237",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "MachineDelusions/LTX-2_Image2Video_Adapter_LoRa",
    "task": null,
    "library": null,
    "downloads": 0,
    "likes": 126,
    "tags": [
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "CodeGoat24/FLUX.2-klein-base-9B-UnifiedReward-Flex-lora",
    "task": "text-to-image",
    "library": "diffusers",
    "downloads": 305,
    "likes": 15,
    "tags": [
      "diffusers",
      "text-to-image",
      "arxiv:2602.02380",
      "base_model:black-forest-labs/FLUX.2-klein-base-9B",
      "base_model:finetune:black-forest-labs/FLUX.2-klein-base-9B",
      "license:mit",
      "region:us"
    ],
    "description": ""
  }
]