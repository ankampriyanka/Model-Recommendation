[
  {
    "id": "zai-org/GLM-Image",
    "task": "text-to-image",
    "library": "diffusers",
    "downloads": 6635,
    "likes": 838,
    "tags": [
      "diffusers",
      "safetensors",
      "text-to-image",
      "zh",
      "en",
      "license:mit",
      "diffusers:GlmImagePipeline",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Lightricks/LTX-2",
    "task": "image-to-video",
    "library": "ltx-2",
    "downloads": 1540901,
    "likes": 1152,
    "tags": [
      "ltx-2",
      "diffusers",
      "safetensors",
      "image-to-video",
      "text-to-video",
      "video-to-video",
      "image-text-to-video",
      "audio-to-video",
      "text-to-audio",
      "video-to-audio",
      "audio-to-audio",
      "text-to-audio-video",
      "image-to-audio-video",
      "image-text-to-audio-video",
      "ltx-video",
      "ltxv",
      "lightricks",
      "en",
      "de",
      "es",
      "fr",
      "ja",
      "ko",
      "zh",
      "it",
      "pt",
      "arxiv:2601.03233",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "fal/Qwen-Image-Edit-2511-Multiple-Angles-LoRA",
    "task": "image-to-image",
    "library": "diffusers",
    "downloads": 53066,
    "likes": 751,
    "tags": [
      "diffusers",
      "qwen",
      "qwen-image-edit",
      "qwen-image-edit-2511",
      "lora",
      "multi-angle",
      "camera-angles",
      "camera-control",
      "image-editing",
      "image-to-image",
      "gaussian-splatting",
      "fal",
      "en",
      "base_model:Qwen/Qwen-Image-Edit-2511",
      "base_model:adapter:Qwen/Qwen-Image-Edit-2511",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "openbmb/AgentCPM-Explore",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 1548,
    "likes": 346,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "conversational",
      "en",
      "base_model:Qwen/Qwen3-4B-Thinking-2507",
      "base_model:finetune:Qwen/Qwen3-4B-Thinking-2507",
      "license:apache-2.0",
      "eval-results",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "google/translategemma-4b-it",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 12782,
    "likes": 310,
    "tags": [
      "transformers",
      "safetensors",
      "gemma3",
      "image-to-text",
      "image-text-to-text",
      "conversational",
      "arxiv:2601.09012",
      "arxiv:2503.19786",
      "license:gemma",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "kyutai/pocket-tts",
    "task": null,
    "library": "pocket-tts",
    "downloads": 21697,
    "likes": 290,
    "tags": [
      "pocket-tts",
      "en",
      "arxiv:2509.06926",
      "license:cc-by-4.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "google/medgemma-1.5-4b-it",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 21481,
    "likes": 268,
    "tags": [
      "transformers",
      "safetensors",
      "gemma3",
      "image-to-text",
      "medical",
      "radiology",
      "clinical-reasoning",
      "dermatology",
      "pathology",
      "ophthalmology",
      "chest-x-ray",
      "image-text-to-text",
      "conversational",
      "arxiv:2303.15343",
      "arxiv:2507.05201",
      "arxiv:2406.19578",
      "arxiv:2405.03162",
      "arxiv:2106.14463",
      "arxiv:2009.13081",
      "arxiv:2203.14371",
      "arxiv:1909.06146",
      "arxiv:2102.09542",
      "arxiv:2411.15640",
      "arxiv:2404.05590",
      "arxiv:2501.18362",
      "arxiv:1605.01397",
      "arxiv:1901.07031",
      "arxiv:2403.17834",
      "arxiv:2402.16040",
      "license:other",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Supertone/supertonic-2",
    "task": "text-to-speech",
    "library": "supertonic",
    "downloads": 12781,
    "likes": 292,
    "tags": [
      "supertonic",
      "onnx",
      "text-to-speech",
      "speech-synthesis",
      "tts",
      "en",
      "ko",
      "es",
      "pt",
      "fr",
      "license:openrail",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "google/translategemma-27b-it",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 9345,
    "likes": 193,
    "tags": [
      "transformers",
      "safetensors",
      "gemma3",
      "image-to-text",
      "image-text-to-text",
      "conversational",
      "arxiv:2601.09012",
      "arxiv:2503.19786",
      "license:gemma",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "black-forest-labs/FLUX.2-klein-4B",
    "task": "image-to-image",
    "library": "diffusers",
    "downloads": 14899,
    "likes": 189,
    "tags": [
      "diffusers",
      "safetensors",
      "text-to-image",
      "image-editing",
      "flux",
      "diffusion-single-file",
      "image-to-image",
      "en",
      "license:apache-2.0",
      "diffusers:Flux2KleinPipeline",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "black-forest-labs/FLUX.2-klein-9B",
    "task": "image-to-image",
    "library": "diffusers",
    "downloads": 11691,
    "likes": 182,
    "tags": [
      "diffusers",
      "safetensors",
      "image-generation",
      "image-editing",
      "flux",
      "diffusion-single-file",
      "image-to-image",
      "en",
      "license:other",
      "diffusers:Flux2KleinPipeline",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Kijai/LTXV2_comfy",
    "task": null,
    "library": null,
    "downloads": 55510,
    "likes": 309,
    "tags": [
      "gguf",
      "comfyui",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-VL-Embedding-8B",
    "task": "image-to-text",
    "library": "transformers",
    "downloads": 46200,
    "likes": 278,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3_vl",
      "image-to-text",
      "multimodal embedding",
      "base_model:Qwen/Qwen3-VL-8B-Instruct",
      "base_model:finetune:Qwen/Qwen3-VL-8B-Instruct",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "google/translategemma-12b-it",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 9133,
    "likes": 140,
    "tags": [
      "transformers",
      "safetensors",
      "gemma3",
      "image-to-text",
      "image-text-to-text",
      "conversational",
      "arxiv:2601.09012",
      "arxiv:2503.19786",
      "license:gemma",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "zai-org/GLM-4.7",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 67833,
    "likes": 1680,
    "tags": [
      "transformers",
      "safetensors",
      "glm4_moe",
      "text-generation",
      "conversational",
      "en",
      "zh",
      "arxiv:2508.06471",
      "license:mit",
      "eval-results",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Tongyi-MAI/Z-Image-Turbo",
    "task": "text-to-image",
    "library": "diffusers",
    "downloads": 418697,
    "likes": 3822,
    "tags": [
      "diffusers",
      "safetensors",
      "text-to-image",
      "en",
      "arxiv:2511.22699",
      "arxiv:2511.22677",
      "arxiv:2511.13649",
      "license:apache-2.0",
      "diffusers:ZImagePipeline",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-VL-Embedding-2B",
    "task": "image-to-text",
    "library": "transformers",
    "downloads": 65971,
    "likes": 248,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3_vl",
      "image-to-text",
      "multimodal embedding",
      "base_model:Qwen/Qwen3-VL-2B-Instruct",
      "base_model:finetune:Qwen/Qwen3-VL-2B-Instruct",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "nvidia/nemotron-speech-streaming-en-0.6b",
    "task": "automatic-speech-recognition",
    "library": "nemo",
    "downloads": 6359,
    "likes": 395,
    "tags": [
      "nemo",
      "speech-recognition",
      "cache-aware ASR",
      "automatic-speech-recognition",
      "streaming-asr",
      "speech",
      "audio",
      "FastConformer",
      "RNNT",
      "Parakeet",
      "ASR",
      "pytorch",
      "NeMo",
      "dataset:nvidia/Granary",
      "dataset:YTC",
      "dataset:Yodas2",
      "dataset:LibriLight",
      "dataset:librispeech_asr",
      "dataset:fisher_corpus",
      "dataset:Switchboard-1",
      "dataset:WSJ-0",
      "dataset:WSJ-1",
      "dataset:National-Singapore-Corpus-Part-1",
      "dataset:National-Singapore-Corpus-Part-6",
      "dataset:vctk",
      "dataset:voxpopuli",
      "dataset:europarl",
      "dataset:multilingual_librispeech",
      "dataset:fleurs",
      "dataset:mozilla-foundation/common_voice_8_0",
      "dataset:MLCommons/peoples_speech",
      "dataset:google/speech_commands",
      "arxiv:2312.17279",
      "arxiv:2305.05084",
      "license:other",
      "model-index",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "stepfun-ai/Step3-VL-10B",
    "task": "image-text-to-text",
    "library": null,
    "downloads": 4963,
    "likes": 116,
    "tags": [
      "safetensors",
      "step_robotics",
      "image-text-to-text",
      "conversational",
      "custom_code",
      "arxiv:2601.09668",
      "base_model:stepfun-ai/Step3-VL-10B-Base",
      "base_model:finetune:stepfun-ai/Step3-VL-10B-Base",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "LiquidAI/LFM2.5-1.2B-Instruct",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 47561,
    "likes": 369,
    "tags": [
      "transformers",
      "safetensors",
      "lfm2",
      "text-generation",
      "liquid",
      "lfm2.5",
      "edge",
      "conversational",
      "en",
      "ar",
      "zh",
      "fr",
      "de",
      "ja",
      "ko",
      "es",
      "arxiv:2511.23404",
      "base_model:LiquidAI/LFM2.5-1.2B-Base",
      "base_model:finetune:LiquidAI/LFM2.5-1.2B-Base",
      "license:other",
      "eval-results",
      "endpoints_compatible",
      "region:us",
      "deploy:azure"
    ],
    "description": ""
  },
  {
    "id": "black-forest-labs/FLUX.2-klein-base-9B",
    "task": "image-to-image",
    "library": "diffusers",
    "downloads": 4600,
    "likes": 105,
    "tags": [
      "diffusers",
      "safetensors",
      "image-generation",
      "image-editing",
      "flux",
      "diffusion-single-file",
      "image-to-image",
      "en",
      "license:other",
      "diffusers:Flux2KleinPipeline",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "dx8152/Qwen-Image-Edit-2511-Gaussian-Splash",
    "task": "image-to-image",
    "library": null,
    "downloads": 0,
    "likes": 103,
    "tags": [
      "lora",
      "image-to-image",
      "base_model:Qwen/Qwen-Image-Edit-2511",
      "base_model:adapter:Qwen/Qwen-Image-Edit-2511",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Phr00t/LTX2-Rapid-Merges",
    "task": "image-text-to-video",
    "library": null,
    "downloads": 0,
    "likes": 97,
    "tags": [
      "ltx2",
      "t2v",
      "i2v",
      "image-text-to-video",
      "base_model:Lightricks/LTX-2",
      "base_model:finetune:Lightricks/LTX-2",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Phr00t/Qwen-Image-Edit-Rapid-AIO",
    "task": "text-to-image",
    "library": "comfyUI",
    "downloads": 0,
    "likes": 1406,
    "tags": [
      "comfyUI",
      "qwen",
      "qwen-edit",
      "t2i",
      "i2i",
      "text-to-image",
      "base_model:Qwen/Qwen-Image-Edit-2511",
      "base_model:finetune:Qwen/Qwen-Image-Edit-2511",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "MiniMaxAI/MiniMax-M2.1",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 233206,
    "likes": 1094,
    "tags": [
      "transformers",
      "safetensors",
      "minimax_m2",
      "text-generation",
      "conversational",
      "custom_code",
      "arxiv:2509.06501",
      "license:other",
      "eval-results",
      "endpoints_compatible",
      "fp8",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-VL-Reranker-2B",
    "task": "image-to-text",
    "library": "transformers",
    "downloads": 66253,
    "likes": 133,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3_vl",
      "image-to-text",
      "multimodal rerank",
      "base_model:Qwen/Qwen3-VL-2B-Instruct",
      "base_model:finetune:Qwen/Qwen3-VL-2B-Instruct",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "nvidia/personaplex-7b-v1",
    "task": null,
    "library": "moshi",
    "downloads": 0,
    "likes": 81,
    "tags": [
      "moshi",
      "safetensors",
      "personaplex",
      "en",
      "arxiv:2503.04721",
      "arxiv:2110.13900",
      "arxiv:2410.00037",
      "base_model:kyutai/moshiko-pytorch-bf16",
      "base_model:finetune:kyutai/moshiko-pytorch-bf16",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "FutureMa/Eva-4B",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 230,
    "likes": 81,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "finance",
      "earnings-calls",
      "financial-nlp",
      "text-classification",
      "llm-as-judge",
      "distillation",
      "conversational",
      "en",
      "arxiv:2601.09142",
      "base_model:Qwen/Qwen3-4B-Instruct-2507",
      "base_model:finetune:Qwen/Qwen3-4B-Instruct-2507",
      "license:apache-2.0",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "stepfun-ai/Step-Audio-R1.1",
    "task": "audio-text-to-text",
    "library": "transformers",
    "downloads": 238,
    "likes": 79,
    "tags": [
      "transformers",
      "safetensors",
      "step_audio_2",
      "text-generation",
      "audio-reasoning",
      "chain-of-thought",
      "multi-modal",
      "step-audio-r1",
      "audio-text-to-text",
      "custom_code",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "ekwek/Soprano-1.1-80M",
    "task": "text-to-speech",
    "library": "transformers",
    "downloads": 2546,
    "likes": 76,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "text-to-speech",
      "license:apache-2.0",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "NousResearch/NousCoder-14B",
    "task": "text-generation",
    "library": null,
    "downloads": 1631,
    "likes": 156,
    "tags": [
      "safetensors",
      "qwen3",
      "text-generation",
      "conversational",
      "dataset:livecodebench/code_generation_lite",
      "dataset:agentica-org/DeepCoder-Preview-Dataset",
      "dataset:NousResearch/lcb_test",
      "dataset:NousResearch/RLVR_Coding_Problems",
      "base_model:Qwen/Qwen3-14B",
      "base_model:finetune:Qwen/Qwen3-14B",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "LiquidAI/LFM2.5-1.2B-JP",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 4816,
    "likes": 130,
    "tags": [
      "transformers",
      "safetensors",
      "lfm2",
      "text-generation",
      "liquid",
      "lfm2.5",
      "edge",
      "conversational",
      "en",
      "ja",
      "arxiv:2402.14531",
      "arxiv:2502.04688",
      "arxiv:2511.23404",
      "base_model:LiquidAI/LFM2.5-1.2B-Base",
      "base_model:finetune:LiquidAI/LFM2.5-1.2B-Base",
      "license:other",
      "endpoints_compatible",
      "region:us",
      "deploy:azure"
    ],
    "description": ""
  },
  {
    "id": "meituan-longcat/LongCat-Flash-Thinking-2601",
    "task": "text-generation",
    "library": "LongCat-Flash-Thinking-2601",
    "downloads": 125,
    "likes": 66,
    "tags": [
      "LongCat-Flash-Thinking-2601",
      "safetensors",
      "transformers",
      "text-generation",
      "conversational",
      "custom_code",
      "license:mit",
      "eval-results",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "facebook/sam3",
    "task": "mask-generation",
    "library": "transformers",
    "downloads": 1536655,
    "likes": 1392,
    "tags": [
      "transformers",
      "safetensors",
      "sam3_video",
      "feature-extraction",
      "sam3",
      "mask-generation",
      "en",
      "license:other",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "tencent/HY-MT1.5-1.8B",
    "task": "translation",
    "library": "transformers",
    "downloads": 17598,
    "likes": 772,
    "tags": [
      "transformers",
      "safetensors",
      "hunyuan_v1_dense",
      "text-generation",
      "translation",
      "zh",
      "en",
      "fr",
      "pt",
      "es",
      "ja",
      "tr",
      "ru",
      "ar",
      "ko",
      "th",
      "it",
      "de",
      "vi",
      "ms",
      "id",
      "tl",
      "hi",
      "pl",
      "cs",
      "nl",
      "km",
      "my",
      "fa",
      "gu",
      "ur",
      "te",
      "mr",
      "he",
      "bn",
      "ta",
      "uk",
      "bo",
      "kk",
      "mn",
      "ug",
      "arxiv:2512.24092",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "LiquidAI/LFM2.5-Audio-1.5B",
    "task": "audio-to-audio",
    "library": "liquid-audio",
    "downloads": 1707,
    "likes": 268,
    "tags": [
      "liquid-audio",
      "safetensors",
      "liquid",
      "lfm2",
      "audio",
      "lfm2-audio",
      "speech-to-speech",
      "audio-to-audio",
      "en",
      "arxiv:2511.23404",
      "base_model:LiquidAI/LFM2-1.2B",
      "base_model:finetune:LiquidAI/LFM2-1.2B",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "miromind-ai/MiroThinker-v1.5-30B",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 4677,
    "likes": 215,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3_moe",
      "text-generation",
      "agent",
      "open-source",
      "miromind",
      "deep-research",
      "conversational",
      "en",
      "arxiv:2511.11793",
      "base_model:Qwen/Qwen3-30B-A3B-Thinking-2507",
      "base_model:finetune:Qwen/Qwen3-30B-A3B-Thinking-2507",
      "license:mit",
      "eval-results",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "baichuan-inc/Baichuan-M3-235B",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 849,
    "likes": 62,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3_moe",
      "text-generation",
      "chat",
      "conversational",
      "en",
      "zh",
      "base_model:Qwen/Qwen3-235B-A22B",
      "base_model:finetune:Qwen/Qwen3-235B-A22B",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "nvidia/Alpamayo-R1-10B",
    "task": "robotics",
    "library": "transformers",
    "downloads": 25743,
    "likes": 310,
    "tags": [
      "transformers",
      "safetensors",
      "alpamayo_r1",
      "robotics",
      "dataset:nvidia/PhysicalAI-Autonomous-Vehicles",
      "dataset:nvidia/PhysicalAI-Autonomous-Vehicles-NuRec",
      "arxiv:2511.00088",
      "license:other",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-VL-Reranker-8B",
    "task": "image-to-text",
    "library": "transformers",
    "downloads": 3802,
    "likes": 101,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3_vl",
      "image-to-text",
      "multimodal rerank",
      "base_model:Qwen/Qwen3-VL-8B-Instruct",
      "base_model:finetune:Qwen/Qwen3-VL-8B-Instruct",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "prithivMLmods/Qwen-Image-Edit-2511-Unblur-Upscale",
    "task": "image-to-image",
    "library": "diffusers",
    "downloads": 4833,
    "likes": 57,
    "tags": [
      "diffusers",
      "lora",
      "art",
      "image-to-image",
      "en",
      "base_model:Qwen/Qwen-Image-Edit-2511",
      "base_model:adapter:Qwen/Qwen-Image-Edit-2511",
      "doi:10.57967/hf/7521",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "black-forest-labs/FLUX.2-klein-base-4B",
    "task": "image-to-image",
    "library": "diffusers",
    "downloads": 3832,
    "likes": 56,
    "tags": [
      "diffusers",
      "safetensors",
      "text-to-image",
      "image-editing",
      "flux",
      "diffusion-single-file",
      "image-to-image",
      "en",
      "license:apache-2.0",
      "diffusers:Flux2KleinPipeline",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Alibaba-Apsara/DASD-4B-Thinking",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 145,
    "likes": 54,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "conversational",
      "dataset:Alibaba-Apsara/Superior-Reasoning-SFT-gpt-oss-120b",
      "dataset:Alibaba-Apsara/Superior-Reasoning-SFT-gpt-oss-120b-Logprob",
      "arxiv:2601.09088",
      "arxiv:2512.20908",
      "license:apache-2.0",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "FunAudioLLM/Fun-CosyVoice3-0.5B-2512",
    "task": "text-to-speech",
    "library": null,
    "downloads": 4334,
    "likes": 402,
    "tags": [
      "onnx",
      "safetensors",
      "text-to-speech",
      "zh",
      "en",
      "fr",
      "es",
      "ja",
      "ko",
      "it",
      "ru",
      "de",
      "arxiv:2505.17589",
      "arxiv:2412.10117",
      "arxiv:2407.05407",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Comfy-Org/flux2-klein-9B",
    "task": null,
    "library": null,
    "downloads": 0,
    "likes": 52,
    "tags": [
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "hexgrad/Kokoro-82M",
    "task": "text-to-speech",
    "library": null,
    "downloads": 1935268,
    "likes": 5586,
    "tags": [
      "text-to-speech",
      "en",
      "arxiv:2306.07691",
      "arxiv:2203.02395",
      "base_model:yl4579/StyleTTS2-LJSpeech",
      "base_model:finetune:yl4579/StyleTTS2-LJSpeech",
      "doi:10.57967/hf/4329",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "zilliz/semantic-highlight-bilingual-v1",
    "task": "token-classification",
    "library": null,
    "downloads": 753,
    "likes": 52,
    "tags": [
      "safetensors",
      "open_provence",
      "RAG",
      "highlight",
      "context-pruning",
      "context-engineering",
      "semantic-highlight",
      "token-classification",
      "custom_code",
      "zh",
      "en",
      "dataset:zilliz/msmarco-context-relevance-with-think",
      "dataset:zilliz/natural_questions-context-relevance-with-think",
      "dataset:zilliz/gooaq-context-relevance-130k-context-relevance-with-think",
      "dataset:zilliz/wikipedia_zh_cn_500k-context-relevance-with-think",
      "dataset:zilliz/mmarco_chinese_200k-context-relevance-with-think",
      "dataset:zilliz/dureader-context-relevance-with-think",
      "arxiv:2501.16214",
      "arxiv:2402.03216",
      "base_model:BAAI/bge-reranker-v2-m3",
      "base_model:finetune:BAAI/bge-reranker-v2-m3",
      "license:mit",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "YatharthS/NovaSR",
    "task": "audio-to-audio",
    "library": null,
    "downloads": 135,
    "likes": 53,
    "tags": [
      "pytorch",
      "audio-to-audio",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen-Image-Edit-2511",
    "task": "image-to-image",
    "library": "diffusers",
    "downloads": 100869,
    "likes": 719,
    "tags": [
      "diffusers",
      "safetensors",
      "image-to-image",
      "en",
      "zh",
      "arxiv:2508.02324",
      "license:apache-2.0",
      "diffusers:QwenImageEditPlusPipeline",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "naver-hyperclovax/HyperCLOVAX-SEED-Think-32B",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 31833,
    "likes": 388,
    "tags": [
      "transformers",
      "safetensors",
      "vlm",
      "text-generation",
      "conversational",
      "custom_code",
      "license:other",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "LiquidAI/LFM2-2.6B-Transcript",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 696,
    "likes": 147,
    "tags": [
      "transformers",
      "safetensors",
      "lfm2",
      "text-generation",
      "liquid",
      "edge",
      "conversational",
      "en",
      "base_model:LiquidAI/LFM2-2.6B",
      "base_model:finetune:LiquidAI/LFM2-2.6B",
      "license:other",
      "endpoints_compatible",
      "region:us",
      "deploy:azure"
    ],
    "description": ""
  },
  {
    "id": "iitolstykh/VIBE-Image-Edit",
    "task": "image-to-image",
    "library": "diffusers",
    "downloads": 131,
    "likes": 58,
    "tags": [
      "diffusers",
      "safetensors",
      "image-editing",
      "text-guided-editing",
      "diffusion",
      "sana",
      "qwen-vl",
      "multimodal",
      "image-to-image",
      "en",
      "arxiv:2601.02242",
      "base_model:Efficient-Large-Model/SANA1.5_1.6B_1024px",
      "base_model:finetune:Efficient-Large-Model/SANA1.5_1.6B_1024px",
      "diffusers:VIBESanaEditingPipeline",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "LiquidAI/LFM2.5-VL-1.6B",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 7490,
    "likes": 180,
    "tags": [
      "transformers",
      "safetensors",
      "lfm2_vl",
      "image-to-text",
      "liquid",
      "lfm2",
      "lfm2-vl",
      "edge",
      "lfm2.5-vl",
      "lfm2.5",
      "image-text-to-text",
      "conversational",
      "en",
      "ja",
      "ko",
      "fr",
      "es",
      "de",
      "ar",
      "zh",
      "arxiv:2511.23404",
      "base_model:LiquidAI/LFM2.5-1.2B-Base",
      "base_model:finetune:LiquidAI/LFM2.5-1.2B-Base",
      "license:other",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "google/medasr",
    "task": "automatic-speech-recognition",
    "library": "transformers",
    "downloads": 7797,
    "likes": 245,
    "tags": [
      "transformers",
      "safetensors",
      "lasr_ctc",
      "medical-asr",
      "radiology",
      "medical",
      "automatic-speech-recognition",
      "en",
      "arxiv:2005.08100",
      "arxiv:2304.13134",
      "arxiv:2309.08105",
      "license:other",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "google/functiongemma-270m-it",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 87685,
    "likes": 827,
    "tags": [
      "transformers",
      "safetensors",
      "gemma3_text",
      "text-generation",
      "gemma3",
      "gemma",
      "google",
      "functiongemma",
      "conversational",
      "license:gemma",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "LiquidAI/LFM2.5-1.2B-Instruct-GGUF",
    "task": "text-generation",
    "library": null,
    "downloads": 18544,
    "likes": 96,
    "tags": [
      "gguf",
      "liquid",
      "lfm2.5",
      "edge",
      "llama.cpp",
      "text-generation",
      "en",
      "ar",
      "zh",
      "fr",
      "de",
      "ja",
      "ko",
      "es",
      "base_model:LiquidAI/LFM2.5-1.2B-Instruct",
      "base_model:quantized:LiquidAI/LFM2.5-1.2B-Instruct",
      "license:other",
      "endpoints_compatible",
      "region:us",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "GitMylo/LTX-2-comfy_gemma_fp8_e4m3fn",
    "task": null,
    "library": null,
    "downloads": 0,
    "likes": 105,
    "tags": [
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "KlingTeam/UniVideo",
    "task": "any-to-any",
    "library": null,
    "downloads": 0,
    "likes": 80,
    "tags": [
      "video",
      "any-to-any",
      "en",
      "arxiv:2510.08377",
      "base_model:Qwen/Qwen2.5-VL-7B-Instruct",
      "base_model:finetune:Qwen/Qwen2.5-VL-7B-Instruct",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "skt/A.X-K1",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 9717,
    "likes": 253,
    "tags": [
      "transformers",
      "safetensors",
      "AXK1",
      "text-generation",
      "conversational",
      "custom_code",
      "en",
      "ko",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen-Image-2512",
    "task": "text-to-image",
    "library": "diffusers",
    "downloads": 47258,
    "likes": 605,
    "tags": [
      "diffusers",
      "safetensors",
      "text-to-image",
      "en",
      "zh",
      "arxiv:2508.02324",
      "license:apache-2.0",
      "diffusers:QwenImagePipeline",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "HeartMuLa/HeartMuLa-oss-3B",
    "task": "text-to-audio",
    "library": null,
    "downloads": 91,
    "likes": 42,
    "tags": [
      "safetensors",
      "heartmula",
      "music",
      "art",
      "text-to-audio",
      "zh",
      "en",
      "ja",
      "ko",
      "es",
      "arxiv:2601.10547",
      "license:cc-by-nc-4.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "unsloth/FLUX.2-klein-4B-GGUF",
    "task": "image-to-image",
    "library": "ggml",
    "downloads": 7885,
    "likes": 42,
    "tags": [
      "ggml",
      "gguf",
      "text-to-image",
      "unsloth",
      "image-editing",
      "flux",
      "diffusion-single-file",
      "image-to-image",
      "en",
      "base_model:black-forest-labs/FLUX.2-klein-4B",
      "base_model:quantized:black-forest-labs/FLUX.2-klein-4B",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "LGAI-EXAONE/K-EXAONE-236B-A23B",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 8506,
    "likes": 493,
    "tags": [
      "transformers",
      "safetensors",
      "exaone_moe",
      "text-generation",
      "lg-ai",
      "exaone",
      "k-exaone",
      "conversational",
      "en",
      "ko",
      "es",
      "de",
      "ja",
      "vi",
      "arxiv:2601.01739",
      "license:other",
      "eval-results",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "microsoft/FrogMini-14B-2510",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 190,
    "likes": 41,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "conversational",
      "arxiv:2510.19898",
      "base_model:Qwen/Qwen3-14B",
      "base_model:finetune:Qwen/Qwen3-14B",
      "license:mit",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us",
      "deploy:azure"
    ],
    "description": ""
  },
  {
    "id": "meta-llama/Llama-3.1-8B-Instruct",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 9731663,
    "likes": 5285,
    "tags": [
      "transformers",
      "safetensors",
      "llama",
      "text-generation",
      "facebook",
      "meta",
      "pytorch",
      "llama-3",
      "conversational",
      "en",
      "de",
      "fr",
      "it",
      "pt",
      "hi",
      "es",
      "th",
      "arxiv:2204.05149",
      "base_model:meta-llama/Llama-3.1-8B",
      "base_model:finetune:meta-llama/Llama-3.1-8B",
      "license:llama3.1",
      "eval-results",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "black-forest-labs/FLUX.1-dev",
    "task": "text-to-image",
    "library": "diffusers",
    "downloads": 719544,
    "likes": 12169,
    "tags": [
      "diffusers",
      "safetensors",
      "text-to-image",
      "image-generation",
      "flux",
      "en",
      "license:other",
      "endpoints_compatible",
      "diffusers:FluxPipeline",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "alibaba-pai/Z-Image-Turbo-Fun-Controlnet-Union-2.1",
    "task": null,
    "library": "videox_fun",
    "downloads": 95622,
    "likes": 304,
    "tags": [
      "videox_fun",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "LiquidAI/LFM2.5-1.2B-Base",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 4737,
    "likes": 98,
    "tags": [
      "transformers",
      "safetensors",
      "lfm2",
      "text-generation",
      "liquid",
      "lfm2.5",
      "edge",
      "conversational",
      "en",
      "ar",
      "zh",
      "fr",
      "de",
      "ja",
      "ko",
      "es",
      "arxiv:2511.23404",
      "license:other",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "black-forest-labs/FLUX.2-dev",
    "task": "image-to-image",
    "library": "diffusers",
    "downloads": 94721,
    "likes": 1250,
    "tags": [
      "diffusers",
      "safetensors",
      "image-generation",
      "image-editing",
      "flux",
      "diffusion-single-file",
      "image-to-image",
      "en",
      "license:other",
      "diffusers:Flux2Pipeline",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "kakaocorp/kanana-2-30b-a3b-instruct-2601",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 122,
    "likes": 39,
    "tags": [
      "transformers",
      "safetensors",
      "deepseek_v3",
      "text-generation",
      "conversational",
      "base_model:kakaocorp/kanana-2-30b-a3b-mid-2601",
      "base_model:finetune:kakaocorp/kanana-2-30b-a3b-mid-2601",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "kakaocorp/kanana-2-30b-a3b-thinking-2601",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 128,
    "likes": 39,
    "tags": [
      "transformers",
      "safetensors",
      "deepseek_v3",
      "text-generation",
      "conversational",
      "base_model:kakaocorp/kanana-2-30b-a3b-mid-2601",
      "base_model:finetune:kakaocorp/kanana-2-30b-a3b-mid-2601",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Alibaba-Apsara/DASD-30B-A3B-Thinking-Preview",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 89,
    "likes": 38,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3_moe",
      "text-generation",
      "conversational",
      "dataset:Alibaba-Apsara/Superior-Reasoning-SFT-gpt-oss-120b",
      "dataset:Alibaba-Apsara/Superior-Reasoning-SFT-gpt-oss-120b-Logprob",
      "arxiv:2601.09088",
      "arxiv:2512.20908",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "unsloth/LTX-2-GGUF",
    "task": "image-to-video",
    "library": "ggml",
    "downloads": 13844,
    "likes": 58,
    "tags": [
      "ggml",
      "gguf",
      "image-to-video",
      "unsloth",
      "text-to-video",
      "video-to-video",
      "image-text-to-video",
      "audio-to-video",
      "text-to-audio",
      "video-to-audio",
      "audio-to-audio",
      "text-to-audio-video",
      "image-to-audio-video",
      "image-text-to-audio-video",
      "ltx-2",
      "ltx-video",
      "ltxv",
      "lightricks",
      "en",
      "de",
      "es",
      "fr",
      "ja",
      "ko",
      "zh",
      "it",
      "pt",
      "arxiv:2601.03233",
      "base_model:Lightricks/LTX-2",
      "base_model:quantized:Lightricks/LTX-2",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "black-forest-labs/FLUX.2-klein-9b-fp8",
    "task": "image-to-image",
    "library": "diffusers",
    "downloads": 7922,
    "likes": 36,
    "tags": [
      "diffusers",
      "image-generation",
      "image-editing",
      "flux",
      "diffusion-single-file",
      "image-to-image",
      "en",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "deepseek-ai/DeepSeek-OCR",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 3057413,
    "likes": 3085,
    "tags": [
      "transformers",
      "safetensors",
      "deepseek_vl_v2",
      "feature-extraction",
      "deepseek",
      "vision-language",
      "ocr",
      "custom_code",
      "image-text-to-text",
      "multilingual",
      "arxiv:2510.18234",
      "license:mit",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "miromind-ai/MiroThinker-v1.5-235B",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 2127,
    "likes": 235,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3_moe",
      "text-generation",
      "agent",
      "open-source",
      "miromind",
      "deep-research",
      "conversational",
      "en",
      "arxiv:2511.11793",
      "base_model:Qwen/Qwen3-235B-A22B-Thinking-2507",
      "base_model:finetune:Qwen/Qwen3-235B-A22B-Thinking-2507",
      "license:mit",
      "eval-results",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "unsloth/FLUX.2-klein-9B-GGUF",
    "task": "image-to-image",
    "library": "ggml",
    "downloads": 12485,
    "likes": 35,
    "tags": [
      "ggml",
      "gguf",
      "image-generation",
      "unsloth",
      "image-editing",
      "flux",
      "diffusion-single-file",
      "image-to-image",
      "en",
      "base_model:black-forest-labs/FLUX.2-klein-9B",
      "base_model:quantized:black-forest-labs/FLUX.2-klein-9B",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "deepseek-ai/DeepSeek-V3.2",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 105949,
    "likes": 1127,
    "tags": [
      "transformers",
      "safetensors",
      "deepseek_v32",
      "text-generation",
      "conversational",
      "base_model:deepseek-ai/DeepSeek-V3.2-Exp-Base",
      "base_model:finetune:deepseek-ai/DeepSeek-V3.2-Exp-Base",
      "license:mit",
      "endpoints_compatible",
      "fp8",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen-Image-Layered",
    "task": "image-text-to-image",
    "library": "diffusers",
    "downloads": 26796,
    "likes": 957,
    "tags": [
      "diffusers",
      "safetensors",
      "image-text-to-image",
      "en",
      "zh",
      "arxiv:2512.15603",
      "base_model:Qwen/Qwen-Image",
      "base_model:finetune:Qwen/Qwen-Image",
      "license:apache-2.0",
      "diffusers:QwenImageLayeredPipeline",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "haykgrigorian/TimeCapsuleLLM-v2-llama-1.2B",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 392,
    "likes": 33,
    "tags": [
      "transformers",
      "safetensors",
      "llama",
      "text-generation",
      "historical",
      "causal-lm",
      "en",
      "dataset:postgrammar/london-llm-1800",
      "license:mit",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "openai/gpt-oss-20b",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 6709441,
    "likes": 4217,
    "tags": [
      "transformers",
      "safetensors",
      "gpt_oss",
      "text-generation",
      "vllm",
      "conversational",
      "arxiv:2508.10925",
      "license:apache-2.0",
      "endpoints_compatible",
      "8-bit",
      "mxfp4",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "unsloth/Qwen3-Next-80B-A3B-Instruct-GGUF",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 76405,
    "likes": 148,
    "tags": [
      "transformers",
      "gguf",
      "qwen3_next",
      "text-generation",
      "unsloth",
      "arxiv:2309.00071",
      "arxiv:2404.06654",
      "arxiv:2505.09388",
      "arxiv:2501.15383",
      "base_model:Qwen/Qwen3-Next-80B-A3B-Instruct",
      "base_model:quantized:Qwen/Qwen3-Next-80B-A3B-Instruct",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us",
      "imatrix",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "nvidia/Nemotron-Orchestrator-8B",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 26418,
    "likes": 520,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "conversational",
      "arxiv:2511.21689",
      "base_model:Qwen/Qwen3-8B",
      "base_model:finetune:Qwen/Qwen3-8B",
      "eval-results",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Comfy-Org/flux2-klein-4B",
    "task": null,
    "library": null,
    "downloads": 0,
    "likes": 31,
    "tags": [
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "thilina/mt5-sinhalese-english",
    "task": "translation",
    "library": "transformers",
    "downloads": 83,
    "likes": 39,
    "tags": [
      "transformers",
      "pytorch",
      "tf",
      "mt5",
      "text2text-generation",
      "translation",
      "si",
      "en",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "ekwek/Soprano-80M",
    "task": "text-to-speech",
    "library": "transformers",
    "downloads": 8818,
    "likes": 304,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "text-to-speech",
      "license:apache-2.0",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Phr00t/WAN2.2-14B-Rapid-AllInOne",
    "task": "image-to-video",
    "library": "wan2.2",
    "downloads": 0,
    "likes": 1357,
    "tags": [
      "wan2.2",
      "wan",
      "accelerator",
      "image-to-video",
      "base_model:Wan-AI/Wan2.2-I2V-A14B",
      "base_model:finetune:Wan-AI/Wan2.2-I2V-A14B",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "iFlyBot/iFlyBotVLM",
    "task": null,
    "library": null,
    "downloads": 59,
    "likes": 34,
    "tags": [
      "safetensors",
      "internvl_chat",
      "custom_code",
      "arxiv:2511.04976",
      "license:mit",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "lilylilith/AnyPose",
    "task": "image-to-image",
    "library": "diffusers",
    "downloads": 34626,
    "likes": 382,
    "tags": [
      "diffusers",
      "LoRA",
      "lora",
      "Qwen-Image-Edit",
      "Qwen-Image",
      "image-to-image",
      "base_model:Qwen/Qwen-Image-Edit-2511",
      "base_model:adapter:Qwen/Qwen-Image-Edit-2511",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "QuantStack/LTX-2-GGUF",
    "task": "image-to-video",
    "library": "gguf",
    "downloads": 17168,
    "likes": 63,
    "tags": [
      "gguf",
      "image-to-video",
      "text-to-video",
      "video-to-video",
      "image-text-to-video",
      "audio-to-video",
      "text-to-audio",
      "video-to-audio",
      "audio-to-audio",
      "text-to-audio-video",
      "image-to-audio-video",
      "image-text-to-audio-video",
      "ltx-2",
      "ltx-video",
      "ltxv",
      "lightricks",
      "en",
      "de",
      "es",
      "fr",
      "ja",
      "ko",
      "zh",
      "it",
      "pt",
      "base_model:Lightricks/LTX-2",
      "base_model:quantized:Lightricks/LTX-2",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "coqui/XTTS-v2",
    "task": "text-to-speech",
    "library": "coqui",
    "downloads": 5287338,
    "likes": 3325,
    "tags": [
      "coqui",
      "text-to-speech",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "voyageai/voyage-4-nano",
    "task": null,
    "library": null,
    "downloads": 499,
    "likes": 28,
    "tags": [
      "safetensors",
      "qwen3",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "DreamFast/gemma-3-12b-it-heretic",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 5486,
    "likes": 32,
    "tags": [
      "transformers",
      "safetensors",
      "gguf",
      "gemma3",
      "image-to-text",
      "abliteration",
      "heretic",
      "uncensored",
      "gemma",
      "ltx-2",
      "comfyui",
      "video-generation",
      "text-encoder",
      "text-generation",
      "conversational",
      "en",
      "base_model:google/gemma-3-12b-it",
      "base_model:quantized:google/gemma-3-12b-it",
      "license:gemma",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "ymcki/Kimi-Linear-48B-A3B-Instruct-GGUF",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 4970,
    "likes": 27,
    "tags": [
      "transformers",
      "gguf",
      "pytorch",
      "text-generation",
      "en",
      "base_model:moonshotai/Kimi-Linear-48B-A3B-Instruct",
      "base_model:quantized:moonshotai/Kimi-Linear-48B-A3B-Instruct",
      "license:mit",
      "endpoints_compatible",
      "region:us",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "Octen/Octen-Embedding-8B",
    "task": "sentence-similarity",
    "library": "sentence-transformers",
    "downloads": 5976,
    "likes": 32,
    "tags": [
      "sentence-transformers",
      "safetensors",
      "qwen3",
      "sentence-similarity",
      "feature-extraction",
      "embedding",
      "text-embedding",
      "retrieval",
      "en",
      "zh",
      "multilingual",
      "base_model:Qwen/Qwen3-Embedding-8B",
      "base_model:finetune:Qwen/Qwen3-Embedding-8B",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "stabilityai/stable-diffusion-xl-base-1.0",
    "task": "text-to-image",
    "library": "diffusers",
    "downloads": 1828813,
    "likes": 7331,
    "tags": [
      "diffusers",
      "onnx",
      "safetensors",
      "text-to-image",
      "stable-diffusion",
      "arxiv:2307.01952",
      "arxiv:2211.01324",
      "arxiv:2108.01073",
      "arxiv:2112.10752",
      "license:openrail++",
      "endpoints_compatible",
      "diffusers:StableDiffusionXLPipeline",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "tiiuae/Falcon-H1R-7B",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 4409,
    "likes": 188,
    "tags": [
      "transformers",
      "safetensors",
      "falcon_h1",
      "text-generation",
      "falcon-h1r",
      "conversational",
      "en",
      "arxiv:2601.02346",
      "base_model:tiiuae/Falcon-H1-7B-Base",
      "base_model:finetune:tiiuae/Falcon-H1-7B-Base",
      "license:other",
      "eval-results",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 302821,
    "likes": 577,
    "tags": [
      "transformers",
      "safetensors",
      "nemotron_h",
      "feature-extraction",
      "nvidia",
      "pytorch",
      "text-generation",
      "conversational",
      "custom_code",
      "en",
      "es",
      "fr",
      "de",
      "ja",
      "it",
      "dataset:nvidia/Nemotron-Pretraining-Code-v1",
      "dataset:nvidia/Nemotron-CC-v2",
      "dataset:nvidia/Nemotron-Pretraining-SFT-v1",
      "dataset:nvidia/Nemotron-CC-Math-v1",
      "dataset:nvidia/Nemotron-Pretraining-Code-v2",
      "dataset:nvidia/Nemotron-Pretraining-Specialized-v1",
      "dataset:nvidia/Nemotron-CC-v2.1",
      "dataset:nvidia/Nemotron-CC-Code-v1",
      "dataset:nvidia/Nemotron-Pretraining-Dataset-sample",
      "dataset:nvidia/Nemotron-Competitive-Programming-v1",
      "dataset:nvidia/Nemotron-Math-v2",
      "dataset:nvidia/Nemotron-Agentic-v1",
      "dataset:nvidia/Nemotron-Math-Proofs-v1",
      "dataset:nvidia/Nemotron-Instruction-Following-Chat-v1",
      "dataset:nvidia/Nemotron-Science-v1",
      "dataset:nvidia/Nemotron-3-Nano-RL-Training-Blend",
      "arxiv:2512.20848",
      "arxiv:2512.20856",
      "license:other",
      "eval-results",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "zai-org/GLM-TTS",
    "task": "text-to-speech",
    "library": "glm-tts",
    "downloads": 699,
    "likes": 301,
    "tags": [
      "glm-tts",
      "safetensors",
      "llm",
      "tts",
      "zero-shot",
      "voice-cloning",
      "reinforcement-learning",
      "flow-matching",
      "text-to-speech",
      "zh",
      "en",
      "arxiv:2512.14291",
      "license:mit",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "AlicanKiraz0/Mihenk-LLM-14B-Turkish-Financial-Model",
    "task": null,
    "library": null,
    "downloads": 353,
    "likes": 26,
    "tags": [
      "gguf",
      "llama-cpp",
      "gguf-my-repo",
      "tr",
      "en",
      "base_model:Qwen/Qwen3-14B",
      "base_model:quantized:Qwen/Qwen3-14B",
      "license:mit",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Kijai/WanVideo_comfy",
    "task": null,
    "library": "diffusion-single-file",
    "downloads": 6164580,
    "likes": 2013,
    "tags": [
      "diffusion-single-file",
      "comfyui",
      "base_model:Wan-AI/Wan2.1-VACE-1.3B",
      "base_model:finetune:Wan-AI/Wan2.1-VACE-1.3B",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "openai/gpt-oss-120b",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 3070383,
    "likes": 4351,
    "tags": [
      "transformers",
      "safetensors",
      "gpt_oss",
      "text-generation",
      "vllm",
      "conversational",
      "arxiv:2508.10925",
      "license:apache-2.0",
      "endpoints_compatible",
      "8-bit",
      "mxfp4",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "ResembleAI/chatterbox-turbo",
    "task": "text-to-speech",
    "library": null,
    "downloads": 0,
    "likes": 566,
    "tags": [
      "text-to-speech",
      "speech",
      "speech-generation",
      "voice-cloning",
      "en",
      "license:mit",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "sentence-transformers/all-MiniLM-L6-v2",
    "task": "sentence-similarity",
    "library": "sentence-transformers",
    "downloads": 141529512,
    "likes": 4342,
    "tags": [
      "sentence-transformers",
      "pytorch",
      "tf",
      "rust",
      "onnx",
      "safetensors",
      "openvino",
      "bert",
      "feature-extraction",
      "sentence-similarity",
      "transformers",
      "en",
      "dataset:s2orc",
      "dataset:flax-sentence-embeddings/stackexchange_xml",
      "dataset:ms_marco",
      "dataset:gooaq",
      "dataset:yahoo_answers_topics",
      "dataset:code_search_net",
      "dataset:search_qa",
      "dataset:eli5",
      "dataset:snli",
      "dataset:multi_nli",
      "dataset:wikihow",
      "dataset:natural_questions",
      "dataset:trivia_qa",
      "dataset:embedding-data/sentence-compression",
      "dataset:embedding-data/flickr30k-captions",
      "dataset:embedding-data/altlex",
      "dataset:embedding-data/simple-wiki",
      "dataset:embedding-data/QQP",
      "dataset:embedding-data/SPECTER",
      "dataset:embedding-data/PAQ_pairs",
      "dataset:embedding-data/WikiAnswers",
      "arxiv:1904.06472",
      "arxiv:2102.07033",
      "arxiv:2104.08727",
      "arxiv:1704.05179",
      "arxiv:1810.09305",
      "license:apache-2.0",
      "text-embeddings-inference",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "google/medgemma-4b-it",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 362925,
    "likes": 845,
    "tags": [
      "transformers",
      "safetensors",
      "gemma3",
      "image-to-text",
      "medical",
      "radiology",
      "clinical-reasoning",
      "dermatology",
      "pathology",
      "ophthalmology",
      "chest-x-ray",
      "image-text-to-text",
      "conversational",
      "arxiv:2303.15343",
      "arxiv:2507.05201",
      "arxiv:2405.03162",
      "arxiv:2106.14463",
      "arxiv:2412.03555",
      "arxiv:2501.19393",
      "arxiv:2009.13081",
      "arxiv:2102.09542",
      "arxiv:2411.15640",
      "arxiv:2404.05590",
      "arxiv:2501.18362",
      "base_model:google/medgemma-4b-pt",
      "base_model:finetune:google/medgemma-4b-pt",
      "license:other",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "nvidia/parakeet-tdt-0.6b-v3",
    "task": "automatic-speech-recognition",
    "library": "nemo",
    "downloads": 71104,
    "likes": 555,
    "tags": [
      "nemo",
      "automatic-speech-recognition",
      "speech",
      "audio",
      "Transducer",
      "TDT",
      "FastConformer",
      "Conformer",
      "pytorch",
      "NeMo",
      "hf-asr-leaderboard",
      "en",
      "es",
      "fr",
      "de",
      "bg",
      "hr",
      "cs",
      "da",
      "nl",
      "et",
      "fi",
      "el",
      "hu",
      "it",
      "lv",
      "lt",
      "mt",
      "pl",
      "pt",
      "ro",
      "sk",
      "sl",
      "sv",
      "ru",
      "uk",
      "dataset:nvidia/Granary",
      "dataset:nemo/asr-set-3.0",
      "arxiv:2509.14128",
      "arxiv:2505.13404",
      "arxiv:2305.05084",
      "arxiv:2304.06795",
      "arxiv:2410.01036",
      "arxiv:2406.00899",
      "arxiv:2205.12446",
      "arxiv:2012.03411",
      "arxiv:2007.10310",
      "arxiv:1510.08484",
      "license:cc-by-4.0",
      "model-index",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "neuphonic/neutts-nano",
    "task": "text-to-speech",
    "library": null,
    "downloads": 797,
    "likes": 24,
    "tags": [
      "safetensors",
      "llama",
      "text-to-speech",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "lightx2v/Qwen-Image-Edit-2511-Lightning",
    "task": "image-to-image",
    "library": "diffusers",
    "downloads": 441384,
    "likes": 331,
    "tags": [
      "diffusers",
      "safetensors",
      "diffusion-single-file",
      "comfyui",
      "distillation",
      "LoRA",
      "lora",
      "Qwen-Image",
      "Qwen-Image-Edit",
      "image-to-image",
      "base_model:Qwen/Qwen-Image-Edit-2511",
      "base_model:adapter:Qwen/Qwen-Image-Edit-2511",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "tencent/HY-Motion-1.0",
    "task": "text-to-3d",
    "library": "HY-Motion-1.0",
    "downloads": 862,
    "likes": 338,
    "tags": [
      "HY-Motion-1.0",
      "text-to-motion",
      "3d-human-motion",
      "text-to-3d",
      "en",
      "zh",
      "arxiv:2512.23464",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "fal/FLUX.2-dev-Turbo",
    "task": "text-to-image",
    "library": "diffusers",
    "downloads": 12332,
    "likes": 292,
    "tags": [
      "diffusers",
      "image-generation",
      "flux",
      "lora",
      "distillation",
      "turbo",
      "text-to-image",
      "en",
      "base_model:black-forest-labs/FLUX.2-dev",
      "base_model:adapter:black-forest-labs/FLUX.2-dev",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Spirit-AI-robotics/Spirit-v1.5",
    "task": null,
    "library": null,
    "downloads": 88,
    "likes": 24,
    "tags": [
      "safetensors",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "alibaba-pai/Qwen-Image-2512-Fun-Controlnet-Union",
    "task": null,
    "library": "videox_fun",
    "downloads": 979,
    "likes": 24,
    "tags": [
      "videox_fun",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "unsloth/GLM-4.7-REAP-218B-A32B-GGUF",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 59985,
    "likes": 24,
    "tags": [
      "transformers",
      "gguf",
      "glm",
      "MOE",
      "pruning",
      "compression",
      "unsloth",
      "text-generation",
      "en",
      "arxiv:2510.13999",
      "base_model:cerebras/GLM-4.7-REAP-218B-A32B",
      "base_model:quantized:cerebras/GLM-4.7-REAP-218B-A32B",
      "license:mit",
      "endpoints_compatible",
      "region:us",
      "imatrix",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "kakaocorp/kanana-2-30b-a3b-base-2601",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 230,
    "likes": 24,
    "tags": [
      "transformers",
      "safetensors",
      "deepseek_v3",
      "text-generation",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "kakaocorp/kanana-2-30b-a3b-mid-2601",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 30,
    "likes": 24,
    "tags": [
      "transformers",
      "safetensors",
      "deepseek_v3",
      "text-generation",
      "base_model:kakaocorp/kanana-2-30b-a3b-base-2601",
      "base_model:finetune:kakaocorp/kanana-2-30b-a3b-base-2601",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "black-forest-labs/FLUX.1-schnell",
    "task": "text-to-image",
    "library": "diffusers",
    "downloads": 617191,
    "likes": 4545,
    "tags": [
      "diffusers",
      "safetensors",
      "text-to-image",
      "image-generation",
      "flux",
      "en",
      "license:apache-2.0",
      "endpoints_compatible",
      "diffusers:FluxPipeline",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "microsoft/FrogBoss-32B-2510",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 352,
    "likes": 23,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "conversational",
      "arxiv:2510.19898",
      "base_model:Qwen/Qwen3-32B",
      "base_model:finetune:Qwen/Qwen3-32B",
      "license:mit",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us",
      "deploy:azure"
    ],
    "description": ""
  },
  {
    "id": "stepfun-ai/Step3-VL-10B-Base",
    "task": "image-text-to-text",
    "library": null,
    "downloads": 50,
    "likes": 23,
    "tags": [
      "safetensors",
      "step_robotics",
      "image-text-to-text",
      "conversational",
      "custom_code",
      "arxiv:2601.09668",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "openai/whisper-large-v3",
    "task": "automatic-speech-recognition",
    "library": "transformers",
    "downloads": 6748451,
    "likes": 5315,
    "tags": [
      "transformers",
      "pytorch",
      "jax",
      "safetensors",
      "whisper",
      "automatic-speech-recognition",
      "audio",
      "hf-asr-leaderboard",
      "en",
      "zh",
      "de",
      "es",
      "ru",
      "ko",
      "fr",
      "ja",
      "pt",
      "tr",
      "pl",
      "ca",
      "nl",
      "ar",
      "sv",
      "it",
      "id",
      "hi",
      "fi",
      "vi",
      "he",
      "uk",
      "el",
      "ms",
      "cs",
      "ro",
      "da",
      "hu",
      "ta",
      "no",
      "th",
      "ur",
      "hr",
      "bg",
      "lt",
      "la",
      "mi",
      "ml",
      "cy",
      "sk",
      "te",
      "fa",
      "lv",
      "bn",
      "sr",
      "az",
      "sl",
      "kn",
      "et",
      "mk",
      "br",
      "eu",
      "is",
      "hy",
      "ne",
      "mn",
      "bs",
      "kk",
      "sq",
      "sw",
      "gl",
      "mr",
      "pa",
      "si",
      "km",
      "sn",
      "yo",
      "so",
      "af",
      "oc",
      "ka",
      "be",
      "tg",
      "sd",
      "gu",
      "am",
      "yi",
      "lo",
      "uz",
      "fo",
      "ht",
      "ps",
      "tk",
      "nn",
      "mt",
      "sa",
      "lb",
      "my",
      "bo",
      "tl",
      "mg",
      "as",
      "tt",
      "haw",
      "ln",
      "ha",
      "ba",
      "jw",
      "su",
      "arxiv:2212.04356",
      "license:apache-2.0",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "facebook/sam-3d-objects",
    "task": null,
    "library": "sam-3d-objects",
    "downloads": 3652,
    "likes": 346,
    "tags": [
      "sam-3d-objects",
      "3d-generation",
      "en",
      "arxiv:2511.16624",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "black-forest-labs/FLUX.2-dev-NVFP4",
    "task": "image-to-image",
    "library": "diffusers",
    "downloads": 37384,
    "likes": 68,
    "tags": [
      "diffusers",
      "image-generation",
      "image-editing",
      "flux",
      "diffusion-single-file",
      "image-to-image",
      "en",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "DavidAU/Llama3.3-8B-Instruct-Thinking-Claude-4.5-Opus-High-Reasoning",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 2304,
    "likes": 90,
    "tags": [
      "transformers",
      "safetensors",
      "llama",
      "text-generation",
      "thinking",
      "reasoning",
      "instruct",
      "Claude4.5-Opus",
      "creative",
      "creative writing",
      "fiction writing",
      "plot generation",
      "sub-plot generation",
      "story generation",
      "scene continue",
      "storytelling",
      "fiction story",
      "science fiction",
      "romance",
      "all genres",
      "story",
      "writing",
      "vivid prosing",
      "vivid writing",
      "fiction",
      "roleplaying",
      "bfloat16",
      "role play",
      "128k context",
      "llama3.3",
      "llama-3",
      "llama-3.3",
      "unsloth",
      "finetune",
      "conversational",
      "en",
      "fr",
      "de",
      "es",
      "it",
      "pt",
      "zh",
      "ja",
      "ru",
      "ko",
      "dataset:TeichAI/claude-4.5-opus-high-reasoning-250x",
      "base_model:allura-forge/Llama-3.3-8B-Instruct",
      "base_model:finetune:allura-forge/Llama-3.3-8B-Instruct",
      "license:apache-2.0",
      "text-generation-inference",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "kyutai/tts-voices",
    "task": null,
    "library": null,
    "downloads": 0,
    "likes": 110,
    "tags": [
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-VL-8B-Instruct",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 1657036,
    "likes": 661,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3_vl",
      "image-to-text",
      "image-text-to-text",
      "conversational",
      "arxiv:2505.09388",
      "arxiv:2502.13923",
      "arxiv:2409.12191",
      "arxiv:2308.12966",
      "license:apache-2.0",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Arunk25/Qwen-Image-Edit-Rapid-AIO-GGUF",
    "task": "image-text-to-image",
    "library": null,
    "downloads": 67143,
    "likes": 109,
    "tags": [
      "gguf",
      "image-text-to-image",
      "base_model:Phr00t/Qwen-Image-Edit-Rapid-AIO",
      "base_model:quantized:Phr00t/Qwen-Image-Edit-Rapid-AIO",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "nvidia/Cosmos-Reason2-8B",
    "task": "image-text-to-text",
    "library": "cosmos",
    "downloads": 45274,
    "likes": 75,
    "tags": [
      "cosmos",
      "safetensors",
      "qwen3_vl",
      "nvidia",
      "conversational",
      "image-text-to-text",
      "base_model:Qwen/Qwen3-VL-8B-Instruct",
      "base_model:finetune:Qwen/Qwen3-VL-8B-Instruct",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "XiaomiMiMo/MiMo-V2-Flash",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 38888,
    "likes": 582,
    "tags": [
      "transformers",
      "safetensors",
      "mimo_v2_flash",
      "text-generation",
      "conversational",
      "custom_code",
      "license:mit",
      "fp8",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "byteshape/Qwen3-30B-A3B-Instruct-2507-GGUF",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 14867,
    "likes": 51,
    "tags": [
      "transformers",
      "gguf",
      "qwen",
      "qwen3",
      "byteshape",
      "text-generation",
      "base_model:Qwen/Qwen3-30B-A3B-Instruct-2507",
      "base_model:quantized:Qwen/Qwen3-30B-A3B-Instruct-2507",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-Coder-30B-A3B-Instruct",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 463862,
    "likes": 870,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3_moe",
      "text-generation",
      "conversational",
      "arxiv:2505.09388",
      "license:apache-2.0",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "upstage/Solar-Open-100B",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 7709,
    "likes": 436,
    "tags": [
      "transformers",
      "safetensors",
      "solar_open",
      "text-generation",
      "upstage",
      "solar",
      "moe",
      "100b",
      "llm",
      "conversational",
      "custom_code",
      "en",
      "ko",
      "arxiv:2601.07022",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "unsloth/Qwen-Image-Edit-2511-GGUF",
    "task": "image-to-image",
    "library": null,
    "downloads": 200416,
    "likes": 306,
    "tags": [
      "gguf",
      "quantized",
      "unsloth",
      "qwen",
      "image-to-image",
      "en",
      "zh",
      "arxiv:2508.02324",
      "base_model:Qwen/Qwen-Image-Edit-2511",
      "base_model:quantized:Qwen/Qwen-Image-Edit-2511",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "cerebras/GLM-4.7-REAP-218B-A32B",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 2335,
    "likes": 22,
    "tags": [
      "transformers",
      "safetensors",
      "glm4_moe",
      "text-generation",
      "glm",
      "MOE",
      "pruning",
      "compression",
      "conversational",
      "en",
      "arxiv:2510.13999",
      "base_model:zai-org/GLM-4.7",
      "base_model:finetune:zai-org/GLM-4.7",
      "license:mit",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "black-forest-labs/FLUX.2-klein-base-9b-fp8",
    "task": "image-to-image",
    "library": "diffusers",
    "downloads": 6443,
    "likes": 20,
    "tags": [
      "diffusers",
      "image-generation",
      "image-editing",
      "flux",
      "diffusion-single-file",
      "image-to-image",
      "en",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-0.6B",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 8156994,
    "likes": 983,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "conversational",
      "arxiv:2505.09388",
      "base_model:Qwen/Qwen3-0.6B-Base",
      "base_model:finetune:Qwen/Qwen3-0.6B-Base",
      "license:apache-2.0",
      "text-generation-inference",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "tencent/Hunyuan3D-2.1",
    "task": "image-to-3d",
    "library": "hunyuan3d-2",
    "downloads": 19681,
    "likes": 821,
    "tags": [
      "hunyuan3d-2",
      "diffusers",
      "safetensors",
      "image-to-3d",
      "text-to-3d",
      "en",
      "zh",
      "arxiv:2506.15442",
      "arxiv:2501.12202",
      "arxiv:2411.02293",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-4B-Instruct-2507",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 2544920,
    "likes": 647,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "conversational",
      "arxiv:2505.09388",
      "license:apache-2.0",
      "text-generation-inference",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "PaddlePaddle/PaddleOCR-VL",
    "task": "image-text-to-text",
    "library": "PaddleOCR",
    "downloads": 12325,
    "likes": 1488,
    "tags": [
      "PaddleOCR",
      "safetensors",
      "paddleocr_vl",
      "ERNIE4.5",
      "PaddlePaddle",
      "image-to-text",
      "ocr",
      "document-parse",
      "layout",
      "table",
      "formula",
      "chart",
      "image-text-to-text",
      "conversational",
      "custom_code",
      "en",
      "zh",
      "multilingual",
      "arxiv:2510.14528",
      "base_model:baidu/ERNIE-4.5-0.3B-Paddle",
      "base_model:finetune:baidu/ERNIE-4.5-0.3B-Paddle",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "kakaocorp/kanana-2-30b-a3b-instruct",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 2851,
    "likes": 44,
    "tags": [
      "transformers",
      "safetensors",
      "deepseek_v3",
      "text-generation",
      "conversational",
      "base_model:kakaocorp/kanana-2-30b-a3b-base",
      "base_model:finetune:kakaocorp/kanana-2-30b-a3b-base",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "kakaocorp/kanana-2-30b-a3b-thinking",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 1181,
    "likes": 37,
    "tags": [
      "transformers",
      "safetensors",
      "deepseek_v3",
      "text-generation",
      "conversational",
      "base_model:kakaocorp/kanana-2-30b-a3b-base",
      "base_model:finetune:kakaocorp/kanana-2-30b-a3b-base",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "lodestones/Zeta-Chroma",
    "task": "text-to-image",
    "library": null,
    "downloads": 0,
    "likes": 89,
    "tags": [
      "text-to-image",
      "base_model:Tongyi-MAI/Z-Image-Turbo",
      "base_model:finetune:Tongyi-MAI/Z-Image-Turbo",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Lightricks/LTX-2-19b-IC-LoRA-Detailer",
    "task": "video-to-video",
    "library": null,
    "downloads": 0,
    "likes": 34,
    "tags": [
      "ltx-video",
      "video-to-video",
      "en",
      "base_model:Lightricks/LTX-2",
      "base_model:finetune:Lightricks/LTX-2",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "ekwek/Soprano-Encoder",
    "task": "feature-extraction",
    "library": null,
    "downloads": 8,
    "likes": 19,
    "tags": [
      "feature-extraction",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "zooeyy/Qwen-Edit-2511_LightingRemap_Alpha0.2",
    "task": "text-to-image",
    "library": "diffusers",
    "downloads": 293,
    "likes": 19,
    "tags": [
      "diffusers",
      "text-to-image",
      "lora",
      "template:diffusion-lora",
      "base_model:Qwen/Qwen-Image-Edit-2511",
      "base_model:adapter:Qwen/Qwen-Image-Edit-2511",
      "license:mit",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "google/gemma-3-27b-it",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 1294697,
    "likes": 1813,
    "tags": [
      "transformers",
      "safetensors",
      "gemma3",
      "image-to-text",
      "image-text-to-text",
      "conversational",
      "arxiv:1905.07830",
      "arxiv:1905.10044",
      "arxiv:1911.11641",
      "arxiv:1904.09728",
      "arxiv:1705.03551",
      "arxiv:1911.01547",
      "arxiv:1907.10641",
      "arxiv:1903.00161",
      "arxiv:2009.03300",
      "arxiv:2304.06364",
      "arxiv:2103.03874",
      "arxiv:2110.14168",
      "arxiv:2311.12022",
      "arxiv:2108.07732",
      "arxiv:2107.03374",
      "arxiv:2210.03057",
      "arxiv:2106.03193",
      "arxiv:1910.11856",
      "arxiv:2502.12404",
      "arxiv:2502.21228",
      "arxiv:2404.16816",
      "arxiv:2104.12756",
      "arxiv:2311.16502",
      "arxiv:2203.10244",
      "arxiv:2404.12390",
      "arxiv:1810.12440",
      "arxiv:1908.02660",
      "arxiv:2312.11805",
      "base_model:google/gemma-3-27b-pt",
      "base_model:finetune:google/gemma-3-27b-pt",
      "license:gemma",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "rednote-hilab/dots.ocr",
    "task": "image-text-to-text",
    "library": "dots_ocr",
    "downloads": 391475,
    "likes": 1196,
    "tags": [
      "dots_ocr",
      "safetensors",
      "text-generation",
      "image-to-text",
      "ocr",
      "document-parse",
      "layout",
      "table",
      "formula",
      "transformers",
      "custom_code",
      "image-text-to-text",
      "conversational",
      "en",
      "zh",
      "multilingual",
      "license:mit",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-VL-2B-Instruct",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 1048334,
    "likes": 287,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3_vl",
      "image-to-text",
      "image-text-to-text",
      "conversational",
      "arxiv:2505.09388",
      "arxiv:2502.13923",
      "arxiv:2409.12191",
      "arxiv:2308.12966",
      "license:apache-2.0",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-FP8",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 746716,
    "likes": 247,
    "tags": [
      "transformers",
      "safetensors",
      "nemotron_h",
      "feature-extraction",
      "nvidia",
      "pytorch",
      "text-generation",
      "conversational",
      "custom_code",
      "en",
      "es",
      "fr",
      "de",
      "ja",
      "it",
      "dataset:nvidia/Nemotron-Pretraining-Code-v1",
      "dataset:nvidia/Nemotron-CC-v2",
      "dataset:nvidia/Nemotron-Pretraining-SFT-v1",
      "dataset:nvidia/Nemotron-CC-Math-v1",
      "dataset:nvidia/Nemotron-Pretraining-Code-v2",
      "dataset:nvidia/Nemotron-Pretraining-Specialized-v1",
      "dataset:nvidia/Nemotron-CC-v2.1",
      "dataset:nvidia/Nemotron-CC-Code-v1",
      "dataset:nvidia/Nemotron-Pretraining-Dataset-sample",
      "dataset:nvidia/Nemotron-Competitive-Programming-v1",
      "dataset:nvidia/Nemotron-Math-v2",
      "dataset:nvidia/Nemotron-Agentic-v1",
      "dataset:nvidia/Nemotron-Math-Proofs-v1",
      "dataset:nvidia/Nemotron-Instruction-Following-Chat-v1",
      "dataset:nvidia/Nemotron-Science-v1",
      "dataset:nvidia/Nemotron-3-Nano-RL-Training-Blend",
      "arxiv:2512.20848",
      "arxiv:2512.20856",
      "base_model:nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16",
      "base_model:quantized:nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "microsoft/OptiMind-SFT",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 70,
    "likes": 18,
    "tags": [
      "transformers",
      "safetensors",
      "gpt_oss",
      "text-generation",
      "optimization",
      "operations-research",
      "milp",
      "gurobi",
      "sft",
      "conversational",
      "en",
      "arxiv:2509.22979",
      "base_model:unsloth/gpt-oss-20b-BF16",
      "base_model:finetune:unsloth/gpt-oss-20b-BF16",
      "license:mit",
      "endpoints_compatible",
      "region:us",
      "deploy:azure"
    ],
    "description": ""
  },
  {
    "id": "tencent/HY-MT1.5-7B",
    "task": "translation",
    "library": "transformers",
    "downloads": 160532,
    "likes": 121,
    "tags": [
      "transformers",
      "safetensors",
      "hunyuan_v1_dense",
      "text-generation",
      "translation",
      "zh",
      "en",
      "fr",
      "pt",
      "es",
      "ja",
      "tr",
      "ru",
      "ar",
      "ko",
      "th",
      "it",
      "de",
      "vi",
      "ms",
      "id",
      "tl",
      "hi",
      "pl",
      "cs",
      "nl",
      "km",
      "my",
      "fa",
      "gu",
      "ur",
      "te",
      "mr",
      "he",
      "bn",
      "ta",
      "uk",
      "bo",
      "kk",
      "mn",
      "ug",
      "arxiv:2512.24092",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "unsloth/Qwen-Image-2512-GGUF",
    "task": "text-to-image",
    "library": null,
    "downloads": 118981,
    "likes": 268,
    "tags": [
      "gguf",
      "quantized",
      "unsloth",
      "qwen",
      "text-to-image",
      "en",
      "zh",
      "arxiv:2508.02324",
      "base_model:Qwen/Qwen-Image-2512",
      "base_model:quantized:Qwen/Qwen-Image-2512",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "black-forest-labs/FLUX.2-klein-9b-nvfp4",
    "task": "image-to-image",
    "library": "diffusers",
    "downloads": 1310,
    "likes": 18,
    "tags": [
      "diffusers",
      "image-generation",
      "image-editing",
      "flux",
      "diffusion-single-file",
      "image-to-image",
      "en",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "pyannote/speaker-diarization-3.1",
    "task": "automatic-speech-recognition",
    "library": "pyannote-audio",
    "downloads": 13297706,
    "likes": 1444,
    "tags": [
      "pyannote-audio",
      "pyannote",
      "pyannote-audio-pipeline",
      "audio",
      "voice",
      "speech",
      "speaker",
      "speaker-diarization",
      "speaker-change-detection",
      "voice-activity-detection",
      "overlapped-speech-detection",
      "automatic-speech-recognition",
      "arxiv:2111.14448",
      "arxiv:2012.01477",
      "license:mit",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "meta-llama/Llama-3.2-1B-Instruct",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 2627263,
    "likes": 1251,
    "tags": [
      "transformers",
      "safetensors",
      "llama",
      "text-generation",
      "facebook",
      "meta",
      "pytorch",
      "llama-3",
      "conversational",
      "en",
      "de",
      "fr",
      "it",
      "pt",
      "hi",
      "es",
      "th",
      "arxiv:2204.05149",
      "arxiv:2405.16406",
      "license:llama3.2",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "google/gemma-3n-E2B-it-litert-lm",
    "task": "text-generation",
    "library": "litert-lm",
    "downloads": 19668,
    "likes": 281,
    "tags": [
      "litert-lm",
      "text-generation",
      "arxiv:1905.07830",
      "arxiv:1905.10044",
      "arxiv:1911.11641",
      "arxiv:1904.09728",
      "arxiv:1705.03551",
      "arxiv:1911.01547",
      "arxiv:1907.10641",
      "arxiv:1903.00161",
      "arxiv:2210.03057",
      "arxiv:2502.12404",
      "arxiv:2411.19799",
      "arxiv:2009.03300",
      "arxiv:2502.21228",
      "arxiv:2311.12022",
      "arxiv:2403.07974",
      "arxiv:2108.07732",
      "arxiv:2107.03374",
      "license:gemma",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "moonshotai/Kimi-K2-Thinking",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 216241,
    "likes": 1619,
    "tags": [
      "transformers",
      "safetensors",
      "kimi_k2",
      "text-generation",
      "conversational",
      "custom_code",
      "license:other",
      "eval-results",
      "endpoints_compatible",
      "compressed-tensors",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Comfy-Org/z_image_turbo",
    "task": null,
    "library": "diffusion-single-file",
    "downloads": 2550487,
    "likes": 549,
    "tags": [
      "diffusion-single-file",
      "comfyui",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "nvidia/magpie_tts_multilingual_357m",
    "task": "text-to-speech",
    "library": "nemo",
    "downloads": 851,
    "likes": 57,
    "tags": [
      "nemo",
      "NeMo",
      "TTS",
      "PyTorch",
      "Speech",
      "Multilingual-TTS",
      "text-to-speech",
      "en",
      "es",
      "de",
      "it",
      "vi",
      "zh",
      "fr",
      "arxiv:2406.17957",
      "arxiv:2502.05236",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "XuGuo699/DreamID-V",
    "task": null,
    "library": null,
    "downloads": 0,
    "likes": 53,
    "tags": [
      "onnx",
      "arxiv:2601.01425",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "black-forest-labs/FLUX.2-klein-4b-nvfp4",
    "task": "image-to-image",
    "library": "diffusion-single-file",
    "downloads": 2059,
    "likes": 17,
    "tags": [
      "diffusion-single-file",
      "text-to-image",
      "image-editing",
      "flux",
      "image-to-image",
      "en",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "ResembleAI/chatterbox",
    "task": "text-to-speech",
    "library": "chatterbox",
    "downloads": 510902,
    "likes": 1425,
    "tags": [
      "chatterbox",
      "text-to-speech",
      "speech",
      "speech-generation",
      "voice-cloning",
      "multilingual-tts",
      "ar",
      "da",
      "de",
      "el",
      "en",
      "es",
      "fi",
      "fr",
      "he",
      "hi",
      "it",
      "ja",
      "ko",
      "ms",
      "nl",
      "no",
      "pl",
      "pt",
      "ru",
      "sv",
      "sw",
      "tr",
      "zh",
      "license:mit",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-Embedding-8B",
    "task": "feature-extraction",
    "library": "sentence-transformers",
    "downloads": 1587548,
    "likes": 536,
    "tags": [
      "sentence-transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "transformers",
      "sentence-similarity",
      "feature-extraction",
      "text-embeddings-inference",
      "arxiv:2506.05176",
      "base_model:Qwen/Qwen3-8B-Base",
      "base_model:finetune:Qwen/Qwen3-8B-Base",
      "license:apache-2.0",
      "text-generation-inference",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "google/medgemma-27b-it",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 16502,
    "likes": 277,
    "tags": [
      "transformers",
      "safetensors",
      "gemma3",
      "image-to-text",
      "medical",
      "x-ray",
      "pathology",
      "dermatology",
      "fundus",
      "radiology report generation",
      "chest-x-ray",
      "medical-embeddings",
      "image-classification",
      "zero-shot-image-classification",
      "image-feature-extraction",
      "image-text-to-text",
      "conversational",
      "en",
      "arxiv:2303.15343",
      "arxiv:2507.05201",
      "arxiv:2405.03162",
      "arxiv:2106.14463",
      "arxiv:2412.03555",
      "arxiv:2501.19393",
      "arxiv:2009.13081",
      "arxiv:2102.09542",
      "arxiv:2411.15640",
      "arxiv:2404.05590",
      "arxiv:2501.18362",
      "base_model:google/gemma-3-27b-pt",
      "base_model:finetune:google/gemma-3-27b-pt",
      "license:other",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "openbmb/VoxCPM1.5",
    "task": "text-to-speech",
    "library": "voxcpm",
    "downloads": 3558,
    "likes": 293,
    "tags": [
      "voxcpm",
      "safetensors",
      "text-to-speech",
      "speech",
      "speech generation",
      "voice cloning",
      "en",
      "zh",
      "arxiv:2509.24650",
      "base_model:openbmb/MiniCPM4-0.5B",
      "base_model:finetune:openbmb/MiniCPM4-0.5B",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "zai-org/GLM-4.6V-Flash",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 164302,
    "likes": 550,
    "tags": [
      "transformers",
      "safetensors",
      "glm4v",
      "image-to-text",
      "image-text-to-text",
      "conversational",
      "zh",
      "en",
      "arxiv:2507.01006",
      "license:mit",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "kakaocorp/kanana-2-30b-a3b-base",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 1396,
    "likes": 26,
    "tags": [
      "transformers",
      "safetensors",
      "deepseek_v3",
      "text-generation",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "lrzjason/Anything2Real_2601",
    "task": "image-to-image",
    "library": "diffusers",
    "downloads": 26051,
    "likes": 60,
    "tags": [
      "diffusers",
      "lora",
      "image-to-image",
      "base_model:Qwen/Qwen-Image-Edit-2511",
      "base_model:adapter:Qwen/Qwen-Image-Edit-2511",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "litert-community/Gemma3-1B-IT",
    "task": "text-generation",
    "library": "litert-lm",
    "downloads": 20041,
    "likes": 474,
    "tags": [
      "litert-lm",
      "chat",
      "text-generation",
      "license:gemma",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "google/embeddinggemma-300m",
    "task": "sentence-similarity",
    "library": "sentence-transformers",
    "downloads": 579016,
    "likes": 1419,
    "tags": [
      "sentence-transformers",
      "safetensors",
      "gemma3_text",
      "sentence-similarity",
      "feature-extraction",
      "text-embeddings-inference",
      "arxiv:2509.20354",
      "license:gemma",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "MedAIBase/AntAngelMed",
    "task": null,
    "library": null,
    "downloads": 237,
    "likes": 76,
    "tags": [
      "safetensors",
      "bailing_moe",
      "custom_code",
      "arxiv:2507.17702",
      "arxiv:2505.08775",
      "arxiv:2511.14439",
      "arxiv:2402.03300",
      "base_model:inclusionAI/Ling-flash-2.0",
      "base_model:finetune:inclusionAI/Ling-flash-2.0",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Comfy-Org/ltx-2",
    "task": null,
    "library": null,
    "downloads": 0,
    "likes": 49,
    "tags": [
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Soul-AILab/SoulX-FlashTalk-14B",
    "task": "image-to-video",
    "library": "diffusers",
    "downloads": 2399,
    "likes": 21,
    "tags": [
      "diffusers",
      "safetensors",
      "i2v",
      "portrait-animation",
      "real-time",
      "diffusion",
      "image-to-video",
      "en",
      "arxiv:2512.23379",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "N8Programs/Unslopper-30B-A3B-bf16",
    "task": null,
    "library": null,
    "downloads": 97,
    "likes": 15,
    "tags": [
      "safetensors",
      "qwen3_moe",
      "dataset:N8Programs/unslop-good",
      "base_model:Qwen/Qwen3-VL-30B-A3B-Instruct",
      "base_model:finetune:Qwen/Qwen3-VL-30B-A3B-Instruct",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "microsoft/colipri",
    "task": null,
    "library": null,
    "downloads": 0,
    "likes": 15,
    "tags": [
      "license:mit",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "facebook/ShapeR",
    "task": null,
    "library": null,
    "downloads": 10,
    "likes": 15,
    "tags": [
      "3d-reconstruction",
      "3d-generation",
      "license:cc-by-nc-4.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "google/gemma-3-4b-it",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 778564,
    "likes": 1107,
    "tags": [
      "transformers",
      "safetensors",
      "gemma3",
      "image-to-text",
      "image-text-to-text",
      "conversational",
      "arxiv:1905.07830",
      "arxiv:1905.10044",
      "arxiv:1911.11641",
      "arxiv:1904.09728",
      "arxiv:1705.03551",
      "arxiv:1911.01547",
      "arxiv:1907.10641",
      "arxiv:1903.00161",
      "arxiv:2009.03300",
      "arxiv:2304.06364",
      "arxiv:2103.03874",
      "arxiv:2110.14168",
      "arxiv:2311.12022",
      "arxiv:2108.07732",
      "arxiv:2107.03374",
      "arxiv:2210.03057",
      "arxiv:2106.03193",
      "arxiv:1910.11856",
      "arxiv:2502.12404",
      "arxiv:2502.21228",
      "arxiv:2404.16816",
      "arxiv:2104.12756",
      "arxiv:2311.16502",
      "arxiv:2203.10244",
      "arxiv:2404.12390",
      "arxiv:1810.12440",
      "arxiv:1908.02660",
      "arxiv:2312.11805",
      "base_model:google/gemma-3-4b-pt",
      "base_model:finetune:google/gemma-3-4b-pt",
      "license:gemma",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "google/gemma-3-1b-it",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 2527183,
    "likes": 807,
    "tags": [
      "transformers",
      "safetensors",
      "gemma3_text",
      "text-generation",
      "conversational",
      "arxiv:1905.07830",
      "arxiv:1905.10044",
      "arxiv:1911.11641",
      "arxiv:1904.09728",
      "arxiv:1705.03551",
      "arxiv:1911.01547",
      "arxiv:1907.10641",
      "arxiv:1903.00161",
      "arxiv:2009.03300",
      "arxiv:2304.06364",
      "arxiv:2103.03874",
      "arxiv:2110.14168",
      "arxiv:2311.12022",
      "arxiv:2108.07732",
      "arxiv:2107.03374",
      "arxiv:2210.03057",
      "arxiv:2106.03193",
      "arxiv:1910.11856",
      "arxiv:2502.12404",
      "arxiv:2502.21228",
      "arxiv:2404.16816",
      "arxiv:2104.12756",
      "arxiv:2311.16502",
      "arxiv:2203.10244",
      "arxiv:2404.12390",
      "arxiv:1810.12440",
      "arxiv:1908.02660",
      "arxiv:2312.11805",
      "base_model:google/gemma-3-1b-pt",
      "base_model:finetune:google/gemma-3-1b-pt",
      "license:gemma",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "unsloth/gemma-3-12b-it-GGUF",
    "task": "image-to-text",
    "library": "transformers",
    "downloads": 66407,
    "likes": 129,
    "tags": [
      "transformers",
      "gguf",
      "gemma3",
      "image-to-text",
      "unsloth",
      "gemma",
      "google",
      "en",
      "arxiv:1905.07830",
      "arxiv:1905.10044",
      "arxiv:1911.11641",
      "arxiv:1904.09728",
      "arxiv:1705.03551",
      "arxiv:1911.01547",
      "arxiv:1907.10641",
      "arxiv:1903.00161",
      "arxiv:2009.03300",
      "arxiv:2304.06364",
      "arxiv:2103.03874",
      "arxiv:2110.14168",
      "arxiv:2311.12022",
      "arxiv:2108.07732",
      "arxiv:2107.03374",
      "arxiv:2210.03057",
      "arxiv:2106.03193",
      "arxiv:1910.11856",
      "arxiv:2502.12404",
      "arxiv:2502.21228",
      "arxiv:2404.16816",
      "arxiv:2104.12756",
      "arxiv:2311.16502",
      "arxiv:2203.10244",
      "arxiv:2404.12390",
      "arxiv:1810.12440",
      "arxiv:1908.02660",
      "arxiv:2312.11805",
      "base_model:google/gemma-3-12b-it",
      "base_model:quantized:google/gemma-3-12b-it",
      "license:gemma",
      "endpoints_compatible",
      "region:us",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "google/gemma-3-270m-it",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 119722,
    "likes": 532,
    "tags": [
      "transformers",
      "safetensors",
      "gemma3_text",
      "text-generation",
      "gemma3",
      "gemma",
      "google",
      "conversational",
      "arxiv:2503.19786",
      "arxiv:1905.07830",
      "arxiv:1905.10044",
      "arxiv:1911.11641",
      "arxiv:1705.03551",
      "arxiv:1911.01547",
      "arxiv:1907.10641",
      "arxiv:2311.07911",
      "arxiv:2311.12022",
      "arxiv:2411.04368",
      "arxiv:1904.09728",
      "arxiv:1903.00161",
      "arxiv:2009.03300",
      "arxiv:2304.06364",
      "arxiv:2103.03874",
      "arxiv:2110.14168",
      "arxiv:2108.07732",
      "arxiv:2107.03374",
      "arxiv:2403.07974",
      "arxiv:2305.03111",
      "arxiv:2405.04520",
      "arxiv:2210.03057",
      "arxiv:2106.03193",
      "arxiv:1910.11856",
      "arxiv:2502.12404",
      "arxiv:2502.21228",
      "arxiv:2404.16816",
      "arxiv:2104.12756",
      "arxiv:2311.16502",
      "arxiv:2203.10244",
      "arxiv:2404.12390",
      "arxiv:1810.12440",
      "arxiv:1908.02660",
      "arxiv:2310.02255",
      "arxiv:2312.11805",
      "base_model:google/gemma-3-270m",
      "base_model:finetune:google/gemma-3-270m",
      "license:gemma",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "unsloth/Qwen3-Coder-30B-A3B-Instruct-GGUF",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 94450,
    "likes": 394,
    "tags": [
      "transformers",
      "gguf",
      "unsloth",
      "qwen3",
      "qwen",
      "text-generation",
      "arxiv:2505.09388",
      "base_model:Qwen/Qwen3-Coder-30B-A3B-Instruct",
      "base_model:quantized:Qwen/Qwen3-Coder-30B-A3B-Instruct",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us",
      "imatrix",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "DavidAU/OpenAi-GPT-oss-20b-abliterated-uncensored-NEO-Imatrix-gguf",
    "task": "text-generation",
    "library": null,
    "downloads": 124415,
    "likes": 401,
    "tags": [
      "gguf",
      "gpt_oss",
      "gpt-oss",
      "openai",
      "mxfp4",
      "programming",
      "code generation",
      "code",
      "coding",
      "coder",
      "chat",
      "reasoning",
      "thinking",
      "r1",
      "cot",
      "deepseek",
      "128k context",
      "general usage",
      "problem solving",
      "brainstorming",
      "solve riddles",
      "uncensored",
      "abliterated",
      "Neo",
      "MOE",
      "Mixture of Experts",
      "24 experts",
      "NEO Imatrix",
      "Imatrix",
      "DI-Matrix",
      "Tri-Matrix",
      "text-generation",
      "en",
      "base_model:huihui-ai/Huihui-gpt-oss-20b-BF16-abliterated",
      "base_model:quantized:huihui-ai/Huihui-gpt-oss-20b-BF16-abliterated",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us",
      "imatrix",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "Jonny001/Qwen-Image-Edit-Remove-Clothes",
    "task": "image-to-image",
    "library": "diffusers",
    "downloads": 3356,
    "likes": 22,
    "tags": [
      "diffusers",
      "image-generation",
      "lora",
      "Qwen-Image",
      "image-to-image",
      "en",
      "base_model:Qwen/Qwen-Image-Edit",
      "base_model:adapter:Qwen/Qwen-Image-Edit",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-Next-80B-A3B-Instruct",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 2514281,
    "likes": 903,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3_next",
      "text-generation",
      "conversational",
      "arxiv:2309.00071",
      "arxiv:2404.06654",
      "arxiv:2505.09388",
      "arxiv:2501.15383",
      "license:apache-2.0",
      "eval-results",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-Omni-30B-A3B-Instruct",
    "task": "any-to-any",
    "library": "transformers",
    "downloads": 256139,
    "likes": 809,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3_omni_moe",
      "text-to-audio",
      "multimodal",
      "any-to-any",
      "en",
      "license:other",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "kpsss34/FHDR_Uncensored",
    "task": "text-to-image",
    "library": "diffusers",
    "downloads": 3171,
    "likes": 34,
    "tags": [
      "diffusers",
      "safetensors",
      "gguf",
      "art",
      "text-to-image",
      "en",
      "base_model:black-forest-labs/FLUX.1-dev",
      "base_model:quantized:black-forest-labs/FLUX.1-dev",
      "license:other",
      "endpoints_compatible",
      "diffusers:FluxPipeline",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "tencent/HunyuanVideo-1.5",
    "task": "text-to-video",
    "library": "HunyuanVideo-1.5",
    "downloads": 507099,
    "likes": 685,
    "tags": [
      "HunyuanVideo-1.5",
      "diffusers",
      "safetensors",
      "text-to-video",
      "image-to-video",
      "en",
      "zh",
      "arxiv:2511.18870",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "VAGOsolutions/SauerkrautLM-Translator-LFM2.5-1.2B",
    "task": "translation",
    "library": "transformers",
    "downloads": 250,
    "likes": 14,
    "tags": [
      "transformers",
      "safetensors",
      "lfm2",
      "text-generation",
      "translation",
      "multilingual",
      "liquidai",
      "lfm",
      "sauerkrautlm",
      "dpo",
      "any-to-any",
      "en",
      "de",
      "fr",
      "es",
      "it",
      "dataset:custom",
      "base_model:LiquidAI/LFM2.5-1.2B-Instruct",
      "base_model:finetune:LiquidAI/LFM2.5-1.2B-Instruct",
      "license:other",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "LiquidAI/LFM2.5-Audio-1.5B-GGUF",
    "task": null,
    "library": null,
    "downloads": 6910,
    "likes": 54,
    "tags": [
      "gguf",
      "liquid",
      "lfm2.5",
      "edge",
      "llama.cpp",
      "audio",
      "speech",
      "en",
      "base_model:LiquidAI/LFM2.5-Audio-1.5B",
      "base_model:quantized:LiquidAI/LFM2.5-Audio-1.5B",
      "license:other",
      "endpoints_compatible",
      "region:us",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen2.5-3B-Instruct",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 13170401,
    "likes": 376,
    "tags": [
      "transformers",
      "safetensors",
      "qwen2",
      "text-generation",
      "chat",
      "conversational",
      "en",
      "arxiv:2407.10671",
      "base_model:Qwen/Qwen2.5-3B",
      "base_model:finetune:Qwen/Qwen2.5-3B",
      "license:other",
      "text-generation-inference",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "deepseek-ai/DeepSeek-R1",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 335399,
    "likes": 12954,
    "tags": [
      "transformers",
      "safetensors",
      "deepseek_v3",
      "text-generation",
      "conversational",
      "custom_code",
      "arxiv:2501.12948",
      "license:mit",
      "eval-results",
      "text-generation-inference",
      "endpoints_compatible",
      "fp8",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "ByteDance-Seed/UI-TARS-1.5-7B",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 321295,
    "likes": 487,
    "tags": [
      "transformers",
      "safetensors",
      "qwen2_5_vl",
      "image-to-text",
      "multimodal",
      "gui",
      "image-text-to-text",
      "conversational",
      "en",
      "arxiv:2501.12326",
      "arxiv:2404.07972",
      "arxiv:2409.08264",
      "arxiv:2401.13919",
      "arxiv:2504.01382",
      "arxiv:2405.14573",
      "arxiv:2410.23218",
      "arxiv:2504.07981",
      "license:apache-2.0",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-Embedding-0.6B",
    "task": "feature-extraction",
    "library": "sentence-transformers",
    "downloads": 2114893,
    "likes": 829,
    "tags": [
      "sentence-transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "transformers",
      "sentence-similarity",
      "feature-extraction",
      "text-embeddings-inference",
      "arxiv:2506.05176",
      "base_model:Qwen/Qwen3-0.6B-Base",
      "base_model:finetune:Qwen/Qwen3-0.6B-Base",
      "license:apache-2.0",
      "text-generation-inference",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "MongoDB/mdbr-leaf-ir",
    "task": "sentence-similarity",
    "library": "sentence-transformers",
    "downloads": 16182,
    "likes": 51,
    "tags": [
      "sentence-transformers",
      "onnx",
      "safetensors",
      "bert",
      "feature-extraction",
      "transformers",
      "sentence-similarity",
      "text-embeddings-inference",
      "information-retrieval",
      "knowledge-distillation",
      "transformers.js",
      "en",
      "arxiv:2509.12539",
      "arxiv:2205.13147",
      "license:apache-2.0",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen-Image-Edit",
    "task": "image-to-image",
    "library": "diffusers",
    "downloads": 48215,
    "likes": 2268,
    "tags": [
      "diffusers",
      "safetensors",
      "image-to-image",
      "en",
      "zh",
      "arxiv:2508.02324",
      "license:apache-2.0",
      "diffusers:QwenImageEditPipeline",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Wan-AI/Wan2.2-Animate-14B",
    "task": "video-to-video",
    "library": "diffusers",
    "downloads": 33161,
    "likes": 983,
    "tags": [
      "diffusers",
      "onnx",
      "safetensors",
      "video-to-video",
      "arxiv:2503.20314",
      "base_model:Wan-AI/Wan2.2-I2V-A14B",
      "base_model:quantized:Wan-AI/Wan2.2-I2V-A14B",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "nvidia/Nemotron-Flash-3B-Instruct",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 798,
    "likes": 42,
    "tags": [
      "transformers",
      "safetensors",
      "nemotron_flash",
      "text-generation",
      "custom_code",
      "arxiv:2511.18890",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "tiiuae/Falcon-H1R-7B-GGUF",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 10494,
    "likes": 52,
    "tags": [
      "transformers",
      "gguf",
      "falcon-h1r",
      "text-generation",
      "en",
      "arxiv:2601.02346",
      "base_model:tiiuae/Falcon-H1-7B-Base",
      "base_model:quantized:tiiuae/Falcon-H1-7B-Base",
      "license:other",
      "endpoints_compatible",
      "region:us",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "mistralai/Devstral-Small-2-24B-Instruct-2512",
    "task": null,
    "library": "vllm",
    "downloads": 275645,
    "likes": 485,
    "tags": [
      "vllm",
      "safetensors",
      "mistral3",
      "mistral-common",
      "arxiv:2501.19399",
      "base_model:mistralai/Mistral-Small-3.1-24B-Base-2503",
      "base_model:quantized:mistralai/Mistral-Small-3.1-24B-Base-2503",
      "license:apache-2.0",
      "fp8",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "malcolmrey/zimage",
    "task": null,
    "library": null,
    "downloads": 0,
    "likes": 111,
    "tags": [
      "license:cc0-1.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "elyza/ELYZA-Diffusion-Base-1.0-Dream-7B",
    "task": null,
    "library": null,
    "downloads": 9,
    "likes": 13,
    "tags": [
      "safetensors",
      "Dream",
      "custom_code",
      "en",
      "ja",
      "arxiv:2508.15487",
      "base_model:Dream-org/Dream-v0-Instruct-7B",
      "base_model:finetune:Dream-org/Dream-v0-Instruct-7B",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "YaoJiefu/Line-drawing-generates-special-effects",
    "task": "image-to-image",
    "library": "diffusers",
    "downloads": 412,
    "likes": 13,
    "tags": [
      "diffusers",
      "image-to-image",
      "base_model:Qwen/Qwen-Image-Edit-2509",
      "base_model:finetune:Qwen/Qwen-Image-Edit-2509",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  }
]