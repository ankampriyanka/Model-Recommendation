[
  {
    "id": "zai-org/GLM-OCR",
    "task": "image-to-text",
    "library": "transformers",
    "downloads": 248295,
    "likes": 834,
    "tags": [
      "transformers",
      "safetensors",
      "glm_ocr",
      "image-to-text",
      "zh",
      "en",
      "fr",
      "es",
      "ru",
      "de",
      "ja",
      "ko",
      "license:mit",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-Coder-Next",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 76632,
    "likes": 627,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3_next",
      "text-generation",
      "conversational",
      "license:apache-2.0",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "openbmb/MiniCPM-o-4_5",
    "task": "any-to-any",
    "library": "transformers",
    "downloads": 17457,
    "likes": 641,
    "tags": [
      "transformers",
      "onnx",
      "safetensors",
      "minicpmo",
      "feature-extraction",
      "minicpm-o",
      "minicpm-v",
      "multimodal",
      "full-duplex",
      "any-to-any",
      "custom_code",
      "arxiv:2408.01800",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "moonshotai/Kimi-K2.5",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 404508,
    "likes": 1879,
    "tags": [
      "transformers",
      "safetensors",
      "kimi_k25",
      "feature-extraction",
      "compressed-tensors",
      "image-text-to-text",
      "conversational",
      "custom_code",
      "arxiv:2602.02276",
      "license:other",
      "eval-results",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "stepfun-ai/Step-3.5-Flash",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 104643,
    "likes": 532,
    "tags": [
      "transformers",
      "safetensors",
      "step3p5",
      "text-generation",
      "conversational",
      "custom_code",
      "arxiv:2601.05593",
      "arxiv:2507.19427",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "ACE-Step/Ace-Step1.5",
    "task": "text-to-audio",
    "library": "transformers",
    "downloads": 23178,
    "likes": 453,
    "tags": [
      "transformers",
      "diffusers",
      "safetensors",
      "acestep",
      "feature-extraction",
      "audio",
      "music",
      "text2music",
      "text-to-audio",
      "custom_code",
      "arxiv:2602.00744",
      "license:mit",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "mistralai/Voxtral-Mini-4B-Realtime-2602",
    "task": null,
    "library": "vllm",
    "downloads": 2427,
    "likes": 396,
    "tags": [
      "vllm",
      "mistral-common",
      "en",
      "fr",
      "es",
      "de",
      "ru",
      "zh",
      "ja",
      "it",
      "pt",
      "nl",
      "ar",
      "hi",
      "ko",
      "base_model:mistralai/Ministral-3-3B-Base-2512",
      "base_model:finetune:mistralai/Ministral-3-3B-Base-2512",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "circlestone-labs/Anima",
    "task": null,
    "library": "diffusion-single-file",
    "downloads": 71655,
    "likes": 519,
    "tags": [
      "diffusion-single-file",
      "comfyui",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "unsloth/Qwen3-Coder-Next-GGUF",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 185433,
    "likes": 228,
    "tags": [
      "transformers",
      "gguf",
      "qwen3_next",
      "unsloth",
      "qwen",
      "qwen3",
      "text-generation",
      "base_model:Qwen/Qwen3-Coder-Next",
      "base_model:quantized:Qwen/Qwen3-Coder-Next",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us",
      "imatrix",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "internlm/Intern-S1-Pro",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 8055,
    "likes": 208,
    "tags": [
      "transformers",
      "safetensors",
      "interns1_pro",
      "text-generation",
      "image-text-to-text",
      "conversational",
      "custom_code",
      "arxiv:2508.15763",
      "license:apache-2.0",
      "fp8",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "TeichAI/GLM-4.7-Flash-Claude-Opus-4.5-High-Reasoning-Distill-GGUF",
    "task": null,
    "library": null,
    "downloads": 25586,
    "likes": 210,
    "tags": [
      "gguf",
      "text-generation-inference",
      "llama.cpp",
      "unsloth",
      "glm4_moe_lite",
      "dataset:TeichAI/claude-4.5-opus-high-reasoning-250x",
      "base_model:TeichAI/GLM-4.7-Flash-Claude-Opus-4.5-High-Reasoning-Distill",
      "base_model:quantized:TeichAI/GLM-4.7-Flash-Claude-Opus-4.5-High-Reasoning-Distill",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "nvidia/personaplex-7b-v1",
    "task": "audio-to-audio",
    "library": "moshi",
    "downloads": 190473,
    "likes": 1707,
    "tags": [
      "moshi",
      "safetensors",
      "personaplex",
      "speech-to-speech",
      "audio-to-audio",
      "en",
      "arxiv:2503.04721",
      "arxiv:2110.13900",
      "arxiv:2410.00037",
      "base_model:kyutai/moshiko-pytorch-bf16",
      "base_model:finetune:kyutai/moshiko-pytorch-bf16",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-ASR-1.7B",
    "task": "automatic-speech-recognition",
    "library": null,
    "downloads": 181826,
    "likes": 419,
    "tags": [
      "safetensors",
      "qwen3_asr",
      "automatic-speech-recognition",
      "arxiv:2601.21337",
      "license:apache-2.0",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "DavidAU/GLM-4.7-Flash-Uncensored-Heretic-NEO-CODE-Imatrix-MAX-GGUF",
    "task": "text-generation",
    "library": null,
    "downloads": 49733,
    "likes": 152,
    "tags": [
      "gguf",
      "GLM 4.7 Flash",
      "thinking",
      "reasoning",
      "NEO Imatrix",
      "MAX Quants",
      "16 bit precision output tensor",
      "heretic",
      "uncensored",
      "abliterated",
      "deep reasoning",
      "fine tune",
      "creative",
      "creative writing",
      "fiction writing",
      "plot generation",
      "sub-plot generation",
      "story generation",
      "scene continue",
      "storytelling",
      "fiction story",
      "science fiction",
      "romance",
      "all genres",
      "story",
      "writing",
      "vivid prosing",
      "vivid writing",
      "fiction",
      "roleplaying",
      "bfloat16",
      "swearing",
      "rp",
      "horror",
      "text-generation",
      "en",
      "zh",
      "base_model:Olafangensan/GLM-4.7-Flash-heretic",
      "base_model:quantized:Olafangensan/GLM-4.7-Flash-heretic",
      "license:mit",
      "endpoints_compatible",
      "region:us",
      "imatrix",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "inference-net/Schematron-3B",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 1387,
    "likes": 221,
    "tags": [
      "transformers",
      "safetensors",
      "llama",
      "text-generation",
      "conversational",
      "base_model:meta-llama/Llama-3.2-3B-Instruct",
      "base_model:finetune:meta-llama/Llama-3.2-3B-Instruct",
      "license:llama3.2",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-Coder-Next-GGUF",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 23259,
    "likes": 115,
    "tags": [
      "transformers",
      "gguf",
      "text-generation",
      "arxiv:2309.00071",
      "license:apache-2.0",
      "endpoints_compatible",
      "deploy:azure",
      "region:us",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "tencent/HunyuanImage-3.0-Instruct",
    "task": "image-to-image",
    "library": null,
    "downloads": 682,
    "likes": 328,
    "tags": [
      "safetensors",
      "hunyuan_image_3_moe",
      "image-to-image",
      "custom_code",
      "arxiv:2509.23951",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "stepfun-ai/Step-3.5-Flash-Int4",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 6054,
    "likes": 113,
    "tags": [
      "transformers",
      "gguf",
      "step3p5",
      "text-generation",
      "custom_code",
      "arxiv:2601.05593",
      "arxiv:2507.19427",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us",
      "imatrix",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "robbyant/lingbot-world-base-cam",
    "task": "image-to-video",
    "library": "diffusers",
    "downloads": 0,
    "likes": 298,
    "tags": [
      "diffusers",
      "safetensors",
      "World Model",
      "image-to-video",
      "en",
      "arxiv:2601.20540",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "deepseek-ai/DeepSeek-OCR-2",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 592080,
    "likes": 712,
    "tags": [
      "transformers",
      "safetensors",
      "deepseek_vl_v2",
      "feature-extraction",
      "deepseek",
      "vision-language",
      "ocr",
      "custom_code",
      "image-text-to-text",
      "multilingual",
      "arxiv:2601.20552",
      "arxiv:2510.18234",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "PaddlePaddle/PaddleOCR-VL-1.5",
    "task": "image-text-to-text",
    "library": "PaddleOCR",
    "downloads": 8504,
    "likes": 364,
    "tags": [
      "PaddleOCR",
      "safetensors",
      "paddleocr_vl",
      "ERNIE4.5",
      "PaddlePaddle",
      "image-to-text",
      "ocr",
      "document-parse",
      "layout",
      "table",
      "formula",
      "chart",
      "seal",
      "spotting",
      "image-text-to-text",
      "conversational",
      "custom_code",
      "en",
      "zh",
      "multilingual",
      "arxiv:2601.21957",
      "base_model:baidu/ERNIE-4.5-0.3B-Paddle",
      "base_model:finetune:baidu/ERNIE-4.5-0.3B-Paddle",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "zai-org/GLM-4.7-Flash",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 1294865,
    "likes": 1460,
    "tags": [
      "transformers",
      "safetensors",
      "glm4_moe_lite",
      "text-generation",
      "conversational",
      "en",
      "zh",
      "arxiv:2508.06471",
      "license:mit",
      "eval-results",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Tongyi-MAI/Z-Image",
    "task": "text-to-image",
    "library": "diffusers",
    "downloads": 16605,
    "likes": 863,
    "tags": [
      "diffusers",
      "safetensors",
      "text-to-image",
      "en",
      "arxiv:2511.22699",
      "license:apache-2.0",
      "diffusers:ZImagePipeline",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "kugelaudio/kugelaudio-0-open",
    "task": "text-to-speech",
    "library": null,
    "downloads": 8796,
    "likes": 104,
    "tags": [
      "safetensors",
      "kugelaudio",
      "text-to-speech",
      "tts",
      "speech-synthesis",
      "audio-generation",
      "european-languages",
      "diffusion",
      "autoregressive",
      "en",
      "de",
      "fr",
      "es",
      "it",
      "pt",
      "nl",
      "pl",
      "ru",
      "uk",
      "cs",
      "ro",
      "hu",
      "sv",
      "da",
      "fi",
      "no",
      "el",
      "bg",
      "sk",
      "hr",
      "sr",
      "tr",
      "license:mit",
      "model-index",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "FutureMa/Eva-4B-V2",
    "task": "text-classification",
    "library": "transformers",
    "downloads": 187,
    "likes": 78,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "finance",
      "earnings-calls",
      "evasion-detection",
      "nlp",
      "text-classification",
      "en",
      "dataset:FutureMa/EvasionBench",
      "arxiv:2601.09142",
      "base_model:Qwen/Qwen3-4B-Instruct-2507",
      "base_model:finetune:Qwen/Qwen3-4B-Instruct-2507",
      "license:apache-2.0",
      "text-embeddings-inference",
      "endpoints_compatible",
      "region:us",
      "deploy:azure"
    ],
    "description": ""
  },
  {
    "id": "Lightricks/LTX-2",
    "task": "image-to-video",
    "library": "diffusers",
    "downloads": 2686336,
    "likes": 1478,
    "tags": [
      "diffusers",
      "safetensors",
      "image-to-video",
      "text-to-video",
      "video-to-video",
      "image-text-to-video",
      "audio-to-video",
      "text-to-audio",
      "video-to-audio",
      "audio-to-audio",
      "text-to-audio-video",
      "image-to-audio-video",
      "image-text-to-audio-video",
      "ltx-2",
      "ltx-video",
      "ltxv",
      "lightricks",
      "en",
      "de",
      "es",
      "fr",
      "ja",
      "ko",
      "zh",
      "it",
      "pt",
      "arxiv:2601.03233",
      "license:other",
      "diffusers:LTX2Pipeline",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Comfy-Org/ace_step_1.5_ComfyUI_files",
    "task": null,
    "library": null,
    "downloads": 0,
    "likes": 71,
    "tags": [
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "microsoft/VibeVoice-ASR",
    "task": "automatic-speech-recognition",
    "library": "transformers",
    "downloads": 328901,
    "likes": 838,
    "tags": [
      "transformers",
      "safetensors",
      "vibevoice",
      "ASR",
      "Transcriptoin",
      "Diarization",
      "Speech-to-Text",
      "automatic-speech-recognition",
      "en",
      "zh",
      "es",
      "pt",
      "de",
      "ja",
      "ko",
      "fr",
      "ru",
      "id",
      "sv",
      "it",
      "he",
      "nl",
      "pl",
      "no",
      "tr",
      "th",
      "ar",
      "hu",
      "ca",
      "cs",
      "da",
      "fa",
      "af",
      "hi",
      "fi",
      "et",
      "aa",
      "el",
      "ro",
      "vi",
      "bg",
      "is",
      "sl",
      "sk",
      "lt",
      "sw",
      "uk",
      "kl",
      "lv",
      "hr",
      "ne",
      "sr",
      "tl",
      "yi",
      "ms",
      "ur",
      "mn",
      "hy",
      "jv",
      "arxiv:2601.18184",
      "license:mit",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-ASR-0.6B",
    "task": "automatic-speech-recognition",
    "library": null,
    "downloads": 40719,
    "likes": 187,
    "tags": [
      "safetensors",
      "qwen3_asr",
      "automatic-speech-recognition",
      "arxiv:2601.21337",
      "license:apache-2.0",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-TTS-12Hz-1.7B-CustomVoice",
    "task": "text-to-speech",
    "library": null,
    "downloads": 402177,
    "likes": 900,
    "tags": [
      "safetensors",
      "qwen3_tts",
      "text-to-speech",
      "arxiv:2601.15621",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Phr00t/LTX2-Rapid-Merges",
    "task": "image-text-to-video",
    "library": null,
    "downloads": 0,
    "likes": 282,
    "tags": [
      "ltx2",
      "t2v",
      "i2v",
      "image-text-to-video",
      "base_model:Lightricks/LTX-2",
      "base_model:finetune:Lightricks/LTX-2",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Alissonerdx/BFS-Best-Face-Swap-Video",
    "task": "image-to-video",
    "library": "diffusers",
    "downloads": 168,
    "likes": 67,
    "tags": [
      "diffusers",
      "ltx-2",
      "ic-lora",
      "head-swap",
      "video-to-video",
      "image-to-video",
      "bfs",
      "lora",
      "base_model:Lightricks/LTX-2",
      "base_model:adapter:Lightricks/LTX-2",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "GuangyuanSD/Z-Image-Distilled",
    "task": "text-to-image",
    "library": "diffusers",
    "downloads": 4259,
    "likes": 85,
    "tags": [
      "diffusers",
      "safetensors",
      "Z",
      "text-to-image",
      "en",
      "zh",
      "base_model:Tongyi-MAI/Z-Image",
      "base_model:finetune:Tongyi-MAI/Z-Image",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "UCSB-SURFI/VulnLLM-R-7B",
    "task": "text-generation",
    "library": null,
    "downloads": 2197,
    "likes": 84,
    "tags": [
      "safetensors",
      "qwen2",
      "security",
      "vulnerability-detection",
      "code-analysis",
      "reasoning",
      "llm",
      "text-generation",
      "conversational",
      "en",
      "code",
      "arxiv:2512.07533",
      "base_model:Qwen/Qwen2.5-7B-Instruct",
      "base_model:finetune:Qwen/Qwen2.5-7B-Instruct",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-Coder-Next-FP8",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 63713,
    "likes": 54,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3_next",
      "text-generation",
      "conversational",
      "license:apache-2.0",
      "endpoints_compatible",
      "fp8",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "MiniMaxAI/MiniMax-M2.1",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 84459,
    "likes": 1242,
    "tags": [
      "transformers",
      "safetensors",
      "minimax_m2",
      "text-generation",
      "conversational",
      "custom_code",
      "arxiv:2509.06501",
      "license:other",
      "eval-results",
      "endpoints_compatible",
      "fp8",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "fal/Qwen-Image-Edit-2511-Multiple-Angles-LoRA",
    "task": "image-to-image",
    "library": "diffusers",
    "downloads": 88814,
    "likes": 956,
    "tags": [
      "diffusers",
      "qwen",
      "qwen-image-edit",
      "qwen-image-edit-2511",
      "lora",
      "multi-angle",
      "camera-angles",
      "camera-control",
      "image-editing",
      "image-to-image",
      "gaussian-splatting",
      "fal",
      "en",
      "base_model:Qwen/Qwen-Image-Edit-2511",
      "base_model:adapter:Qwen/Qwen-Image-Edit-2511",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Tongyi-MAI/Z-Image-Turbo",
    "task": "text-to-image",
    "library": "diffusers",
    "downloads": 657765,
    "likes": 4067,
    "tags": [
      "diffusers",
      "safetensors",
      "text-to-image",
      "en",
      "arxiv:2511.22699",
      "arxiv:2511.22677",
      "arxiv:2511.13649",
      "license:apache-2.0",
      "diffusers:ZImagePipeline",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Octen/Octen-Embedding-8B",
    "task": "sentence-similarity",
    "library": "sentence-transformers",
    "downloads": 9936,
    "likes": 111,
    "tags": [
      "sentence-transformers",
      "safetensors",
      "qwen3",
      "sentence-similarity",
      "feature-extraction",
      "embedding",
      "text-embedding",
      "retrieval",
      "en",
      "zh",
      "multilingual",
      "base_model:Qwen/Qwen3-Embedding-8B",
      "base_model:finetune:Qwen/Qwen3-Embedding-8B",
      "license:apache-2.0",
      "text-embeddings-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "meta-llama/Llama-3.1-8B-Instruct",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 6301194,
    "likes": 5407,
    "tags": [
      "transformers",
      "safetensors",
      "llama",
      "text-generation",
      "facebook",
      "meta",
      "pytorch",
      "llama-3",
      "conversational",
      "en",
      "de",
      "fr",
      "it",
      "pt",
      "hi",
      "es",
      "th",
      "arxiv:2204.05149",
      "base_model:meta-llama/Llama-3.1-8B",
      "base_model:finetune:meta-llama/Llama-3.1-8B",
      "license:llama3.1",
      "eval-results",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "lightonai/LightOnOCR-2-1B",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 188457,
    "likes": 504,
    "tags": [
      "transformers",
      "safetensors",
      "mistral3",
      "text-generation",
      "ocr",
      "document-understanding",
      "vision-language",
      "pdf",
      "tables",
      "forms",
      "image-text-to-text",
      "conversational",
      "en",
      "fr",
      "de",
      "es",
      "it",
      "nl",
      "pt",
      "sv",
      "da",
      "zh",
      "ja",
      "arxiv:2601.14251",
      "arxiv:2412.13663",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:eu"
    ],
    "description": ""
  },
  {
    "id": "openai/gpt-oss-20b",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 5958548,
    "likes": 4317,
    "tags": [
      "transformers",
      "safetensors",
      "gpt_oss",
      "text-generation",
      "vllm",
      "conversational",
      "arxiv:2508.10925",
      "license:apache-2.0",
      "endpoints_compatible",
      "8-bit",
      "mxfp4",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Phr00t/Qwen-Image-Edit-Rapid-AIO",
    "task": "text-to-image",
    "library": "comfyUI",
    "downloads": 0,
    "likes": 1602,
    "tags": [
      "comfyUI",
      "qwen",
      "qwen-edit",
      "t2i",
      "i2i",
      "text-to-image",
      "base_model:Qwen/Qwen-Image-Edit-2511",
      "base_model:finetune:Qwen/Qwen-Image-Edit-2511",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-Coder-Next-Base",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 1013,
    "likes": 41,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3_next",
      "text-generation",
      "conversational",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Wuli-art/Qwen-Image-2512-Turbo-LoRA-2-Steps",
    "task": "text-to-image",
    "library": "diffusers",
    "downloads": 12362,
    "likes": 86,
    "tags": [
      "diffusers",
      "Qwen",
      "distillation",
      "lora",
      "text-to-image",
      "en",
      "zh",
      "base_model:Qwen/Qwen-Image-2512",
      "base_model:adapter:Qwen/Qwen-Image-2512",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "black-forest-labs/FLUX.2-klein-4B",
    "task": "image-to-image",
    "library": "diffusers",
    "downloads": 137405,
    "likes": 442,
    "tags": [
      "diffusers",
      "safetensors",
      "text-to-image",
      "image-editing",
      "flux",
      "diffusion-single-file",
      "image-to-image",
      "en",
      "license:apache-2.0",
      "diffusers:Flux2KleinPipeline",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "unsloth/GLM-4.7-Flash-GGUF",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 342998,
    "likes": 425,
    "tags": [
      "transformers",
      "gguf",
      "unsloth",
      "text-generation",
      "en",
      "zh",
      "arxiv:2508.06471",
      "base_model:zai-org/GLM-4.7-Flash",
      "base_model:quantized:zai-org/GLM-4.7-Flash",
      "license:mit",
      "endpoints_compatible",
      "deploy:azure",
      "region:us",
      "imatrix",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "sentence-transformers/all-MiniLM-L6-v2",
    "task": "sentence-similarity",
    "library": "sentence-transformers",
    "downloads": 151373219,
    "likes": 4442,
    "tags": [
      "sentence-transformers",
      "pytorch",
      "tf",
      "rust",
      "onnx",
      "safetensors",
      "openvino",
      "bert",
      "feature-extraction",
      "sentence-similarity",
      "transformers",
      "en",
      "dataset:s2orc",
      "dataset:flax-sentence-embeddings/stackexchange_xml",
      "dataset:ms_marco",
      "dataset:gooaq",
      "dataset:yahoo_answers_topics",
      "dataset:code_search_net",
      "dataset:search_qa",
      "dataset:eli5",
      "dataset:snli",
      "dataset:multi_nli",
      "dataset:wikihow",
      "dataset:natural_questions",
      "dataset:trivia_qa",
      "dataset:embedding-data/sentence-compression",
      "dataset:embedding-data/flickr30k-captions",
      "dataset:embedding-data/altlex",
      "dataset:embedding-data/simple-wiki",
      "dataset:embedding-data/QQP",
      "dataset:embedding-data/SPECTER",
      "dataset:embedding-data/PAQ_pairs",
      "dataset:embedding-data/WikiAnswers",
      "arxiv:1904.06472",
      "arxiv:2102.07033",
      "arxiv:2104.08727",
      "arxiv:1704.05179",
      "arxiv:1810.09305",
      "license:apache-2.0",
      "text-embeddings-inference",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "openai/gpt-oss-120b",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 3249747,
    "likes": 4457,
    "tags": [
      "transformers",
      "safetensors",
      "gpt_oss",
      "text-generation",
      "vllm",
      "conversational",
      "arxiv:2508.10925",
      "license:apache-2.0",
      "endpoints_compatible",
      "8-bit",
      "mxfp4",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "facebook/sam3",
    "task": "mask-generation",
    "library": "transformers",
    "downloads": 1643424,
    "likes": 1533,
    "tags": [
      "transformers",
      "safetensors",
      "sam3_video",
      "feature-extraction",
      "sam3",
      "mask-generation",
      "en",
      "license:other",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "ACE-Step/acestep-v15-base",
    "task": "text-to-audio",
    "library": "transformers",
    "downloads": 3373,
    "likes": 35,
    "tags": [
      "transformers",
      "safetensors",
      "acestep",
      "feature-extraction",
      "audio",
      "music",
      "text2music",
      "text-to-audio",
      "custom_code",
      "arxiv:2602.00744",
      "license:mit",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "meituan-longcat/LongCat-Image-Edit-Turbo",
    "task": "image-to-image",
    "library": "transformers",
    "downloads": 11562,
    "likes": 35,
    "tags": [
      "transformers",
      "diffusers",
      "safetensors",
      "image-to-image",
      "en",
      "zh",
      "arxiv:2512.07584",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "OpenMOSS-Team/MOVA-720p",
    "task": "image-to-video",
    "library": "diffusers",
    "downloads": 1638,
    "likes": 90,
    "tags": [
      "diffusers",
      "safetensors",
      "image-to-video",
      "image-text-to-video",
      "image-to-audio-video",
      "image-text-to-audio-video",
      "MOVA",
      "OpenMOSS",
      "SII",
      "MOSI",
      "sglang-diffusion",
      "license:apache-2.0",
      "diffusers:MOVA",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "zai-org/GLM-4.7",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 101888,
    "likes": 1898,
    "tags": [
      "transformers",
      "safetensors",
      "glm4_moe",
      "text-generation",
      "conversational",
      "en",
      "zh",
      "arxiv:2508.06471",
      "license:mit",
      "eval-results",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "unsloth/Kimi-K2.5-GGUF",
    "task": null,
    "library": "transformers",
    "downloads": 32163,
    "likes": 193,
    "tags": [
      "transformers",
      "gguf",
      "unsloth",
      "kimi_k25",
      "base_model:moonshotai/Kimi-K2.5",
      "base_model:quantized:moonshotai/Kimi-K2.5",
      "license:other",
      "endpoints_compatible",
      "region:us",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "unsloth/Z-Image-GGUF",
    "task": "text-to-image",
    "library": "ggml",
    "downloads": 15888,
    "likes": 99,
    "tags": [
      "ggml",
      "gguf",
      "unsloth",
      "quantized",
      "text-to-image",
      "en",
      "arxiv:2511.22699",
      "base_model:Tongyi-MAI/Z-Image",
      "base_model:quantized:Tongyi-MAI/Z-Image",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "trillionlabs/gWorld-8B",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 258,
    "likes": 34,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3_vl",
      "image-to-text",
      "image-text-to-text",
      "conversational",
      "en",
      "ko",
      "arxiv:2602.01576",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "pyannote/speaker-diarization-3.1",
    "task": "automatic-speech-recognition",
    "library": "pyannote-audio",
    "downloads": 12716871,
    "likes": 1521,
    "tags": [
      "pyannote-audio",
      "pyannote",
      "pyannote-audio-pipeline",
      "audio",
      "voice",
      "speech",
      "speaker",
      "speaker-diarization",
      "speaker-change-detection",
      "voice-activity-detection",
      "overlapped-speech-detection",
      "automatic-speech-recognition",
      "arxiv:2111.14448",
      "arxiv:2012.01477",
      "license:mit",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "black-forest-labs/FLUX.1-dev",
    "task": "text-to-image",
    "library": "diffusers",
    "downloads": 815002,
    "likes": 12272,
    "tags": [
      "diffusers",
      "safetensors",
      "text-to-image",
      "image-generation",
      "flux",
      "en",
      "license:other",
      "endpoints_compatible",
      "diffusers:FluxPipeline",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "ytu-ce-cosmos/Turkish-Gemma-9b-T1",
    "task": "text-generation",
    "library": null,
    "downloads": 958,
    "likes": 61,
    "tags": [
      "safetensors",
      "gemma2",
      "Turkish",
      "DPO",
      "SFT",
      "conversational",
      "instruction",
      "reasoning",
      "thinking",
      "text-generation",
      "tr",
      "license:gemma",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "black-forest-labs/FLUX.2-dev",
    "task": "image-to-image",
    "library": "diffusers",
    "downloads": 152704,
    "likes": 1340,
    "tags": [
      "diffusers",
      "safetensors",
      "image-generation",
      "image-editing",
      "flux",
      "diffusion-single-file",
      "image-to-image",
      "en",
      "license:other",
      "diffusers:Flux2Pipeline",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "meituan-longcat/LongCat-Flash-Lite",
    "task": "text-generation",
    "library": "LongCat-Flash-Lite",
    "downloads": 2197,
    "likes": 154,
    "tags": [
      "LongCat-Flash-Lite",
      "safetensors",
      "text-generation",
      "transformers",
      "conversational",
      "custom_code",
      "arxiv:2601.21204",
      "license:mit",
      "eval-results",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-ForcedAligner-0.6B",
    "task": "automatic-speech-recognition",
    "library": null,
    "downloads": 17420,
    "likes": 78,
    "tags": [
      "safetensors",
      "qwen3_asr",
      "automatic-speech-recognition",
      "arxiv:2601.21337",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "stepfun-ai/Step-3.5-Flash-FP8",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 8207,
    "likes": 43,
    "tags": [
      "transformers",
      "safetensors",
      "step3p5",
      "text-generation",
      "conversational",
      "custom_code",
      "arxiv:2601.05593",
      "arxiv:2507.19427",
      "license:apache-2.0",
      "fp8",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "lovedheart/Qwen3-Coder-Next-REAP-48B-A3B-GGUF",
    "task": null,
    "library": null,
    "downloads": 4232,
    "likes": 31,
    "tags": [
      "gguf",
      "text-generation-inference",
      "base_model:Qwen/Qwen3-Coder-Next",
      "base_model:quantized:Qwen/Qwen3-Coder-Next",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "hexgrad/Kokoro-82M",
    "task": "text-to-speech",
    "library": null,
    "downloads": 5363093,
    "likes": 5675,
    "tags": [
      "text-to-speech",
      "en",
      "arxiv:2306.07691",
      "arxiv:2203.02395",
      "base_model:yl4579/StyleTTS2-LJSpeech",
      "base_model:finetune:yl4579/StyleTTS2-LJSpeech",
      "doi:10.57967/hf/4329",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-NVFP4",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 104141,
    "likes": 81,
    "tags": [
      "transformers",
      "safetensors",
      "nemotron_h",
      "feature-extraction",
      "nvidia",
      "pytorch",
      "text-generation",
      "conversational",
      "custom_code",
      "en",
      "es",
      "fr",
      "de",
      "ja",
      "it",
      "dataset:nvidia/Nemotron-Pretraining-Code-v1",
      "dataset:nvidia/Nemotron-CC-v2",
      "dataset:nvidia/Nemotron-Pretraining-SFT-v1",
      "dataset:nvidia/Nemotron-CC-Math-v1",
      "dataset:nvidia/Nemotron-Pretraining-Code-v2",
      "dataset:nvidia/Nemotron-Pretraining-Specialized-v1",
      "dataset:nvidia/Nemotron-CC-v2.1",
      "dataset:nvidia/Nemotron-CC-Code-v1",
      "dataset:nvidia/Nemotron-Pretraining-Dataset-sample",
      "dataset:nvidia/Nemotron-Competitive-Programming-v1",
      "dataset:nvidia/Nemotron-Math-v2",
      "dataset:nvidia/Nemotron-Agentic-v1",
      "dataset:nvidia/Nemotron-Math-Proofs-v1",
      "dataset:nvidia/Nemotron-Instruction-Following-Chat-v1",
      "dataset:nvidia/Nemotron-Science-v1",
      "dataset:nvidia/Nemotron-3-Nano-RL-Training-Blend",
      "arxiv:2512.20848",
      "arxiv:2512.20856",
      "arxiv:2601.20088",
      "base_model:nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16",
      "base_model:quantized:nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16",
      "license:other",
      "8-bit",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "RuneXX/LTX-2-Workflows",
    "task": null,
    "library": null,
    "downloads": 0,
    "likes": 228,
    "tags": [
      "ltx",
      "ltx-2",
      "comfyui",
      "comfy",
      "GGUF",
      "ltx-video",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "tencent/Youtu-VL-4B-Instruct",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 3892,
    "likes": 144,
    "tags": [
      "transformers",
      "safetensors",
      "youtu_vl",
      "text-generation",
      "image-text-to-text",
      "conversational",
      "custom_code",
      "arxiv:2601.19798",
      "arxiv:2512.24618",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Tele-AI/TeleStyle",
    "task": "any-to-any",
    "library": null,
    "downloads": 0,
    "likes": 56,
    "tags": [
      "video",
      "image",
      "stylization",
      "any-to-any",
      "en",
      "arxiv:2601.20175",
      "base_model:Qwen/Qwen-Image-Edit-2509",
      "base_model:finetune:Qwen/Qwen-Image-Edit-2509",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Skywork/SkyReels-V3-A2V-19B",
    "task": "image-to-video",
    "library": "diffusers",
    "downloads": 1401,
    "likes": 60,
    "tags": [
      "diffusers",
      "safetensors",
      "i2v",
      "image-to-video",
      "arxiv:2601.17323",
      "arxiv:2506.00830",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "TeichAI/GLM-4.7-Flash-Claude-Opus-4.5-High-Reasoning-Distill",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 1718,
    "likes": 33,
    "tags": [
      "transformers",
      "safetensors",
      "glm4_moe_lite",
      "text-generation",
      "text-generation-inference",
      "unsloth",
      "conversational",
      "dataset:TeichAI/claude-4.5-opus-high-reasoning-250x",
      "base_model:unsloth/GLM-4.7-Flash",
      "base_model:finetune:unsloth/GLM-4.7-Flash",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "nvidia/parakeet-ctc-0.6b-Vietnamese",
    "task": "automatic-speech-recognition",
    "library": "nemo",
    "downloads": 1240,
    "likes": 65,
    "tags": [
      "nemo",
      "Nemo",
      "ASR",
      "Pytorch",
      "FastConformer",
      "Parakeet",
      "CTC",
      "automatic-speech-recognition",
      "audio",
      "speech",
      "vi",
      "arxiv:2305.05084",
      "arxiv:2005.08100",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "ACE-Step/acestep-5Hz-lm-4B",
    "task": "text-to-audio",
    "library": "transformers",
    "downloads": 4600,
    "likes": 27,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "audio",
      "music",
      "text2music",
      "text-to-audio",
      "arxiv:2602.00744",
      "license:mit",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "allenai/SERA-32B",
    "task": null,
    "library": null,
    "downloads": 921,
    "likes": 96,
    "tags": [
      "safetensors",
      "qwen3",
      "arxiv:2601.20789",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "arcee-ai/Trinity-Large-Preview",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 1537,
    "likes": 139,
    "tags": [
      "transformers",
      "safetensors",
      "afmoe",
      "text-generation",
      "conversational",
      "custom_code",
      "en",
      "es",
      "fr",
      "de",
      "it",
      "pt",
      "ru",
      "ar",
      "hi",
      "ko",
      "zh",
      "base_model:arcee-ai/Trinity-Large-Base",
      "base_model:finetune:arcee-ai/Trinity-Large-Base",
      "license:apache-2.0",
      "eval-results",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "stabilityai/stable-diffusion-xl-base-1.0",
    "task": "text-to-image",
    "library": "diffusers",
    "downloads": 2036040,
    "likes": 7412,
    "tags": [
      "diffusers",
      "onnx",
      "safetensors",
      "text-to-image",
      "stable-diffusion",
      "arxiv:2307.01952",
      "arxiv:2211.01324",
      "arxiv:2108.01073",
      "arxiv:2112.10752",
      "license:openrail++",
      "endpoints_compatible",
      "diffusers:StableDiffusionXLPipeline",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "BAAI/bge-m3",
    "task": "sentence-similarity",
    "library": "sentence-transformers",
    "downloads": 12860769,
    "likes": 2727,
    "tags": [
      "sentence-transformers",
      "pytorch",
      "onnx",
      "xlm-roberta",
      "feature-extraction",
      "sentence-similarity",
      "arxiv:2402.03216",
      "arxiv:2004.04906",
      "arxiv:2106.14807",
      "arxiv:2107.05720",
      "arxiv:2004.12832",
      "license:mit",
      "text-embeddings-inference",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "LGAI-EXAONE/EXAONE-4.0-1.2B",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 40964,
    "likes": 157,
    "tags": [
      "transformers",
      "safetensors",
      "exaone4",
      "text-generation",
      "lg-ai",
      "exaone",
      "exaone-4.0",
      "conversational",
      "en",
      "ko",
      "es",
      "arxiv:2507.11407",
      "license:other",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "openbmb/MiniCPM-o-4_5-gguf",
    "task": "any-to-any",
    "library": "transformers",
    "downloads": 12425,
    "likes": 26,
    "tags": [
      "transformers",
      "gguf",
      "minicpm-o",
      "minicpm-v",
      "multimodal",
      "full-duplex",
      "any-to-any",
      "arxiv:2408.01800",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "unsloth/Qwen3-Coder-Next-FP8-Dynamic",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 11637,
    "likes": 26,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3_next",
      "text-generation",
      "unsloth",
      "qwen",
      "qwen3",
      "conversational",
      "base_model:Qwen/Qwen3-Coder-Next",
      "base_model:quantized:Qwen/Qwen3-Coder-Next",
      "license:apache-2.0",
      "endpoints_compatible",
      "compressed-tensors",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-VL-8B-Instruct",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 2630868,
    "likes": 734,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3_vl",
      "image-to-text",
      "image-text-to-text",
      "conversational",
      "arxiv:2505.09388",
      "arxiv:2502.13923",
      "arxiv:2409.12191",
      "arxiv:2308.12966",
      "license:apache-2.0",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "tencent/HY3D-Bench",
    "task": "image-to-3d",
    "library": "hunyuan3d-2",
    "downloads": 20,
    "likes": 25,
    "tags": [
      "hunyuan3d-2",
      "image-to-3d",
      "text-to-3d",
      "dataset:tencent/HY3D-Bench",
      "arxiv:2602.03907",
      "arxiv:2509.06784",
      "arxiv:2509.08643",
      "arxiv:2509.21245",
      "arxiv:2506.15442",
      "arxiv:2501.12202",
      "arxiv:2411.02293",
      "base_model:tencent/Hunyuan3D-2.1",
      "base_model:finetune:tencent/Hunyuan3D-2.1",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "nvidia/C-RADIOv4-H",
    "task": "feature-extraction",
    "library": "transformers",
    "downloads": 6038,
    "likes": 41,
    "tags": [
      "transformers",
      "safetensors",
      "feature-extraction",
      "custom_code",
      "arxiv:2312.06709",
      "arxiv:2410.01680",
      "arxiv:2412.07679",
      "arxiv:2502.16025",
      "arxiv:2601.17237",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "fashn-ai/fashn-vton-1.5",
    "task": "image-to-image",
    "library": "pytorch",
    "downloads": 0,
    "likes": 73,
    "tags": [
      "pytorch",
      "safetensors",
      "virtual-try-on",
      "diffusion",
      "mmdit",
      "fashion",
      "image-generation",
      "pixel-space",
      "image-to-image",
      "en",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "XeyonAI/Mistral-Helcyon-Mercury-12b-v3.0-GGUF",
    "task": null,
    "library": null,
    "downloads": 1964,
    "likes": 24,
    "tags": [
      "gguf",
      "companion",
      "assistant",
      "conversational",
      "roleplay",
      "adventure",
      "writing",
      "long-context",
      "en",
      "base_model:mistralai/Mistral-Nemo-Instruct-2407",
      "base_model:quantized:mistralai/Mistral-Nemo-Instruct-2407",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "alibaba-pai/Z-Image-Fun-Lora-Distill",
    "task": null,
    "library": "videox_fun",
    "downloads": 1212,
    "likes": 24,
    "tags": [
      "videox_fun",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "google/medgemma-1.5-4b-it",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 155827,
    "likes": 420,
    "tags": [
      "transformers",
      "safetensors",
      "gemma3",
      "image-to-text",
      "medical",
      "radiology",
      "clinical-reasoning",
      "dermatology",
      "pathology",
      "ophthalmology",
      "chest-x-ray",
      "image-text-to-text",
      "conversational",
      "arxiv:2303.15343",
      "arxiv:2507.05201",
      "arxiv:2406.19578",
      "arxiv:2405.03162",
      "arxiv:2106.14463",
      "arxiv:2009.13081",
      "arxiv:2203.14371",
      "arxiv:1909.06146",
      "arxiv:2102.09542",
      "arxiv:2411.15640",
      "arxiv:2404.05590",
      "arxiv:2501.18362",
      "arxiv:1605.01397",
      "arxiv:1901.07031",
      "arxiv:2403.17834",
      "arxiv:2402.16040",
      "license:other",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-TTS-12Hz-1.7B-Base",
    "task": null,
    "library": null,
    "downloads": 461377,
    "likes": 294,
    "tags": [
      "safetensors",
      "qwen3_tts",
      "arxiv:2601.15621",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "ChenkinRF/ChenkinNoob-XL-v0.2-Rectified-Flow",
    "task": null,
    "library": "diffusers",
    "downloads": 2352,
    "likes": 23,
    "tags": [
      "diffusers",
      "base_model:ChenkinNoob/ChenkinNoob-XL-V0.2",
      "base_model:finetune:ChenkinNoob/ChenkinNoob-XL-V0.2",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-0.6B",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 9591163,
    "likes": 1052,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "conversational",
      "arxiv:2505.09388",
      "base_model:Qwen/Qwen3-0.6B-Base",
      "base_model:finetune:Qwen/Qwen3-0.6B-Base",
      "license:apache-2.0",
      "text-generation-inference",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Nurburgring/BEYOND_REALITY_Z_IMAGE",
    "task": "text-to-image",
    "library": "diffusers",
    "downloads": 19156,
    "likes": 102,
    "tags": [
      "diffusers",
      "art",
      "text-to-image",
      "zh",
      "base_model:Tongyi-MAI/Z-Image-Turbo",
      "base_model:finetune:Tongyi-MAI/Z-Image-Turbo",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "black-forest-labs/FLUX.2-klein-9B",
    "task": "image-to-image",
    "library": "diffusers",
    "downloads": 75907,
    "likes": 384,
    "tags": [
      "diffusers",
      "safetensors",
      "image-generation",
      "image-editing",
      "flux",
      "diffusion-single-file",
      "image-to-image",
      "en",
      "license:other",
      "diffusers:Flux2KleinPipeline",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "google/alphagenome-all-folds",
    "task": null,
    "library": null,
    "downloads": 0,
    "likes": 66,
    "tags": [
      "biology",
      "en",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "ACE-Step/acestep-v15-sft",
    "task": "text-to-audio",
    "library": "transformers",
    "downloads": 2454,
    "likes": 22,
    "tags": [
      "transformers",
      "safetensors",
      "acestep",
      "feature-extraction",
      "audio",
      "music",
      "text2music",
      "text-to-audio",
      "custom_code",
      "arxiv:2602.00744",
      "license:mit",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "ACE-Step/acestep-captioner",
    "task": "text-to-audio",
    "library": "transformers",
    "downloads": 299,
    "likes": 22,
    "tags": [
      "transformers",
      "safetensors",
      "qwen2_5_omni",
      "text-to-audio",
      "music",
      "audio",
      "arxiv:2602.00744",
      "license:mit",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "alibaba-pai/Z-Image-Fun-Controlnet-Union-2.1",
    "task": null,
    "library": "videox_fun",
    "downloads": 1850,
    "likes": 22,
    "tags": [
      "videox_fun",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "unsloth/Qwen3-Coder-30B-A3B-Instruct-GGUF",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 125048,
    "likes": 455,
    "tags": [
      "transformers",
      "gguf",
      "unsloth",
      "qwen3",
      "qwen",
      "text-generation",
      "arxiv:2505.09388",
      "base_model:Qwen/Qwen3-Coder-30B-A3B-Instruct",
      "base_model:quantized:Qwen/Qwen3-Coder-30B-A3B-Instruct",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us",
      "imatrix",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "Alissonerdx/BFS-Best-Face-Swap",
    "task": "image-to-image",
    "library": "diffusers",
    "downloads": 32068,
    "likes": 214,
    "tags": [
      "diffusers",
      "lora",
      "qwen-image-edit",
      "face-swap",
      "head-swap",
      "image-editing",
      "ai-generated",
      "comfyui",
      "bfs",
      "flux 2",
      "flux",
      "klein",
      "image-to-image",
      "en",
      "base_model:Qwen/Qwen-Image-Edit-2511",
      "base_model:adapter:Qwen/Qwen-Image-Edit-2511",
      "license:mit",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen-Image-2512",
    "task": "text-to-image",
    "library": "diffusers",
    "downloads": 155858,
    "likes": 650,
    "tags": [
      "diffusers",
      "safetensors",
      "text-to-image",
      "en",
      "zh",
      "arxiv:2508.02324",
      "license:apache-2.0",
      "diffusers:QwenImagePipeline",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "PaddlePaddle/PP-DocLayoutV3",
    "task": "image-segmentation",
    "library": "PaddleOCR",
    "downloads": 5083,
    "likes": 29,
    "tags": [
      "PaddleOCR",
      "PaddlePaddle",
      "image-segmentation",
      "ocr",
      "layout",
      "layout_detection",
      "en",
      "zh",
      "multilingual",
      "arxiv:2601.21957",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "unsloth/GLM-4.7-Flash-REAP-23B-A3B-GGUF",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 47860,
    "likes": 122,
    "tags": [
      "transformers",
      "gguf",
      "glm",
      "unsloth",
      "MOE",
      "pruning",
      "compression",
      "text-generation",
      "en",
      "arxiv:2510.13999",
      "base_model:cerebras/GLM-4.7-Flash-REAP-23B-A3B",
      "base_model:quantized:cerebras/GLM-4.7-Flash-REAP-23B-A3B",
      "license:mit",
      "endpoints_compatible",
      "region:us",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "MachineDelusions/LTX-2_Image2Video_Adapter_LoRa",
    "task": null,
    "library": null,
    "downloads": 0,
    "likes": 116,
    "tags": [
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Hcompany/Holo2-235B-A22B",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 162,
    "likes": 21,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3_vl_moe",
      "image-to-text",
      "multimodal",
      "action",
      "pytorch",
      "computer use",
      "gui agents",
      "image-text-to-text",
      "conversational",
      "en",
      "base_model:Qwen/Qwen3-VL-235B-A22B-Thinking",
      "base_model:finetune:Qwen/Qwen3-VL-235B-A22B-Thinking",
      "license:cc-by-nc-4.0",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "trillionlabs/gWorld-32B",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 258,
    "likes": 23,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3_vl",
      "image-text-to-text",
      "conversational",
      "en",
      "ko",
      "arxiv:2602.01576",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "numind/NuMarkdown-8B-Thinking",
    "task": "image-to-text",
    "library": "transformers",
    "downloads": 1187395,
    "likes": 436,
    "tags": [
      "transformers",
      "safetensors",
      "qwen2_5_vl",
      "image-to-text",
      "OCR",
      "vision-language",
      "VLM",
      "Reasoning",
      "document-to-markdown",
      "qwen2.5",
      "markdown",
      "extraction",
      "RAG",
      "license:mit",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-Coder-30B-A3B-Instruct",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 526329,
    "likes": 935,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3_moe",
      "text-generation",
      "conversational",
      "arxiv:2505.09388",
      "license:apache-2.0",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "nvidia/parakeet-tdt-0.6b-v3",
    "task": "automatic-speech-recognition",
    "library": "nemo",
    "downloads": 79640,
    "likes": 612,
    "tags": [
      "nemo",
      "automatic-speech-recognition",
      "speech",
      "audio",
      "Transducer",
      "TDT",
      "FastConformer",
      "Conformer",
      "pytorch",
      "NeMo",
      "hf-asr-leaderboard",
      "en",
      "es",
      "fr",
      "de",
      "bg",
      "hr",
      "cs",
      "da",
      "nl",
      "et",
      "fi",
      "el",
      "hu",
      "it",
      "lv",
      "lt",
      "mt",
      "pl",
      "pt",
      "ro",
      "sk",
      "sl",
      "sv",
      "ru",
      "uk",
      "dataset:nvidia/Granary",
      "dataset:nemo/asr-set-3.0",
      "arxiv:2509.14128",
      "arxiv:2505.13404",
      "arxiv:2305.05084",
      "arxiv:2304.06795",
      "arxiv:2410.01036",
      "arxiv:2406.00899",
      "arxiv:2205.12446",
      "arxiv:2012.03411",
      "arxiv:2007.10310",
      "arxiv:1510.08484",
      "license:cc-by-4.0",
      "model-index",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "voyageai/voyage-4-nano",
    "task": "feature-extraction",
    "library": "sentence-transformers",
    "downloads": 32149,
    "likes": 76,
    "tags": [
      "sentence-transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "transformers",
      "feature-extraction",
      "custom_code",
      "multilingual",
      "license:apache-2.0",
      "text-embeddings-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "LiquidAI/LFM2.5-1.2B-Instruct",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 79935,
    "likes": 474,
    "tags": [
      "transformers",
      "safetensors",
      "lfm2",
      "text-generation",
      "liquid",
      "lfm2.5",
      "edge",
      "conversational",
      "en",
      "ar",
      "zh",
      "fr",
      "de",
      "ja",
      "ko",
      "es",
      "arxiv:2511.23404",
      "base_model:LiquidAI/LFM2.5-1.2B-Base",
      "base_model:finetune:LiquidAI/LFM2.5-1.2B-Base",
      "license:other",
      "eval-results",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-TTS-12Hz-1.7B-VoiceDesign",
    "task": "text-to-speech",
    "library": "qwen-tts",
    "downloads": 184007,
    "likes": 238,
    "tags": [
      "qwen-tts",
      "safetensors",
      "qwen3_tts",
      "audio",
      "tts",
      "qwen",
      "multilingual",
      "text-to-speech",
      "arxiv:2601.15621",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "google/gemma-3-4b-it",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 1048167,
    "likes": 1161,
    "tags": [
      "transformers",
      "safetensors",
      "gemma3",
      "image-to-text",
      "image-text-to-text",
      "conversational",
      "arxiv:1905.07830",
      "arxiv:1905.10044",
      "arxiv:1911.11641",
      "arxiv:1904.09728",
      "arxiv:1705.03551",
      "arxiv:1911.01547",
      "arxiv:1907.10641",
      "arxiv:1903.00161",
      "arxiv:2009.03300",
      "arxiv:2304.06364",
      "arxiv:2103.03874",
      "arxiv:2110.14168",
      "arxiv:2311.12022",
      "arxiv:2108.07732",
      "arxiv:2107.03374",
      "arxiv:2210.03057",
      "arxiv:2106.03193",
      "arxiv:1910.11856",
      "arxiv:2502.12404",
      "arxiv:2502.21228",
      "arxiv:2404.16816",
      "arxiv:2104.12756",
      "arxiv:2311.16502",
      "arxiv:2203.10244",
      "arxiv:2404.12390",
      "arxiv:1810.12440",
      "arxiv:1908.02660",
      "arxiv:2312.11805",
      "base_model:google/gemma-3-4b-pt",
      "base_model:finetune:google/gemma-3-4b-pt",
      "license:gemma",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "unsloth/gpt-oss-20b-GGUF",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 135918,
    "likes": 577,
    "tags": [
      "transformers",
      "gguf",
      "gpt_oss",
      "text-generation",
      "openai",
      "unsloth",
      "base_model:openai/gpt-oss-20b",
      "base_model:quantized:openai/gpt-oss-20b",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "google/functiongemma-270m-it",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 85861,
    "likes": 885,
    "tags": [
      "transformers",
      "safetensors",
      "gemma3_text",
      "text-generation",
      "gemma3",
      "gemma",
      "google",
      "functiongemma",
      "conversational",
      "license:gemma",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "google/translategemma-4b-it",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 108667,
    "likes": 602,
    "tags": [
      "transformers",
      "safetensors",
      "gemma3",
      "image-to-text",
      "image-text-to-text",
      "conversational",
      "arxiv:2601.09012",
      "arxiv:2503.19786",
      "license:gemma",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "fal/flux-2-klein-4b-spritesheet-lora",
    "task": "image-to-image",
    "library": null,
    "downloads": 0,
    "likes": 45,
    "tags": [
      "flux",
      "flux-2-klein",
      "flux-lora",
      "lora",
      "sprite-sheet",
      "game-asset",
      "2x2-grid",
      "multi-view",
      "isometric",
      "top-down",
      "side-view",
      "image-to-image",
      "fal-ai",
      "template:diffusion-lora",
      "en",
      "base_model:black-forest-labs/FLUX.2-klein-4B",
      "base_model:adapter:black-forest-labs/FLUX.2-klein-4B",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "openai/whisper-large-v3",
    "task": "automatic-speech-recognition",
    "library": "transformers",
    "downloads": 6222219,
    "likes": 5375,
    "tags": [
      "transformers",
      "pytorch",
      "jax",
      "safetensors",
      "whisper",
      "automatic-speech-recognition",
      "audio",
      "hf-asr-leaderboard",
      "en",
      "zh",
      "de",
      "es",
      "ru",
      "ko",
      "fr",
      "ja",
      "pt",
      "tr",
      "pl",
      "ca",
      "nl",
      "ar",
      "sv",
      "it",
      "id",
      "hi",
      "fi",
      "vi",
      "he",
      "uk",
      "el",
      "ms",
      "cs",
      "ro",
      "da",
      "hu",
      "ta",
      "no",
      "th",
      "ur",
      "hr",
      "bg",
      "lt",
      "la",
      "mi",
      "ml",
      "cy",
      "sk",
      "te",
      "fa",
      "lv",
      "bn",
      "sr",
      "az",
      "sl",
      "kn",
      "et",
      "mk",
      "br",
      "eu",
      "is",
      "hy",
      "ne",
      "mn",
      "bs",
      "kk",
      "sq",
      "sw",
      "gl",
      "mr",
      "pa",
      "si",
      "km",
      "sn",
      "yo",
      "so",
      "af",
      "oc",
      "ka",
      "be",
      "tg",
      "sd",
      "gu",
      "am",
      "yi",
      "lo",
      "uz",
      "fo",
      "ht",
      "ps",
      "tk",
      "nn",
      "mt",
      "sa",
      "lb",
      "my",
      "bo",
      "tl",
      "mg",
      "as",
      "tt",
      "haw",
      "ln",
      "ha",
      "ba",
      "jw",
      "su",
      "arxiv:2212.04356",
      "license:apache-2.0",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "black-forest-labs/FLUX.1-schnell",
    "task": "text-to-image",
    "library": "diffusers",
    "downloads": 657024,
    "likes": 4600,
    "tags": [
      "diffusers",
      "safetensors",
      "text-to-image",
      "image-generation",
      "flux",
      "en",
      "license:apache-2.0",
      "endpoints_compatible",
      "diffusers:FluxPipeline",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "ACE-Step/ACE-Step-v1-3.5B",
    "task": "text-to-audio",
    "library": "diffusers",
    "downloads": 0,
    "likes": 709,
    "tags": [
      "diffusers",
      "safetensors",
      "music",
      "text2music",
      "acestep",
      "text-to-audio",
      "en",
      "zh",
      "de",
      "fr",
      "es",
      "it",
      "pt",
      "pl",
      "tr",
      "ru",
      "cs",
      "nl",
      "ar",
      "ja",
      "hu",
      "ko",
      "hi",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-4B-Instruct-2507",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 3154060,
    "likes": 706,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "conversational",
      "arxiv:2505.09388",
      "license:apache-2.0",
      "eval-results",
      "text-generation-inference",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "deepseek-ai/DeepSeek-V3.2",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 238471,
    "likes": 1220,
    "tags": [
      "transformers",
      "safetensors",
      "deepseek_v32",
      "text-generation",
      "conversational",
      "base_model:deepseek-ai/DeepSeek-V3.2-Exp-Base",
      "base_model:finetune:deepseek-ai/DeepSeek-V3.2-Exp-Base",
      "license:mit",
      "endpoints_compatible",
      "fp8",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Alibaba-Apsara/DASD-4B-Thinking",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 3731,
    "likes": 228,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "conversational",
      "dataset:Alibaba-Apsara/Superior-Reasoning-SFT-gpt-oss-120b",
      "dataset:Alibaba-Apsara/Superior-Reasoning-SFT-gpt-oss-120b-Logprob",
      "arxiv:2601.09088",
      "arxiv:2512.20908",
      "license:apache-2.0",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "lodestones/Chroma2-Kaleidoscope",
    "task": "text-to-image",
    "library": null,
    "downloads": 0,
    "likes": 77,
    "tags": [
      "safetensors",
      "text-to-image",
      "base_model:black-forest-labs/FLUX.2-klein-base-4B",
      "base_model:finetune:black-forest-labs/FLUX.2-klein-base-4B",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "OpenMOSS-Team/MOVA-360p",
    "task": "image-to-video",
    "library": "diffusers",
    "downloads": 391,
    "likes": 50,
    "tags": [
      "diffusers",
      "safetensors",
      "image-to-video",
      "image-text-to-video",
      "image-to-audio-video",
      "image-text-to-audio-video",
      "MOVA",
      "OpenMOSS",
      "SII",
      "MOSI",
      "sglang-diffusion",
      "license:apache-2.0",
      "diffusers:MOVA",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "pyannote/segmentation-3.0",
    "task": "voice-activity-detection",
    "library": "pyannote-audio",
    "downloads": 13504800,
    "likes": 787,
    "tags": [
      "pyannote-audio",
      "pytorch",
      "pyannote",
      "pyannote-audio-model",
      "audio",
      "voice",
      "speech",
      "speaker",
      "speaker-diarization",
      "speaker-change-detection",
      "speaker-segmentation",
      "voice-activity-detection",
      "overlapped-speech-detection",
      "resegmentation",
      "license:mit",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Kijai/WanVideo_comfy",
    "task": null,
    "library": "diffusion-single-file",
    "downloads": 7011018,
    "likes": 2079,
    "tags": [
      "diffusion-single-file",
      "comfyui",
      "base_model:Wan-AI/Wan2.1-VACE-1.3B",
      "base_model:finetune:Wan-AI/Wan2.1-VACE-1.3B",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "google/gemma-3-27b-it",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 1647480,
    "likes": 1859,
    "tags": [
      "transformers",
      "safetensors",
      "gemma3",
      "image-to-text",
      "image-text-to-text",
      "conversational",
      "arxiv:1905.07830",
      "arxiv:1905.10044",
      "arxiv:1911.11641",
      "arxiv:1904.09728",
      "arxiv:1705.03551",
      "arxiv:1911.01547",
      "arxiv:1907.10641",
      "arxiv:1903.00161",
      "arxiv:2009.03300",
      "arxiv:2304.06364",
      "arxiv:2103.03874",
      "arxiv:2110.14168",
      "arxiv:2311.12022",
      "arxiv:2108.07732",
      "arxiv:2107.03374",
      "arxiv:2210.03057",
      "arxiv:2106.03193",
      "arxiv:1910.11856",
      "arxiv:2502.12404",
      "arxiv:2502.21228",
      "arxiv:2404.16816",
      "arxiv:2104.12756",
      "arxiv:2311.16502",
      "arxiv:2203.10244",
      "arxiv:2404.12390",
      "arxiv:1810.12440",
      "arxiv:1908.02660",
      "arxiv:2312.11805",
      "base_model:google/gemma-3-27b-pt",
      "base_model:finetune:google/gemma-3-27b-pt",
      "license:gemma",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Phr00t/WAN2.2-14B-Rapid-AllInOne",
    "task": "image-to-video",
    "library": "wan2.2",
    "downloads": 0,
    "likes": 1404,
    "tags": [
      "wan2.2",
      "wan",
      "accelerator",
      "image-to-video",
      "base_model:Wan-AI/Wan2.2-I2V-A14B",
      "base_model:finetune:Wan-AI/Wan2.2-I2V-A14B",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Wan-AI/Wan2.2-Animate-14B",
    "task": "video-to-video",
    "library": "diffusers",
    "downloads": 58956,
    "likes": 1028,
    "tags": [
      "diffusers",
      "onnx",
      "safetensors",
      "video-to-video",
      "arxiv:2503.20314",
      "base_model:Wan-AI/Wan2.2-I2V-A14B",
      "base_model:quantized:Wan-AI/Wan2.2-I2V-A14B",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-VL-Embedding-2B",
    "task": "feature-extraction",
    "library": "transformers",
    "downloads": 349667,
    "likes": 306,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3_vl",
      "image-to-text",
      "multimodal embedding",
      "qwen",
      "embedding",
      "feature-extraction",
      "arxiv:2601.04720",
      "base_model:Qwen/Qwen3-VL-2B-Instruct",
      "base_model:finetune:Qwen/Qwen3-VL-2B-Instruct",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "zai-org/GLM-Image",
    "task": "text-to-image",
    "library": "diffusers",
    "downloads": 16725,
    "likes": 1024,
    "tags": [
      "diffusers",
      "safetensors",
      "text-to-image",
      "zh",
      "en",
      "license:mit",
      "diffusers:GlmImagePipeline",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "LiquidAI/LFM2.5-1.2B-Thinking",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 27657,
    "likes": 251,
    "tags": [
      "transformers",
      "safetensors",
      "lfm2",
      "text-generation",
      "liquid",
      "lfm2.5",
      "edge",
      "conversational",
      "en",
      "ar",
      "zh",
      "fr",
      "de",
      "ja",
      "ko",
      "es",
      "arxiv:2511.23404",
      "base_model:LiquidAI/LFM2.5-1.2B-Base",
      "base_model:finetune:LiquidAI/LFM2.5-1.2B-Base",
      "license:other",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "ruv/ruvltra-claude-code",
    "task": "text-generation",
    "library": "gguf",
    "downloads": 2205,
    "likes": 30,
    "tags": [
      "gguf",
      "ruvltra",
      "claude-code",
      "code-generation",
      "sona",
      "adaptive-learning",
      "self-learning",
      "swarm-optimized",
      "quantized",
      "llama-cpp",
      "text-generation-inference",
      "first-of-its-kind",
      "text-generation",
      "en",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us",
      "imatrix",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "wikeeyang/Flux2-Klein-9B-True-V1",
    "task": "text-to-image",
    "library": "diffusers",
    "downloads": 5337,
    "likes": 56,
    "tags": [
      "diffusers",
      "gguf",
      "text-to-image",
      "en",
      "zh",
      "base_model:black-forest-labs/FLUX.2-klein-9B",
      "base_model:finetune:black-forest-labs/FLUX.2-klein-9B",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "nvidia/Kimi-K2.5-NVFP4",
    "task": "text-generation",
    "library": "Model Optimizer",
    "downloads": 13231,
    "likes": 17,
    "tags": [
      "Model Optimizer",
      "safetensors",
      "kimi_k25",
      "nvidia",
      "ModelOpt",
      "Kimi-K2",
      "quantized",
      "FP4",
      "text-generation",
      "conversational",
      "custom_code",
      "base_model:moonshotai/Kimi-K2.5",
      "base_model:quantized:moonshotai/Kimi-K2.5",
      "license:other",
      "modelopt",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "BennyDaBall/Qwen3-4b-Z-Image-Engineer-V4",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 1925,
    "likes": 17,
    "tags": [
      "transformers",
      "safetensors",
      "gguf",
      "text-generation",
      "prompt-engineering",
      "image-generation",
      "qwen3",
      "en",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "ResembleAI/chatterbox",
    "task": "text-to-speech",
    "library": "chatterbox",
    "downloads": 587637,
    "likes": 1468,
    "tags": [
      "chatterbox",
      "text-to-speech",
      "speech",
      "speech-generation",
      "voice-cloning",
      "multilingual-tts",
      "ar",
      "da",
      "de",
      "el",
      "en",
      "es",
      "fi",
      "fr",
      "he",
      "hi",
      "it",
      "ja",
      "ko",
      "ms",
      "nl",
      "no",
      "pl",
      "pt",
      "ru",
      "sv",
      "sw",
      "tr",
      "zh",
      "license:mit",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-8B",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 4687112,
    "likes": 905,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "conversational",
      "arxiv:2309.00071",
      "arxiv:2505.09388",
      "base_model:Qwen/Qwen3-8B-Base",
      "base_model:finetune:Qwen/Qwen3-8B-Base",
      "license:apache-2.0",
      "text-generation-inference",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-Embedding-8B",
    "task": "feature-extraction",
    "library": "sentence-transformers",
    "downloads": 1828989,
    "likes": 570,
    "tags": [
      "sentence-transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "transformers",
      "sentence-similarity",
      "feature-extraction",
      "text-embeddings-inference",
      "arxiv:2506.05176",
      "base_model:Qwen/Qwen3-8B-Base",
      "base_model:finetune:Qwen/Qwen3-8B-Base",
      "license:apache-2.0",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "IndexTeam/IndexTTS-2",
    "task": "text-to-speech",
    "library": null,
    "downloads": 18332,
    "likes": 636,
    "tags": [
      "safetensors",
      "text-to-speech",
      "en",
      "zh",
      "arxiv:2506.21619",
      "arxiv:2502.05512",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "deepseek-ai/DeepSeek-OCR",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 3041110,
    "likes": 3137,
    "tags": [
      "transformers",
      "safetensors",
      "deepseek_vl_v2",
      "feature-extraction",
      "deepseek",
      "vision-language",
      "ocr",
      "custom_code",
      "image-text-to-text",
      "multilingual",
      "arxiv:2510.18234",
      "license:mit",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "lkzd7/WAN2.2_LoraSet_NSFW",
    "task": null,
    "library": null,
    "downloads": 0,
    "likes": 63,
    "tags": [
      "license:unknown",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "kyutai/pocket-tts",
    "task": null,
    "library": "pocket-tts",
    "downloads": 63009,
    "likes": 530,
    "tags": [
      "pocket-tts",
      "en",
      "arxiv:2509.06926",
      "license:cc-by-4.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "SicariusSicariiStuff/Assistant_Pepe_8B",
    "task": null,
    "library": null,
    "downloads": 175,
    "likes": 40,
    "tags": [
      "safetensors",
      "llama",
      "en",
      "dataset:SicariusSicariiStuff/UBW_Tapestries",
      "base_model:SicariusSicariiStuff/Llama-3.1-Nemotron-8B-UltraLong-1M-Instruct_Abliterated",
      "base_model:finetune:SicariusSicariiStuff/Llama-3.1-Nemotron-8B-UltraLong-1M-Instruct_Abliterated",
      "license:llama3.1",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "unsloth/FLUX.2-klein-9B-GGUF",
    "task": "image-to-image",
    "library": "ggml",
    "downloads": 62408,
    "likes": 89,
    "tags": [
      "ggml",
      "gguf",
      "image-generation",
      "unsloth",
      "image-editing",
      "flux",
      "diffusion-single-file",
      "image-to-image",
      "en",
      "base_model:black-forest-labs/FLUX.2-klein-9B",
      "base_model:quantized:black-forest-labs/FLUX.2-klein-9B",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Comfy-Org/z_image",
    "task": null,
    "library": "diffusion-single-file",
    "downloads": 169290,
    "likes": 187,
    "tags": [
      "diffusion-single-file",
      "comfyui",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "SnJake/Ref2Font",
    "task": "text-to-image",
    "library": null,
    "downloads": 23,
    "likes": 16,
    "tags": [
      "lora",
      "flux",
      "flux.2",
      "flux.2-klein-9b",
      "image-to-image",
      "text-to-image",
      "font",
      "typography",
      "atlas",
      "comfyui",
      "safetensors",
      "base_model:black-forest-labs/FLUX.2-klein-9B",
      "base_model:adapter:black-forest-labs/FLUX.2-klein-9B",
      "license:mit",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "noctrex/GLM-4.7-Flash-Claude-Opus-4.5-High-Reasoning-Distill",
    "task": "text-generation",
    "library": null,
    "downloads": 1643,
    "likes": 16,
    "tags": [
      "gguf",
      "text-generation",
      "base_model:TeichAI/GLM-4.7-Flash-Claude-Opus-4.5-High-Reasoning-Distill",
      "base_model:quantized:TeichAI/GLM-4.7-Flash-Claude-Opus-4.5-High-Reasoning-Distill",
      "endpoints_compatible",
      "region:us",
      "imatrix",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "UDCAI/Z-Image-Fun-Distill-ComfyUI",
    "task": "text-to-image",
    "library": "diffusers",
    "downloads": 1102,
    "likes": 16,
    "tags": [
      "diffusers",
      "text-to-image",
      "lora",
      "template:diffusion-lora",
      "base_model:Tongyi-MAI/Z-Image",
      "base_model:adapter:Tongyi-MAI/Z-Image",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "briaai/RMBG-2.0",
    "task": "image-segmentation",
    "library": "transformers",
    "downloads": 420977,
    "likes": 1070,
    "tags": [
      "transformers",
      "pytorch",
      "onnx",
      "safetensors",
      "image-segmentation",
      "remove background",
      "background",
      "background-removal",
      "Pytorch",
      "vision",
      "legal liability",
      "transformers.js",
      "custom_code",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "google/embeddinggemma-300m",
    "task": "sentence-similarity",
    "library": "sentence-transformers",
    "downloads": 1156395,
    "likes": 1458,
    "tags": [
      "sentence-transformers",
      "safetensors",
      "gemma3_text",
      "sentence-similarity",
      "feature-extraction",
      "text-embeddings-inference",
      "arxiv:2509.20354",
      "license:gemma",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-Omni-30B-A3B-Thinking",
    "task": "any-to-any",
    "library": "transformers",
    "downloads": 17669,
    "likes": 268,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3_omni_moe",
      "text-to-audio",
      "multimodal",
      "any-to-any",
      "en",
      "license:other",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "nvidia/nemotron-speech-streaming-en-0.6b",
    "task": "automatic-speech-recognition",
    "library": "nemo",
    "downloads": 11191,
    "likes": 469,
    "tags": [
      "nemo",
      "speech-recognition",
      "cache-aware ASR",
      "automatic-speech-recognition",
      "streaming-asr",
      "speech",
      "audio",
      "FastConformer",
      "RNNT",
      "Parakeet",
      "ASR",
      "pytorch",
      "NeMo",
      "dataset:nvidia/Granary",
      "dataset:YTC",
      "dataset:Yodas2",
      "dataset:LibriLight",
      "dataset:librispeech_asr",
      "dataset:fisher_corpus",
      "dataset:Switchboard-1",
      "dataset:WSJ-0",
      "dataset:WSJ-1",
      "dataset:National-Singapore-Corpus-Part-1",
      "dataset:National-Singapore-Corpus-Part-6",
      "dataset:vctk",
      "dataset:voxpopuli",
      "dataset:europarl",
      "dataset:multilingual_librispeech",
      "dataset:fleurs",
      "dataset:mozilla-foundation/common_voice_8_0",
      "dataset:MLCommons/peoples_speech",
      "dataset:google/speech_commands",
      "arxiv:2312.17279",
      "arxiv:2305.05084",
      "license:other",
      "model-index",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "nvidia/music-flamingo-2601-hf",
    "task": "audio-text-to-text",
    "library": "transformers",
    "downloads": 8491,
    "likes": 57,
    "tags": [
      "transformers",
      "safetensors",
      "audioflamingo3",
      "text2text-generation",
      "music/songs",
      "music understanding",
      "music reasoning",
      "audio-text-to-text",
      "en",
      "dataset:nvidia/MF-Skills",
      "arxiv:2511.10289",
      "arxiv:2505.13032",
      "license:other",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-VL-Embedding-8B",
    "task": "feature-extraction",
    "library": "transformers",
    "downloads": 281820,
    "likes": 329,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3_vl",
      "image-to-text",
      "multimodal embedding",
      "qwen",
      "embedding",
      "feature-extraction",
      "arxiv:2601.04720",
      "base_model:Qwen/Qwen3-VL-8B-Instruct",
      "base_model:finetune:Qwen/Qwen3-VL-8B-Instruct",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Kijai/LTXV2_comfy",
    "task": null,
    "library": null,
    "downloads": 134472,
    "likes": 393,
    "tags": [
      "gguf",
      "comfyui",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "koute/GLM-4.7-Flash-Derestricted",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 172,
    "likes": 23,
    "tags": [
      "transformers",
      "safetensors",
      "glm4_moe_lite",
      "text-generation",
      "abliterated",
      "derestricted",
      "glm-4.7-flash",
      "unlimited",
      "uncensored",
      "conversational",
      "en",
      "zh",
      "base_model:zai-org/GLM-4.7-Flash",
      "base_model:finetune:zai-org/GLM-4.7-Flash",
      "license:mit",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "tencent/Youtu-HiChunk",
    "task": "feature-extraction",
    "library": "transformers",
    "downloads": 10,
    "likes": 15,
    "tags": [
      "transformers",
      "safetensors",
      "utu_v1",
      "feature-extraction",
      "custom_code",
      "zh",
      "arxiv:2509.11552",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "concavity-ai/superlinear-exp-v0.1",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 28,
    "likes": 15,
    "tags": [
      "transformers",
      "safetensors",
      "long-context",
      "superlinear-attention",
      "subquadratic",
      "causal-lm",
      "text-generation",
      "conversational",
      "arxiv:2601.18401",
      "base_model:nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16",
      "base_model:finetune:nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16",
      "license:other",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "facebook/mms-1b-all",
    "task": "automatic-speech-recognition",
    "library": "transformers",
    "downloads": 60377,
    "likes": 187,
    "tags": [
      "transformers",
      "pytorch",
      "safetensors",
      "wav2vec2",
      "automatic-speech-recognition",
      "mms",
      "ab",
      "af",
      "ak",
      "am",
      "ar",
      "as",
      "av",
      "ay",
      "az",
      "ba",
      "bm",
      "be",
      "bn",
      "bi",
      "bo",
      "sh",
      "br",
      "bg",
      "ca",
      "cs",
      "ce",
      "cv",
      "ku",
      "cy",
      "da",
      "de",
      "dv",
      "dz",
      "el",
      "en",
      "eo",
      "et",
      "eu",
      "ee",
      "fo",
      "fa",
      "fj",
      "fi",
      "fr",
      "fy",
      "ff",
      "ga",
      "gl",
      "gn",
      "gu",
      "zh",
      "ht",
      "ha",
      "he",
      "hi",
      "hu",
      "hy",
      "ig",
      "ia",
      "ms",
      "is",
      "it",
      "jv",
      "ja",
      "kn",
      "ka",
      "kk",
      "kr",
      "km",
      "ki",
      "rw",
      "ky",
      "ko",
      "kv",
      "lo",
      "la",
      "lv",
      "ln",
      "lt",
      "lb",
      "lg",
      "mh",
      "ml",
      "mr",
      "mk",
      "mg",
      "mt",
      "mn",
      "mi",
      "my",
      "nl",
      "no",
      "ne",
      "ny",
      "oc",
      "om",
      "or",
      "os",
      "pa",
      "pl",
      "pt",
      "ps",
      "qu",
      "ro",
      "rn",
      "ru",
      "sg",
      "sk",
      "sl",
      "sm",
      "sn",
      "sd",
      "so",
      "es",
      "sq",
      "su",
      "sv",
      "sw",
      "ta",
      "tt",
      "te",
      "tg",
      "tl",
      "th",
      "ti",
      "ts",
      "tr",
      "uk",
      "vi",
      "wo",
      "xh",
      "yo",
      "zu",
      "za",
      "dataset:google/fleurs",
      "arxiv:2305.13516",
      "license:cc-by-nc-4.0",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "coqui/XTTS-v2",
    "task": "text-to-speech",
    "library": "coqui",
    "downloads": 6597453,
    "likes": 3384,
    "tags": [
      "coqui",
      "text-to-speech",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "meta-llama/Llama-3.2-3B-Instruct",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 2100937,
    "likes": 1973,
    "tags": [
      "transformers",
      "safetensors",
      "llama",
      "text-generation",
      "facebook",
      "meta",
      "pytorch",
      "llama-3",
      "conversational",
      "en",
      "de",
      "fr",
      "it",
      "pt",
      "hi",
      "es",
      "th",
      "arxiv:2204.05149",
      "arxiv:2405.16406",
      "license:llama3.2",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "ByteDance-Seed/UI-TARS-1.5-7B",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 67198,
    "likes": 511,
    "tags": [
      "transformers",
      "safetensors",
      "qwen2_5_vl",
      "image-to-text",
      "multimodal",
      "gui",
      "image-text-to-text",
      "conversational",
      "en",
      "arxiv:2501.12326",
      "arxiv:2404.07972",
      "arxiv:2409.08264",
      "arxiv:2401.13919",
      "arxiv:2504.01382",
      "arxiv:2405.14573",
      "arxiv:2410.23218",
      "arxiv:2504.07981",
      "license:apache-2.0",
      "text-generation-inference",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "google/gemma-3n-E4B-it-litert-lm",
    "task": "text-generation",
    "library": "litert-lm",
    "downloads": 21010,
    "likes": 321,
    "tags": [
      "litert-lm",
      "text-generation",
      "arxiv:1905.07830",
      "arxiv:1905.10044",
      "arxiv:1911.11641",
      "arxiv:1904.09728",
      "arxiv:1705.03551",
      "arxiv:1911.01547",
      "arxiv:1907.10641",
      "arxiv:1903.00161",
      "arxiv:2210.03057",
      "arxiv:2502.12404",
      "arxiv:2411.19799",
      "arxiv:2009.03300",
      "arxiv:2502.21228",
      "arxiv:2311.12022",
      "arxiv:2403.07974",
      "arxiv:2108.07732",
      "arxiv:2107.03374",
      "license:gemma",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "fdtn-ai/Foundation-Sec-8B-Reasoning",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 1023,
    "likes": 23,
    "tags": [
      "transformers",
      "safetensors",
      "llama",
      "text-generation",
      "security",
      "fdtn-sec",
      "conversational",
      "en",
      "arxiv:2601.21051",
      "base_model:fdtn-ai/Foundation-Sec-8B",
      "base_model:finetune:fdtn-ai/Foundation-Sec-8B",
      "license:other",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "nvidia/Alpamayo-R1-10B",
    "task": "robotics",
    "library": "transformers",
    "downloads": 57434,
    "likes": 355,
    "tags": [
      "transformers",
      "safetensors",
      "alpamayo_r1",
      "robotics",
      "dataset:nvidia/PhysicalAI-Autonomous-Vehicles",
      "dataset:nvidia/PhysicalAI-Autonomous-Vehicles-NuRec",
      "arxiv:2511.00088",
      "license:other",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "alibaba-pai/Z-Image-Turbo-Fun-Controlnet-Union-2.1",
    "task": null,
    "library": "videox_fun",
    "downloads": 91132,
    "likes": 335,
    "tags": [
      "videox_fun",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "LiquidAI/LFM2.5-Audio-1.5B",
    "task": "audio-to-audio",
    "library": "liquid-audio",
    "downloads": 2198,
    "likes": 340,
    "tags": [
      "liquid-audio",
      "safetensors",
      "liquid",
      "lfm2",
      "audio",
      "lfm2-audio",
      "speech-to-speech",
      "audio-to-audio",
      "en",
      "arxiv:2511.23404",
      "base_model:LiquidAI/LFM2-1.2B",
      "base_model:finetune:LiquidAI/LFM2-1.2B",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "bakrianoo/arabic-legal-documents-ocr-1.0",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 341,
    "likes": 14,
    "tags": [
      "transformers",
      "safetensors",
      "gemma3",
      "image-to-text",
      "vision",
      "multimodal",
      "ocr",
      "arabic",
      "vllm",
      "lora",
      "llama-factory",
      "image-text-to-text",
      "conversational",
      "ar",
      "en",
      "dataset:custom",
      "base_model:google/gemma-3-4b-it",
      "base_model:adapter:google/gemma-3-4b-it",
      "license:gemma",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "nvidia/nemotron-colembed-vl-8b-v2",
    "task": "visual-document-retrieval",
    "library": "transformers",
    "downloads": 1891,
    "likes": 18,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3_vl_nemotron_embed",
      "feature-extraction",
      "text",
      "image",
      "vidore",
      "colpali",
      "multimodal-embedding",
      "multilingual-embedding",
      "Text-to-Visual Document (TVD) retrieval",
      "visual-document-retrieval",
      "custom_code",
      "multilingual",
      "arxiv:2602.03992",
      "arxiv:2511.21631",
      "license:cc-by-nc-4.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "sweepai/sweep-next-edit-1.5B",
    "task": null,
    "library": null,
    "downloads": 5154,
    "likes": 295,
    "tags": [
      "gguf",
      "code",
      "autocomplete",
      "next-edit",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "ACE-Step/acestep-transcriber",
    "task": "audio-text-to-text",
    "library": "transformers",
    "downloads": 188,
    "likes": 14,
    "tags": [
      "transformers",
      "safetensors",
      "qwen2_5_omni",
      "text-to-audio",
      "music",
      "audio",
      "audio-text-to-text",
      "arxiv:2602.00744",
      "license:mit",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "allenai/SERA-8B",
    "task": null,
    "library": null,
    "downloads": 11692,
    "likes": 35,
    "tags": [
      "safetensors",
      "qwen3",
      "arxiv:2601.20789",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "prithivMLmods/QIE-2511-Studio-DeLight",
    "task": "image-to-image",
    "library": "diffusers",
    "downloads": 3598,
    "likes": 14,
    "tags": [
      "diffusers",
      "lora",
      "art",
      "Studio-DeLight",
      "image-to-image",
      "en",
      "base_model:Qwen/Qwen-Image-Edit-2511",
      "base_model:adapter:Qwen/Qwen-Image-Edit-2511",
      "doi:10.57967/hf/7713",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "rhasspy/piper-voices",
    "task": null,
    "library": null,
    "downloads": 0,
    "likes": 412,
    "tags": [
      "onnx",
      "ar",
      "ca",
      "cs",
      "cy",
      "da",
      "de",
      "el",
      "en",
      "es",
      "fa",
      "fi",
      "fr",
      "hu",
      "is",
      "it",
      "ka",
      "kk",
      "lb",
      "lv",
      "ne",
      "nl",
      "no",
      "pl",
      "pt",
      "ro",
      "ru",
      "sk",
      "sl",
      "sr",
      "sv",
      "sw",
      "tr",
      "uk",
      "vi",
      "zh",
      "license:mit",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "mistralai/Mistral-7B-Instruct-v0.3",
    "task": null,
    "library": "vllm",
    "downloads": 1070507,
    "likes": 2392,
    "tags": [
      "vllm",
      "safetensors",
      "mistral",
      "mistral-common",
      "base_model:mistralai/Mistral-7B-v0.3",
      "base_model:finetune:mistralai/Mistral-7B-v0.3",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "stabilityai/stable-diffusion-3.5-large",
    "task": "text-to-image",
    "library": "diffusers",
    "downloads": 39757,
    "likes": 3354,
    "tags": [
      "diffusers",
      "safetensors",
      "text-to-image",
      "stable-diffusion",
      "en",
      "arxiv:2403.03206",
      "license:other",
      "diffusers:StableDiffusion3Pipeline",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "microsoft/bitnet-b1.58-2B-4T",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 6282,
    "likes": 1289,
    "tags": [
      "transformers",
      "safetensors",
      "bitnet",
      "text-generation",
      "chat",
      "large-language-model",
      "conversational",
      "custom_code",
      "en",
      "arxiv:2504.12285",
      "license:mit",
      "endpoints_compatible",
      "8-bit",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "google/medgemma-4b-it",
    "task": "image-text-to-text",
    "library": "transformers",
    "downloads": 360666,
    "likes": 882,
    "tags": [
      "transformers",
      "safetensors",
      "gemma3",
      "image-to-text",
      "medical",
      "radiology",
      "clinical-reasoning",
      "dermatology",
      "pathology",
      "ophthalmology",
      "chest-x-ray",
      "image-text-to-text",
      "conversational",
      "arxiv:2303.15343",
      "arxiv:2507.05201",
      "arxiv:2405.03162",
      "arxiv:2106.14463",
      "arxiv:2412.03555",
      "arxiv:2501.19393",
      "arxiv:2009.13081",
      "arxiv:2102.09542",
      "arxiv:2411.15640",
      "arxiv:2404.05590",
      "arxiv:2501.18362",
      "base_model:google/medgemma-4b-pt",
      "base_model:finetune:google/medgemma-4b-pt",
      "license:other",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "DavidAU/OpenAi-GPT-oss-20b-abliterated-uncensored-NEO-Imatrix-gguf",
    "task": "text-generation",
    "library": null,
    "downloads": 108819,
    "likes": 435,
    "tags": [
      "gguf",
      "gpt_oss",
      "gpt-oss",
      "openai",
      "mxfp4",
      "programming",
      "code generation",
      "code",
      "coding",
      "coder",
      "chat",
      "reasoning",
      "thinking",
      "r1",
      "cot",
      "deepseek",
      "128k context",
      "general usage",
      "problem solving",
      "brainstorming",
      "solve riddles",
      "uncensored",
      "abliterated",
      "Neo",
      "MOE",
      "Mixture of Experts",
      "24 experts",
      "NEO Imatrix",
      "Imatrix",
      "DI-Matrix",
      "Tri-Matrix",
      "text-generation",
      "en",
      "base_model:huihui-ai/Huihui-gpt-oss-20b-BF16-abliterated",
      "base_model:quantized:huihui-ai/Huihui-gpt-oss-20b-BF16-abliterated",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us",
      "imatrix",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "moonshotai/Kimi-K2-Thinking",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 364694,
    "likes": 1659,
    "tags": [
      "transformers",
      "safetensors",
      "kimi_k2",
      "text-generation",
      "conversational",
      "custom_code",
      "license:other",
      "eval-results",
      "endpoints_compatible",
      "compressed-tensors",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "ResembleAI/chatterbox-turbo",
    "task": "text-to-speech",
    "library": null,
    "downloads": 0,
    "likes": 595,
    "tags": [
      "text-to-speech",
      "speech",
      "speech-generation",
      "voice-cloning",
      "en",
      "license:mit",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "stepfun-ai/Step3-VL-10B",
    "task": "image-text-to-text",
    "library": null,
    "downloads": 81710,
    "likes": 387,
    "tags": [
      "safetensors",
      "step_robotics",
      "image-text-to-text",
      "conversational",
      "custom_code",
      "arxiv:2601.09668",
      "base_model:stepfun-ai/Step3-VL-10B-Base",
      "base_model:finetune:stepfun-ai/Step3-VL-10B-Base",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "facebook/ActionMesh",
    "task": "image-to-3d",
    "library": null,
    "downloads": 172,
    "likes": 34,
    "tags": [
      "safetensors",
      "custom",
      "video-to-4D",
      "image-to-3d",
      "en",
      "arxiv:2601.16148",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Hellrunner/z_image_fp32",
    "task": null,
    "library": null,
    "downloads": 0,
    "likes": 17,
    "tags": [
      "license:unknown",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "unsloth/Qwen3-Coder-Next",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 2412,
    "likes": 13,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3_next",
      "text-generation",
      "unsloth",
      "qwen",
      "qwen3",
      "conversational",
      "base_model:Qwen/Qwen3-Coder-Next",
      "base_model:finetune:Qwen/Qwen3-Coder-Next",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "unsloth/GLM-OCR",
    "task": "image-to-text",
    "library": "transformers",
    "downloads": 570,
    "likes": 13,
    "tags": [
      "transformers",
      "safetensors",
      "glm_ocr",
      "image-to-text",
      "zh",
      "en",
      "fr",
      "es",
      "ru",
      "de",
      "ja",
      "ko",
      "base_model:zai-org/GLM-OCR",
      "base_model:finetune:zai-org/GLM-OCR",
      "license:mit",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "ubergarm/Step-3.5-Flash-GGUF",
    "task": "text-generation",
    "library": null,
    "downloads": 2742,
    "likes": 13,
    "tags": [
      "gguf",
      "imatrix",
      "conversational",
      "ik_llama.cpp",
      "step3p5",
      "text-generation",
      "base_model:stepfun-ai/Step-3.5-Flash",
      "base_model:quantized:stepfun-ai/Step-3.5-Flash",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen2.5-7B-Instruct",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 10551465,
    "likes": 1059,
    "tags": [
      "transformers",
      "safetensors",
      "qwen2",
      "text-generation",
      "chat",
      "conversational",
      "en",
      "arxiv:2309.00071",
      "arxiv:2407.10671",
      "base_model:Qwen/Qwen2.5-7B",
      "base_model:finetune:Qwen/Qwen2.5-7B",
      "license:apache-2.0",
      "text-generation-inference",
      "endpoints_compatible",
      "deploy:azure",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "google/gemma-3n-E2B-it-litert-lm",
    "task": "text-generation",
    "library": "litert-lm",
    "downloads": 20237,
    "likes": 329,
    "tags": [
      "litert-lm",
      "text-generation",
      "arxiv:1905.07830",
      "arxiv:1905.10044",
      "arxiv:1911.11641",
      "arxiv:1904.09728",
      "arxiv:1705.03551",
      "arxiv:1911.01547",
      "arxiv:1907.10641",
      "arxiv:1903.00161",
      "arxiv:2210.03057",
      "arxiv:2502.12404",
      "arxiv:2411.19799",
      "arxiv:2009.03300",
      "arxiv:2502.21228",
      "arxiv:2311.12022",
      "arxiv:2403.07974",
      "arxiv:2108.07732",
      "arxiv:2107.03374",
      "license:gemma",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Kijai/WanVideo_comfy_fp8_scaled",
    "task": null,
    "library": "diffusion-single-file",
    "downloads": 619438,
    "likes": 564,
    "tags": [
      "diffusion-single-file",
      "comfyui",
      "base_model:Wan-AI/Wan2.1-VACE-1.3B",
      "base_model:finetune:Wan-AI/Wan2.1-VACE-1.3B",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen3-Omni-30B-A3B-Instruct",
    "task": "any-to-any",
    "library": "transformers",
    "downloads": 614166,
    "likes": 838,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3_omni_moe",
      "text-to-audio",
      "multimodal",
      "any-to-any",
      "en",
      "license:other",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "mistralai/Devstral-Small-2-24B-Instruct-2512",
    "task": null,
    "library": "vllm",
    "downloads": 277117,
    "likes": 519,
    "tags": [
      "vllm",
      "safetensors",
      "mistral3",
      "mistral-common",
      "arxiv:2501.19399",
      "base_model:mistralai/Mistral-Small-3.1-24B-Base-2503",
      "base_model:quantized:mistralai/Mistral-Small-3.1-24B-Base-2503",
      "license:apache-2.0",
      "fp8",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "FunAudioLLM/Fun-CosyVoice3-0.5B-2512",
    "task": "text-to-speech",
    "library": null,
    "downloads": 4641,
    "likes": 444,
    "tags": [
      "onnx",
      "safetensors",
      "text-to-speech",
      "zh",
      "en",
      "fr",
      "es",
      "ja",
      "ko",
      "it",
      "ru",
      "de",
      "arxiv:2505.17589",
      "arxiv:2412.10117",
      "arxiv:2407.05407",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "nvidia/Cosmos-Reason2-8B",
    "task": "image-text-to-text",
    "library": "cosmos",
    "downloads": 160099,
    "likes": 109,
    "tags": [
      "cosmos",
      "safetensors",
      "qwen3_vl",
      "nvidia",
      "conversational",
      "image-text-to-text",
      "base_model:Qwen/Qwen3-VL-8B-Instruct",
      "base_model:finetune:Qwen/Qwen3-VL-8B-Instruct",
      "license:other",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "Qwen/Qwen-Image-Edit-2511",
    "task": "image-to-image",
    "library": "diffusers",
    "downloads": 120820,
    "likes": 790,
    "tags": [
      "diffusers",
      "safetensors",
      "image-to-image",
      "en",
      "zh",
      "arxiv:2508.02324",
      "license:apache-2.0",
      "diffusers:QwenImageEditPlusPipeline",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "ekwek/Soprano-1.1-80M",
    "task": "text-to-speech",
    "library": "transformers",
    "downloads": 35737,
    "likes": 198,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "text-to-speech",
      "license:apache-2.0",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "janhq/Jan-v3-4B-base-instruct-gguf",
    "task": "text-generation",
    "library": "transformers",
    "downloads": 77231,
    "likes": 40,
    "tags": [
      "transformers",
      "gguf",
      "code",
      "text-generation",
      "en",
      "base_model:janhq/Jan-v3-4B-base-instruct",
      "base_model:quantized:janhq/Jan-v3-4B-base-instruct",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us",
      "conversational"
    ],
    "description": ""
  },
  {
    "id": "tencent/Youtu-VL-4B-Instruct-GGUF",
    "task": "image-text-to-text",
    "library": "llama.cpp",
    "downloads": 4080,
    "likes": 58,
    "tags": [
      "llama.cpp",
      "gguf",
      "vision",
      "vlm",
      "image-text-to-text",
      "conversational",
      "arxiv:2601.19798",
      "arxiv:2512.24618",
      "base_model:tencent/Youtu-VL-4B-Instruct",
      "base_model:quantized:tencent/Youtu-VL-4B-Instruct",
      "license:other",
      "endpoints_compatible",
      "region:us"
    ],
    "description": ""
  },
  {
    "id": "DiffSynth-Studio/Z-Image-i2L",
    "task": null,
    "library": null,
    "downloads": 0,
    "likes": 33,
    "tags": [
      "safetensors",
      "base_model:Tongyi-MAI/Z-Image",
      "base_model:adapter:Tongyi-MAI/Z-Image",
      "license:apache-2.0",
      "region:us"
    ],
    "description": ""
  }
]