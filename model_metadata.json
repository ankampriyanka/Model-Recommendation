[
  {
    "id": "bert-base-uncased",
    "family": "BERT",
    "task": "text-classification",
    "input_type": [
      "text"
    ],
    "library": "transformers",
    "domain": [
      "NLP"
    ],
    "description": "Bidirectional Transformer model for general-purpose NLP classification tasks.",
    "best_for": [
      "sentiment analysis",
      "intent detection"
    ],
    "limitations": [
      "Max 512 tokens"
    ],
    "infra_requirements": "GPU recommended for training; CPU ok for inference.",
    "cost_per_1k_inferences_usd": 0.002,
    "latency_ms": 35,
    "gpu_required": false,
    "memory_mb": 420,
    "accuracy_score": 0.92,
    "roi_score": 8.4,
    "link": "https://huggingface.co/bert-base-uncased"
  },
  {
    "id": "distilbert-base-uncased",
    "family": "DistilBERT",
    "task": "text-classification",
    "input_type": [
      "text"
    ],
    "library": "transformers",
    "domain": [
      "NLP"
    ],
    "description": "Lightweight distilled version of BERT offering efficiency with competitive accuracy.",
    "best_for": [
      "real-time inference",
      "low-latency NLP"
    ],
    "limitations": [
      "Slightly lower accuracy than BERT"
    ],
    "infra_requirements": "Runs on CPU easily.",
    "cost_per_1k_inferences_usd": 0.0012,
    "latency_ms": 18,
    "gpu_required": false,
    "memory_mb": 250,
    "accuracy_score": 0.89,
    "roi_score": 9.1,
    "link": "https://huggingface.co/distilbert-base-uncased"
  }
]
